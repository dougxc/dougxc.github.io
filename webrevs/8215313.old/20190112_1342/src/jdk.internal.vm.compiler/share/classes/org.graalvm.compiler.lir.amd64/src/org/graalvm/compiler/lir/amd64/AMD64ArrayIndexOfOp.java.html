<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta charset="utf-8">
<meta http-equiv="cache-control" content="no-cache" />
<meta http-equiv="Pragma" content="no-cache" />
<meta http-equiv="Expires" content="-1" />
<!--
   Note to customizers: the body of the webrev is IDed as SUNWwebrev
   to allow easy overriding by users of webrev via the userContent.css
   mechanism available in some browsers.

   For example, to have all "removed" information be red instead of
   brown, set a rule in your userContent.css file like:

       body#SUNWwebrev span.removed { color: red ! important; }
-->
<style type="text/css" media="screen">
body {
    background-color: #eeeeee;
}
hr {
    border: none 0;
    border-top: 1px solid #aaa;
    height: 1px;
}
div.summary {
    font-size: .8em;
    border-bottom: 1px solid #aaa;
    padding-left: 1em;
    padding-right: 1em;
}
div.summary h2 {
    margin-bottom: 0.3em;
}
div.summary table th {
    text-align: right;
    vertical-align: top;
    white-space: nowrap;
}
span.lineschanged {
    font-size: 0.7em;
}
span.oldmarker {
    color: red;
    font-size: large;
    font-weight: bold;
}
span.newmarker {
    color: green;
    font-size: large;
    font-weight: bold;
}
span.removed {
    color: brown;
}
span.changed {
    color: blue;
}
span.new {
    color: blue;
    font-weight: bold;
}
a.print { font-size: x-small; }

</style>

<style type="text/css" media="print">
pre { font-size: 0.8em; font-family: courier, monospace; }
span.removed { color: #444; font-style: italic }
span.changed { font-weight: bold; }
span.new { font-weight: bold; }
span.newmarker { font-size: 1.2em; font-weight: bold; }
span.oldmarker { font-size: 1.2em; font-weight: bold; }
a.print {display: none}
hr { border: none 0; border-top: 1px solid #aaa; height: 1px; }
</style>

<title>New src/jdk.internal.vm.compiler/share/classes/org.graalvm.compiler.lir.amd64/src/org/graalvm/compiler/lir/amd64/AMD64ArrayIndexOfOp.java</title>
<body id="SUNWwebrev">
<pre>
   1 /*
   2  * Copyright (c) 2019, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  */
  23 package org.graalvm.compiler.lir.amd64;
  24 
  25 import jdk.vm.ci.amd64.AMD64;
  26 import jdk.vm.ci.amd64.AMD64.CPUFeature;
  27 import jdk.vm.ci.amd64.AMD64Kind;
  28 import jdk.vm.ci.code.Register;
  29 import jdk.vm.ci.meta.JavaKind;
  30 import jdk.vm.ci.meta.Value;
  31 import org.graalvm.compiler.asm.Label;
  32 import org.graalvm.compiler.asm.amd64.AMD64Address;
  33 import org.graalvm.compiler.asm.amd64.AMD64Assembler;
  34 import org.graalvm.compiler.asm.amd64.AMD64Assembler.VexMoveOp;
  35 import org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRMIOp;
  36 import org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRMOp;
  37 import org.graalvm.compiler.asm.amd64.AMD64Assembler.VexRVMOp;
  38 import org.graalvm.compiler.asm.amd64.AMD64MacroAssembler;
  39 import org.graalvm.compiler.asm.amd64.AVXKind;
  40 import org.graalvm.compiler.core.common.LIRKind;
  41 import org.graalvm.compiler.lir.LIRInstructionClass;
  42 import org.graalvm.compiler.lir.Opcode;
  43 import org.graalvm.compiler.lir.asm.CompilationResultBuilder;
  44 import org.graalvm.compiler.lir.gen.LIRGeneratorTool;
  45 
  46 import static jdk.vm.ci.code.ValueUtil.asRegister;
  47 import static org.graalvm.compiler.lir.LIRInstruction.OperandFlag.ILLEGAL;
  48 import static org.graalvm.compiler.lir.LIRInstruction.OperandFlag.REG;
  49 
  50 /**
  51  */
  52 @Opcode("AMD64_ARRAY_INDEX_OF")
  53 public final class AMD64ArrayIndexOfOp extends AMD64LIRInstruction {
  54     public static final LIRInstructionClass&lt;AMD64ArrayIndexOfOp&gt; TYPE = LIRInstructionClass.create(AMD64ArrayIndexOfOp.class);
  55 
  56     private final JavaKind kind;
  57     private final int vmPageSize;
  58     private final int nValues;
  59     private final boolean findTwoConsecutive;
  60     private final AMD64Kind vectorKind;
  61 
  62     @Def({REG}) protected Value resultValue;
  63     @Alive({REG}) protected Value arrayPtrValue;
  64     @Use({REG}) protected Value arrayLengthValue;
  65     @Alive({REG}) protected Value searchValue1;
  66     @Alive({REG, ILLEGAL}) protected Value searchValue2;
  67     @Alive({REG, ILLEGAL}) protected Value searchValue3;
  68     @Alive({REG, ILLEGAL}) protected Value searchValue4;
  69     @Temp({REG}) protected Value arraySlotsRemaining;
  70     @Temp({REG}) protected Value comparisonResult1;
  71     @Temp({REG}) protected Value comparisonResult2;
  72     @Temp({REG}) protected Value comparisonResult3;
  73     @Temp({REG}) protected Value comparisonResult4;
  74     @Temp({REG, ILLEGAL}) protected Value vectorCompareVal1;
  75     @Temp({REG, ILLEGAL}) protected Value vectorCompareVal2;
  76     @Temp({REG, ILLEGAL}) protected Value vectorCompareVal3;
  77     @Temp({REG, ILLEGAL}) protected Value vectorCompareVal4;
  78     @Temp({REG, ILLEGAL}) protected Value vectorArray1;
  79     @Temp({REG, ILLEGAL}) protected Value vectorArray2;
  80     @Temp({REG, ILLEGAL}) protected Value vectorArray3;
  81     @Temp({REG, ILLEGAL}) protected Value vectorArray4;
  82 
  83     public AMD64ArrayIndexOfOp(JavaKind kind, boolean findTwoConsecutive, int vmPageSize, int maxVectorSize, LIRGeneratorTool tool, Value result, Value arrayPtr, Value arrayLength,
  84                     Value... searchValues) {
  85         super(TYPE);
  86         this.kind = kind;
  87         this.findTwoConsecutive = findTwoConsecutive;
  88         this.vmPageSize = vmPageSize;
  89         assert 0 &lt; searchValues.length &amp;&amp; searchValues.length &lt;= 4;
  90         assert byteMode(kind) || charMode(kind);
  91         assert supports(tool, CPUFeature.SSE2) || supports(tool, CPUFeature.AVX) || supportsAVX2(tool);
  92         nValues = searchValues.length;
  93         assert !findTwoConsecutive || nValues == 1;
  94         resultValue = result;
  95         arrayPtrValue = arrayPtr;
  96         arrayLengthValue = arrayLength;
  97         searchValue1 = searchValues[0];
  98         searchValue2 = nValues &gt; 1 ? searchValues[1] : Value.ILLEGAL;
  99         searchValue3 = nValues &gt; 2 ? searchValues[2] : Value.ILLEGAL;
 100         searchValue4 = nValues &gt; 3 ? searchValues[3] : Value.ILLEGAL;
 101         arraySlotsRemaining = tool.newVariable(LIRKind.value(AMD64Kind.DWORD));
 102         comparisonResult1 = tool.newVariable(LIRKind.value(AMD64Kind.DWORD));
 103         comparisonResult2 = tool.newVariable(LIRKind.value(AMD64Kind.DWORD));
 104         comparisonResult3 = tool.newVariable(LIRKind.value(AMD64Kind.DWORD));
 105         comparisonResult4 = tool.newVariable(LIRKind.value(AMD64Kind.DWORD));
 106         vectorKind = supportsAVX2(tool) &amp;&amp; (maxVectorSize &lt; 0 || maxVectorSize &gt;= 32) ? byteMode(kind) ? AMD64Kind.V256_BYTE : AMD64Kind.V256_WORD
 107                         : byteMode(kind) ? AMD64Kind.V128_BYTE : AMD64Kind.V128_WORD;
 108         vectorCompareVal1 = tool.newVariable(LIRKind.value(vectorKind));
 109         vectorCompareVal2 = nValues &gt; 1 ? tool.newVariable(LIRKind.value(vectorKind)) : Value.ILLEGAL;
 110         vectorCompareVal3 = nValues &gt; 2 ? tool.newVariable(LIRKind.value(vectorKind)) : Value.ILLEGAL;
 111         vectorCompareVal4 = nValues &gt; 3 ? tool.newVariable(LIRKind.value(vectorKind)) : Value.ILLEGAL;
 112         vectorArray1 = tool.newVariable(LIRKind.value(vectorKind));
 113         vectorArray2 = tool.newVariable(LIRKind.value(vectorKind));
 114         vectorArray3 = tool.newVariable(LIRKind.value(vectorKind));
 115         vectorArray4 = tool.newVariable(LIRKind.value(vectorKind));
 116     }
 117 
 118     private static boolean byteMode(JavaKind kind) {
 119         return kind == JavaKind.Byte;
 120     }
 121 
 122     private static boolean charMode(JavaKind kind) {
 123         return kind == JavaKind.Char;
 124     }
 125 
 126     @Override
 127     public void emitCode(CompilationResultBuilder crb, AMD64MacroAssembler asm) {
 128         Register arrayPtr = asRegister(arrayPtrValue);
 129         Register arrayLength = asRegister(arrayLengthValue);
 130         Register result = asRegister(resultValue);
 131         Register slotsRemaining = asRegister(arraySlotsRemaining);
 132         Register[] searchValue = {
 133                         nValues &gt; 0 ? asRegister(searchValue1) : null,
 134                         nValues &gt; 1 ? asRegister(searchValue2) : null,
 135                         nValues &gt; 2 ? asRegister(searchValue3) : null,
 136                         nValues &gt; 3 ? asRegister(searchValue4) : null,
 137         };
 138         Register[] vecCmp = {
 139                         nValues &gt; 0 ? asRegister(vectorCompareVal1) : null,
 140                         nValues &gt; 1 ? asRegister(vectorCompareVal2) : null,
 141                         nValues &gt; 2 ? asRegister(vectorCompareVal3) : null,
 142                         nValues &gt; 3 ? asRegister(vectorCompareVal4) : null,
 143         };
 144         Register[] vecArray = {
 145                         asRegister(vectorArray1),
 146                         asRegister(vectorArray2),
 147                         asRegister(vectorArray3),
 148                         asRegister(vectorArray4),
 149         };
 150         Register[] cmpResult = {
 151                         asRegister(comparisonResult1),
 152                         asRegister(comparisonResult2),
 153                         asRegister(comparisonResult3),
 154                         asRegister(comparisonResult4),
 155         };
 156         Label retFound = new Label();
 157         Label retNotFound = new Label();
 158         Label end = new Label();
 159 
 160         AVXKind.AVXSize vectorSize = AVXKind.getDataSize(vectorKind);
 161         int nVectors = nValues == 1 ? 4 : nValues == 2 ? 2 : 1;
 162 
 163         // load array length
 164         // important: this must be the first register manipulation, since arrayLengthValue is
 165         // annotated with @Use
 166         asm.movl(slotsRemaining, arrayLength);
 167         // load array pointer
 168         asm.movq(result, arrayPtr);
 169         // move search values to vectors
 170         for (int i = 0; i &lt; nValues; i++) {
 171             if (asm.supports(CPUFeature.AVX)) {
 172                 VexMoveOp.VMOVD.emit(asm, AVXKind.AVXSize.DWORD, vecCmp[i], searchValue[i]);
 173             } else {
 174                 asm.movdl(vecCmp[i], searchValue[i]);
 175             }
 176         }
 177         // fill comparison vector with copies of the search value
 178         for (int i = 0; i &lt; nValues; i++) {
 179             emitBroadcast(asm, findTwoConsecutive ? (byteMode(kind) ? JavaKind.Char : JavaKind.Int) : kind, vecCmp[i], vecArray[0], vectorSize);
 180         }
 181 
 182         emitArrayIndexOfChars(crb, asm, kind, vectorSize, result, slotsRemaining, searchValue, vecCmp, vecArray, cmpResult, retFound, retNotFound, vmPageSize, nValues, nVectors, findTwoConsecutive);
 183 
 184         // return -1 (no match)
 185         asm.bind(retNotFound);
 186         asm.movq(result, -1);
 187         asm.jmpb(end);
 188 
 189         asm.bind(retFound);
 190         // convert array pointer to offset
 191         asm.subq(result, arrayPtr);
 192         if (charMode(kind)) {
 193             asm.shrq(result, 1);
 194         }
 195         asm.bind(end);
 196     }
 197 
 198     private static void emitArrayIndexOfChars(CompilationResultBuilder crb, AMD64MacroAssembler asm, JavaKind kind, AVXKind.AVXSize vectorSize,
 199                     Register arrayPtr,
 200                     Register slotsRemaining,
 201                     Register[] searchValue,
 202                     Register[] vecCmp,
 203                     Register[] vecArray,
 204                     Register[] cmpResult,
 205                     Label retFound,
 206                     Label retNotFound,
 207                     int vmPageSize,
 208                     int nValues,
 209                     int nVectors,
 210                     boolean findTwoCharPrefix) {
 211         Label bulkVectorLoop = new Label();
 212         Label singleVectorLoop = new Label();
 213         Label[] vectorFound = {
 214                         new Label(),
 215                         new Label(),
 216                         new Label(),
 217                         new Label(),
 218         };
 219         Label lessThanVectorSizeRemaining = new Label();
 220         Label lessThanVectorSizeRemainingLoop = new Label();
 221         Label lessThanVectorSizeRemainingLoopBegin = new Label();
 222         Label bulkVectorLoopExit = nVectors == 1 ? lessThanVectorSizeRemaining : singleVectorLoop;
 223         int bytesPerVector = vectorSize.getBytes();
 224         int arraySlotsPerVector = vectorSize.getBytes() / kind.getByteCount();
 225         int singleVectorLoopCondition = arraySlotsPerVector;
 226         int bulkSize = arraySlotsPerVector * nVectors;
 227         int bulkSizeBytes = bytesPerVector * nVectors;
 228         int bulkLoopCondition = bulkSize;
 229         int[] vectorOffsets;
 230         JavaKind vectorCompareKind = kind;
 231         if (findTwoCharPrefix) {
 232             singleVectorLoopCondition++;
 233             bulkLoopCondition++;
 234             bulkSize /= 2;
 235             bulkSizeBytes /= 2;
 236             vectorOffsets = new int[]{0, kind.getByteCount(), bytesPerVector, bytesPerVector + kind.getByteCount()};
 237             vectorCompareKind = byteMode(kind) ? JavaKind.Char : JavaKind.Int;
 238         } else {
 239             vectorOffsets = new int[]{0, bytesPerVector, bytesPerVector * 2, bytesPerVector * 3};
 240         }
 241 
 242         // load copy of low part of array pointer
 243         Register tmpArrayPtrLow = cmpResult[0];
 244         asm.movl(tmpArrayPtrLow, arrayPtr);
 245 
 246         // check if bulk vector load is in bounds
 247         asm.cmpl(slotsRemaining, bulkLoopCondition);
 248         asm.jcc(AMD64Assembler.ConditionFlag.Below, bulkVectorLoopExit);
 249 
 250         // check if array pointer is aligned to bulkSize
 251         asm.andl(tmpArrayPtrLow, bulkSizeBytes - 1);
 252         asm.jcc(AMD64Assembler.ConditionFlag.Zero, bulkVectorLoop);
 253 
 254         // do one unaligned bulk comparison pass and adjust alignment afterwards
 255         emitVectorCompare(asm, vectorCompareKind, vectorSize, nValues, nVectors, vectorOffsets, arrayPtr, vecCmp, vecArray, cmpResult, vectorFound, false);
 256         // load copy of low part of array pointer
 257         asm.movl(tmpArrayPtrLow, arrayPtr);
 258         // adjust array pointer
 259         asm.addq(arrayPtr, bulkSizeBytes);
 260         // adjust number of array slots remaining
 261         asm.subl(slotsRemaining, bulkSize);
 262         // get offset to bulk size alignment
 263         asm.andl(tmpArrayPtrLow, bulkSizeBytes - 1);
 264         emitBytesToArraySlots(asm, kind, tmpArrayPtrLow);
 265         // adjust array pointer to bulk size alignment
 266         asm.andq(arrayPtr, ~(bulkSizeBytes - 1));
 267         // adjust number of array slots remaining
 268         asm.addl(slotsRemaining, tmpArrayPtrLow);
 269         // check if there are enough array slots remaining for the bulk loop
 270         asm.cmpl(slotsRemaining, bulkLoopCondition);
 271         asm.jcc(AMD64Assembler.ConditionFlag.Below, bulkVectorLoopExit);
 272 
 273         emitAlign(crb, asm);
 274         asm.bind(bulkVectorLoop);
 275         // memory-aligned bulk comparison
 276         emitVectorCompare(asm, vectorCompareKind, vectorSize, nValues, nVectors, vectorOffsets, arrayPtr, vecCmp, vecArray, cmpResult, vectorFound, !findTwoCharPrefix);
 277         // adjust number of array slots remaining
 278         asm.subl(slotsRemaining, bulkSize);
 279         // adjust array pointer
 280         asm.addq(arrayPtr, bulkSizeBytes);
 281         // check if there are enough array slots remaining for the bulk loop
 282         asm.cmpl(slotsRemaining, bulkLoopCondition);
 283         asm.jcc(AMD64Assembler.ConditionFlag.Below, bulkVectorLoopExit);
 284         // continue loop
 285         asm.jmp(bulkVectorLoop);
 286 
 287         if (nVectors &gt; 1) {
 288             emitAlign(crb, asm);
 289             // same loop as bulkVectorLoop, with only one vector
 290             asm.bind(singleVectorLoop);
 291             // check if single vector load is in bounds
 292             asm.cmpl(slotsRemaining, singleVectorLoopCondition);
 293             asm.jcc(AMD64Assembler.ConditionFlag.Below, lessThanVectorSizeRemaining);
 294             // compare
 295             emitVectorCompare(asm, vectorCompareKind, vectorSize, nValues, findTwoCharPrefix ? 2 : 1, vectorOffsets, arrayPtr, vecCmp, vecArray, cmpResult, vectorFound, false);
 296             // adjust number of array slots remaining
 297             asm.subl(slotsRemaining, arraySlotsPerVector);
 298             // adjust array pointer
 299             asm.addq(arrayPtr, bytesPerVector);
 300             // continue loop
 301             asm.jmpb(singleVectorLoop);
 302         }
 303 
 304         asm.bind(lessThanVectorSizeRemaining);
 305         // check if any array slots remain
 306         asm.testl(slotsRemaining, slotsRemaining);
 307         asm.jcc(AMD64Assembler.ConditionFlag.Zero, retNotFound);
 308 
 309         // a vector compare will read out of bounds of the input array.
 310         // check if the out-of-bounds read would cross a memory page boundary.
 311         // load copy of low part of array pointer
 312         asm.movl(tmpArrayPtrLow, arrayPtr);
 313         // check if pointer + vector size would cross the page boundary
 314         asm.andl(tmpArrayPtrLow, (vmPageSize - 1));
 315         asm.cmpl(tmpArrayPtrLow, (vmPageSize - (findTwoCharPrefix ? bytesPerVector + kind.getByteCount() : bytesPerVector)));
 316         // if the page boundary would be crossed, do byte/character-wise comparison instead.
 317         asm.jccb(AMD64Assembler.ConditionFlag.Above, lessThanVectorSizeRemainingLoopBegin);
 318 
 319         Label[] overBoundsMatch = {new Label(), new Label()};
 320         // otherwise, do a vector compare that reads beyond array bounds
 321         emitVectorCompare(asm, vectorCompareKind, vectorSize, nValues, findTwoCharPrefix ? 2 : 1, vectorOffsets, arrayPtr, vecCmp, vecArray, cmpResult, overBoundsMatch, false);
 322         // no match
 323         asm.jmp(retNotFound);
 324         if (findTwoCharPrefix) {
 325             Label overBoundsFinish = new Label();
 326             asm.bind(overBoundsMatch[1]);
 327             // get match offset of second result
 328             asm.bsfq(cmpResult[1], cmpResult[1]);
 329             asm.addl(cmpResult[1], kind.getByteCount());
 330             // replace first result with second and continue
 331             asm.movl(cmpResult[0], cmpResult[1]);
 332             asm.jmpb(overBoundsFinish);
 333 
 334             asm.bind(overBoundsMatch[0]);
 335             emitFindTwoCharPrefixMinResult(asm, kind, cmpResult, overBoundsFinish);
 336         } else {
 337             asm.bind(overBoundsMatch[0]);
 338             // find match offset
 339             asm.bsfq(cmpResult[0], cmpResult[0]);
 340         }
 341 
 342         // adjust array pointer for match result
 343         asm.addq(arrayPtr, cmpResult[0]);
 344         if (charMode(kind)) {
 345             // convert byte offset to chars
 346             asm.shrl(cmpResult[0], 1);
 347         }
 348         // check if offset of matched value is greater than number of bytes remaining / out of array
 349         // bounds
 350         if (findTwoCharPrefix) {
 351             asm.decrementl(slotsRemaining);
 352         }
 353         asm.cmpl(cmpResult[0], slotsRemaining);
 354         // match is out of bounds, return no match
 355         asm.jcc(AMD64Assembler.ConditionFlag.GreaterEqual, retNotFound);
 356         // adjust number of array slots remaining
 357         if (findTwoCharPrefix) {
 358             asm.incrementl(slotsRemaining, 1);
 359         }
 360         asm.subl(slotsRemaining, cmpResult[0]);
 361         // match is in bounds, return offset
 362         asm.jmp(retFound);
 363 
 364         asm.bind(lessThanVectorSizeRemainingLoopBegin);
 365         if (!(charMode(kind) &amp;&amp; findTwoCharPrefix)) {
 366             for (int i = 0; i &lt; nValues; i++) {
 367                 asm.andl(searchValue[i], byteMode(kind) &amp;&amp; !findTwoCharPrefix ? 0xff : 0xffff);
 368             }
 369         }
 370         // compare remaining slots in the array one-by-one
 371         asm.bind(lessThanVectorSizeRemainingLoop);
 372         // check if enough array slots remain
 373         asm.cmpl(slotsRemaining, findTwoCharPrefix ? 1 : 0);
 374         asm.jcc(AMD64Assembler.ConditionFlag.LessEqual, retNotFound);
 375         // load char / byte
 376         if (byteMode(kind)) {
 377             if (findTwoCharPrefix) {
 378                 asm.movzwl(cmpResult[0], new AMD64Address(arrayPtr));
 379             } else {
 380                 asm.movzbl(cmpResult[0], new AMD64Address(arrayPtr));
 381             }
 382         } else {
 383             if (findTwoCharPrefix) {
 384                 asm.movl(cmpResult[0], new AMD64Address(arrayPtr));
 385             } else {
 386                 asm.movzwl(cmpResult[0], new AMD64Address(arrayPtr));
 387             }
 388         }
 389         // check for match
 390         for (int i = 0; i &lt; nValues; i++) {
 391             asm.cmpl(cmpResult[0], searchValue[i]);
 392             asm.jcc(AMD64Assembler.ConditionFlag.Equal, retFound);
 393         }
 394         // adjust number of array slots remaining
 395         asm.decrementl(slotsRemaining);
 396         // adjust array pointer
 397         asm.addq(arrayPtr, kind.getByteCount());
 398         // continue loop
 399         asm.jmpb(lessThanVectorSizeRemainingLoop);
 400 
 401         for (int i = 1; i &lt; nVectors; i += (findTwoCharPrefix ? 2 : 1)) {
 402             emitVectorFoundWithOffset(asm, kind, vectorOffsets[i], arrayPtr, cmpResult[i], slotsRemaining, vectorFound[i], retFound);
 403         }
 404 
 405         if (findTwoCharPrefix) {
 406             asm.bind(vectorFound[2]);
 407             asm.addq(arrayPtr, vectorOffsets[2]);
 408             // adjust number of array slots remaining
 409             asm.subl(slotsRemaining, charMode(kind) ? vectorOffsets[2] / 2 : vectorOffsets[2]);
 410             asm.movl(cmpResult[0], cmpResult[2]);
 411             asm.movl(cmpResult[1], cmpResult[3]);
 412             asm.bind(vectorFound[0]);
 413             emitFindTwoCharPrefixMinResult(asm, kind, cmpResult, new Label());
 414         } else {
 415             asm.bind(vectorFound[0]);
 416             // find index of first set bit in bit mask
 417             asm.bsfq(cmpResult[0], cmpResult[0]);
 418         }
 419         // add offset to array pointer
 420         asm.addq(arrayPtr, cmpResult[0]);
 421         if (charMode(kind)) {
 422             // convert byte offset to chars
 423             asm.shrl(cmpResult[0], 1);
 424         }
 425         // adjust number of array slots remaining
 426         asm.subl(slotsRemaining, cmpResult[0]);
 427         asm.jmpb(retFound);
 428     }
 429 
 430     private static void emitFindTwoCharPrefixMinResult(AMD64MacroAssembler asm, JavaKind kind, Register[] cmpResult, Label done) {
 431         // find match offset
 432         asm.bsfq(cmpResult[0], cmpResult[0]);
 433         // check if second result is also a match
 434         asm.testl(cmpResult[1], cmpResult[1]);
 435         asm.jcc(AMD64Assembler.ConditionFlag.Zero, done);
 436         // get match offset of second result
 437         asm.bsfq(cmpResult[1], cmpResult[1]);
 438         asm.addl(cmpResult[1], kind.getByteCount());
 439         // check if first result is less than second
 440         asm.cmpl(cmpResult[0], cmpResult[1]);
 441         asm.jcc(AMD64Assembler.ConditionFlag.LessEqual, done);
 442         // first result is greater than second, replace it with the second result
 443         asm.movl(cmpResult[0], cmpResult[1]);
 444         asm.bind(done);
 445     }
 446 
 447     private static void emitAlign(CompilationResultBuilder crb, AMD64MacroAssembler asm) {
 448         asm.align(crb.target.wordSize * 2);
 449     }
 450 
 451     /**
 452      * Fills {@code vecDst} with copies of its lowest byte, word or dword.
 453      */
 454     private static void emitBroadcast(AMD64MacroAssembler asm, JavaKind kind, Register vecDst, Register vecTmp, AVXKind.AVXSize vectorSize) {
 455         switch (kind) {
 456             case Byte:
 457                 if (asm.supports(CPUFeature.AVX2)) {
 458                     VexRMOp.VPBROADCASTB.emit(asm, vectorSize, vecDst, vecDst);
 459                 } else if (asm.supports(CPUFeature.AVX)) {
 460                     VexRVMOp.VPXOR.emit(asm, vectorSize, vecTmp, vecTmp, vecTmp);
 461                     VexRVMOp.VPSHUFB.emit(asm, vectorSize, vecDst, vecDst, vecTmp);
 462                 } else if (asm.supports(CPUFeature.SSSE3)) {
 463                     asm.pxor(vecTmp, vecTmp);
 464                     asm.pshufb(vecDst, vecTmp);
 465                 } else { // SSE2
 466                     asm.punpcklbw(vecDst, vecDst);
 467                     asm.punpcklbw(vecDst, vecDst);
 468                     asm.pshufd(vecDst, vecDst, 0);
 469                 }
 470                 break;
 471             case Short:
 472             case Char:
 473                 if (asm.supports(CPUFeature.AVX2)) {
 474                     VexRMOp.VPBROADCASTW.emit(asm, vectorSize, vecDst, vecDst);
 475                 } else if (asm.supports(CPUFeature.AVX)) {
 476                     VexRMIOp.VPSHUFLW.emit(asm, vectorSize, vecDst, vecDst, 0);
 477                     VexRMIOp.VPSHUFD.emit(asm, vectorSize, vecDst, vecDst, 0);
 478                 } else { // SSE
 479                     asm.pshuflw(vecDst, vecDst, 0);
 480                     asm.pshufd(vecDst, vecDst, 0);
 481                 }
 482                 break;
 483             case Int:
 484                 if (asm.supports(CPUFeature.AVX2)) {
 485                     VexRMOp.VPBROADCASTD.emit(asm, vectorSize, vecDst, vecDst);
 486                 } else if (asm.supports(CPUFeature.AVX)) {
 487                     VexRMIOp.VPSHUFD.emit(asm, vectorSize, vecDst, vecDst, 0);
 488                 } else { // SSE
 489                     asm.pshufd(vecDst, vecDst, 0);
 490                 }
 491                 break;
 492             default:
 493                 throw new UnsupportedOperationException();
 494         }
 495     }
 496 
 497     /**
 498      * Convert a byte offset stored in {@code bytes} to an array index offset.
 499      */
 500     private static void emitBytesToArraySlots(AMD64MacroAssembler asm, JavaKind kind, Register bytes) {
 501         if (charMode(kind)) {
 502             asm.shrl(bytes, 1);
 503         } else {
 504             assert byteMode(kind);
 505         }
 506     }
 507 
 508     private static void emitVectorCompare(AMD64MacroAssembler asm,
 509                     JavaKind kind,
 510                     AVXKind.AVXSize vectorSize,
 511                     int nValues,
 512                     int nVectors,
 513                     int[] vectorOffsets,
 514                     Register arrayPtr,
 515                     Register[] vecCmp,
 516                     Register[] vecArray,
 517                     Register[] cmpResult,
 518                     Label[] vectorFound,
 519                     boolean alignedLoad) {
 520         // load array contents into vectors
 521         for (int i = 0; i &lt; nValues; i++) {
 522             for (int j = 0; j &lt; nVectors; j++) {
 523                 emitArrayLoad(asm, vectorSize, vecArray[(i * nVectors) + j], arrayPtr, vectorOffsets[j], alignedLoad);
 524             }
 525         }
 526         // compare all loaded bytes to the search value.
 527         // matching bytes are set to 0xff, non-matching bytes are set to 0x00.
 528         for (int i = 0; i &lt; nValues; i++) {
 529             for (int j = 0; j &lt; nVectors; j++) {
 530                 emitVectorCompareInst(asm, kind, vectorSize, vecArray[(i * nVectors) + j], vecCmp[i]);
 531             }
 532         }
 533         // create 32-bit-masks from the most significant bit of every byte in the comparison
 534         // results.
 535         for (int i = 0; i &lt; nValues * nVectors; i++) {
 536             emitMOVMSK(asm, vectorSize, cmpResult[i], vecArray[i]);
 537         }
 538         // join results of comparisons against multiple values
 539         for (int stride = 1; stride &lt; nValues; stride *= 2) {
 540             for (int i = 0; i &lt; nVectors; i++) {
 541                 for (int j = 0; j + stride &lt; nValues; j += stride * 2) {
 542                     asm.orl(cmpResult[i + (j * nVectors)], cmpResult[i + ((j + stride) * nVectors)]);
 543                 }
 544             }
 545         }
 546         // check if a match was found
 547         for (int i = 0; i &lt; nVectors; i++) {
 548             asm.testl(cmpResult[i], cmpResult[i]);
 549             asm.jcc(AMD64Assembler.ConditionFlag.NotZero, vectorFound[i]);
 550         }
 551     }
 552 
 553     private static void emitVectorFoundWithOffset(AMD64MacroAssembler asm,
 554                     JavaKind kind,
 555                     int resultOffset,
 556                     Register result,
 557                     Register cmpResult,
 558                     Register slotsRemaining,
 559                     Label entry,
 560                     Label ret) {
 561         asm.bind(entry);
 562         if (resultOffset &gt; 0) {
 563             // adjust array pointer
 564             asm.addq(result, resultOffset);
 565             // adjust number of array slots remaining
 566             asm.subl(slotsRemaining, charMode(kind) ? resultOffset / 2 : resultOffset);
 567         }
 568         // find index of first set bit in bit mask
 569         asm.bsfq(cmpResult, cmpResult);
 570         // add offset to array pointer
 571         asm.addq(result, cmpResult);
 572         if (charMode(kind)) {
 573             // convert byte offset to chars
 574             asm.shrl(cmpResult, 1);
 575         }
 576         // adjust number of array slots remaining
 577         asm.subl(slotsRemaining, cmpResult);
 578         asm.jmpb(ret);
 579     }
 580 
 581     private static void emitArrayLoad(AMD64MacroAssembler asm, AVXKind.AVXSize vectorSize, Register vecDst, Register arrayPtr, int offset, boolean alignedLoad) {
 582         AMD64Address src = new AMD64Address(arrayPtr, offset);
 583         if (asm.supports(CPUFeature.AVX)) {
 584             VexMoveOp loadOp = alignedLoad ? VexMoveOp.VMOVDQA : VexMoveOp.VMOVDQU;
 585             loadOp.emit(asm, vectorSize, vecDst, src);
 586         } else {
 587             // SSE
 588             asm.movdqu(vecDst, src);
 589         }
 590     }
 591 
 592     /**
 593      * Compares all packed bytes/words/dwords in {@code vecArray} to {@code vecCmp}. Matching values
 594      * are set to all ones (0xff, 0xffff, ...), non-matching values are set to zero.
 595      */
 596     private static void emitVectorCompareInst(AMD64MacroAssembler asm, JavaKind kind, AVXKind.AVXSize vectorSize, Register vecArray, Register vecCmp) {
 597         switch (kind) {
 598             case Byte:
 599                 if (asm.supports(CPUFeature.AVX)) {
 600                     VexRVMOp.VPCMPEQB.emit(asm, vectorSize, vecArray, vecCmp, vecArray);
 601                 } else { // SSE
 602                     asm.pcmpeqb(vecArray, vecCmp);
 603                 }
 604                 break;
 605             case Short:
 606             case Char:
 607                 if (asm.supports(CPUFeature.AVX)) {
 608                     VexRVMOp.VPCMPEQW.emit(asm, vectorSize, vecArray, vecCmp, vecArray);
 609                 } else { // SSE
 610                     asm.pcmpeqw(vecArray, vecCmp);
 611                 }
 612                 break;
 613             case Int:
 614                 if (asm.supports(CPUFeature.AVX)) {
 615                     VexRVMOp.VPCMPEQD.emit(asm, vectorSize, vecArray, vecCmp, vecArray);
 616                 } else { // SSE
 617                     asm.pcmpeqd(vecArray, vecCmp);
 618                 }
 619                 break;
 620             default:
 621                 throw new UnsupportedOperationException();
 622         }
 623     }
 624 
 625     private static void emitMOVMSK(AMD64MacroAssembler asm, AVXKind.AVXSize vectorSize, Register dst, Register vecSrc) {
 626         if (asm.supports(CPUFeature.AVX)) {
 627             VexRMOp.VPMOVMSKB.emit(asm, vectorSize, dst, vecSrc);
 628         } else {
 629             // SSE
 630             asm.pmovmskb(dst, vecSrc);
 631         }
 632     }
 633 
 634     private static boolean supportsAVX2(LIRGeneratorTool tool) {
 635         return supports(tool, CPUFeature.AVX2);
 636     }
 637 
 638     private static boolean supports(LIRGeneratorTool tool, CPUFeature cpuFeature) {
 639         return ((AMD64) tool.target().arch).getFeatures().contains(cpuFeature);
 640     }
 641 }
</pre></body></html>
