<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta charset="utf-8">
<meta http-equiv="cache-control" content="no-cache" />
<meta http-equiv="Pragma" content="no-cache" />
<meta http-equiv="Expires" content="-1" />
<!--
   Note to customizers: the body of the webrev is IDed as SUNWwebrev
   to allow easy overriding by users of webrev via the userContent.css
   mechanism available in some browsers.

   For example, to have all "removed" information be red instead of
   brown, set a rule in your userContent.css file like:

       body#SUNWwebrev span.removed { color: red ! important; }
-->
<style type="text/css" media="screen">
body {
    background-color: #eeeeee;
}
hr {
    border: none 0;
    border-top: 1px solid #aaa;
    height: 1px;
}
div.summary {
    font-size: .8em;
    border-bottom: 1px solid #aaa;
    padding-left: 1em;
    padding-right: 1em;
}
div.summary h2 {
    margin-bottom: 0.3em;
}
div.summary table th {
    text-align: right;
    vertical-align: top;
    white-space: nowrap;
}
span.lineschanged {
    font-size: 0.7em;
}
span.oldmarker {
    color: red;
    font-size: large;
    font-weight: bold;
}
span.newmarker {
    color: green;
    font-size: large;
    font-weight: bold;
}
span.removed {
    color: brown;
}
span.changed {
    color: blue;
}
span.new {
    color: blue;
    font-weight: bold;
}
a.print { font-size: x-small; }

</style>

<style type="text/css" media="print">
pre { font-size: 0.8em; font-family: courier, monospace; }
span.removed { color: #444; font-style: italic }
span.changed { font-weight: bold; }
span.new { font-weight: bold; }
span.newmarker { font-size: 1.2em; font-weight: bold; }
span.oldmarker { font-size: 1.2em; font-weight: bold; }
a.print {display: none}
hr { border: none 0; border-top: 1px solid #aaa; height: 1px; }
</style>

<title>New src/share/vm/runtime/thread.cpp</title>
<body id="SUNWwebrev">
<pre>
   1 /*
   2  * Copyright (c) 1997, 2016, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #include "precompiled.hpp"
  26 #include "classfile/classLoader.hpp"
  27 #include "classfile/javaClasses.hpp"
  28 #include "classfile/moduleEntry.hpp"
  29 #include "classfile/systemDictionary.hpp"
  30 #include "classfile/vmSymbols.hpp"
  31 #include "code/codeCache.hpp"
  32 #include "code/codeCacheExtensions.hpp"
  33 #include "code/scopeDesc.hpp"
  34 #include "compiler/compileBroker.hpp"
  35 #include "compiler/compileTask.hpp"
  36 #include "gc/shared/gcId.hpp"
  37 #include "gc/shared/gcLocker.inline.hpp"
  38 #include "gc/shared/referencePendingListLocker.hpp"
  39 #include "gc/shared/workgroup.hpp"
  40 #include "interpreter/interpreter.hpp"
  41 #include "interpreter/linkResolver.hpp"
  42 #include "interpreter/oopMapCache.hpp"
  43 #include "jvmtifiles/jvmtiEnv.hpp"
  44 #include "logging/log.hpp"
  45 #include "logging/logConfiguration.hpp"
  46 #include "memory/metaspaceShared.hpp"
  47 #include "memory/oopFactory.hpp"
  48 #include "memory/resourceArea.hpp"
  49 #include "memory/universe.inline.hpp"
  50 #include "oops/instanceKlass.hpp"
  51 #include "oops/objArrayOop.hpp"
  52 #include "oops/oop.inline.hpp"
  53 #include "oops/symbol.hpp"
  54 #include "oops/verifyOopClosure.hpp"
  55 #include "prims/jvm_misc.hpp"
  56 #include "prims/jvmtiExport.hpp"
  57 #include "prims/jvmtiThreadState.hpp"
  58 #include "prims/privilegedStack.hpp"
  59 #include "runtime/arguments.hpp"
  60 #include "runtime/atomic.inline.hpp"
  61 #include "runtime/biasedLocking.hpp"
  62 #include "runtime/commandLineFlagConstraintList.hpp"
  63 #include "runtime/commandLineFlagRangeList.hpp"
  64 #include "runtime/deoptimization.hpp"
  65 #include "runtime/fprofiler.hpp"
  66 #include "runtime/frame.inline.hpp"
  67 #include "runtime/globals.hpp"
  68 #include "runtime/init.hpp"
  69 #include "runtime/interfaceSupport.hpp"
  70 #include "runtime/java.hpp"
  71 #include "runtime/javaCalls.hpp"
  72 #include "runtime/jniPeriodicChecker.hpp"
  73 #include "runtime/timerTrace.hpp"
  74 #include "runtime/memprofiler.hpp"
  75 #include "runtime/mutexLocker.hpp"
  76 #include "runtime/objectMonitor.hpp"
  77 #include "runtime/orderAccess.inline.hpp"
  78 #include "runtime/osThread.hpp"
  79 #include "runtime/safepoint.hpp"
  80 #include "runtime/sharedRuntime.hpp"
  81 #include "runtime/statSampler.hpp"
  82 #include "runtime/stubRoutines.hpp"
  83 #include "runtime/sweeper.hpp"
  84 #include "runtime/task.hpp"
  85 #include "runtime/thread.inline.hpp"
  86 #include "runtime/threadCritical.hpp"
  87 #include "runtime/vframe.hpp"
  88 #include "runtime/vframeArray.hpp"
  89 #include "runtime/vframe_hp.hpp"
  90 #include "runtime/vmThread.hpp"
  91 #include "runtime/vm_operations.hpp"
  92 #include "runtime/vm_version.hpp"
  93 #include "services/attachListener.hpp"
  94 #include "services/management.hpp"
  95 #include "services/memTracker.hpp"
  96 #include "services/threadService.hpp"
  97 #include "trace/traceMacros.hpp"
  98 #include "trace/tracing.hpp"
  99 #include "utilities/defaultStream.hpp"
 100 #include "utilities/dtrace.hpp"
 101 #include "utilities/events.hpp"
 102 #include "utilities/macros.hpp"
 103 #include "utilities/preserveException.hpp"
 104 #if INCLUDE_ALL_GCS
 105 #include "gc/cms/concurrentMarkSweepThread.hpp"
 106 #include "gc/g1/concurrentMarkThread.inline.hpp"
 107 #include "gc/parallel/pcTasks.hpp"
 108 #endif // INCLUDE_ALL_GCS
 109 #if INCLUDE_JVMCI
 110 #include "jvmci/jvmciCompiler.hpp"
 111 #include "jvmci/jvmciRuntime.hpp"
 112 #endif
 113 #ifdef COMPILER1
 114 #include "c1/c1_Compiler.hpp"
 115 #endif
 116 #ifdef COMPILER2
 117 #include "opto/c2compiler.hpp"
 118 #include "opto/idealGraphPrinter.hpp"
 119 #endif
 120 #if INCLUDE_RTM_OPT
 121 #include "runtime/rtmLocking.hpp"
 122 #endif
 123 
 124 // Initialization after module runtime initialization
 125 void universe_post_module_init();  // must happen after call_initPhase2
 126 
 127 #ifdef DTRACE_ENABLED
 128 
 129 // Only bother with this argument setup if dtrace is available
 130 
 131   #define HOTSPOT_THREAD_PROBE_start HOTSPOT_THREAD_START
 132   #define HOTSPOT_THREAD_PROBE_stop HOTSPOT_THREAD_STOP
 133 
 134   #define DTRACE_THREAD_PROBE(probe, javathread)                           \
 135     {                                                                      \
 136       ResourceMark rm(this);                                               \
 137       int len = 0;                                                         \
 138       const char* name = (javathread)-&gt;get_thread_name();                  \
 139       len = strlen(name);                                                  \
 140       HOTSPOT_THREAD_PROBE_##probe(/* probe = start, stop */               \
 141         (char *) name, len,                                                \
 142         java_lang_Thread::thread_id((javathread)-&gt;threadObj()),            \
 143         (uintptr_t) (javathread)-&gt;osthread()-&gt;thread_id(),                 \
 144         java_lang_Thread::is_daemon((javathread)-&gt;threadObj()));           \
 145     }
 146 
 147 #else //  ndef DTRACE_ENABLED
 148 
 149   #define DTRACE_THREAD_PROBE(probe, javathread)
 150 
 151 #endif // ndef DTRACE_ENABLED
 152 
 153 #ifndef USE_LIBRARY_BASED_TLS_ONLY
 154 // Current thread is maintained as a thread-local variable
 155 THREAD_LOCAL_DECL Thread* Thread::_thr_current = NULL;
 156 #endif
 157 // Class hierarchy
 158 // - Thread
 159 //   - VMThread
 160 //   - WatcherThread
 161 //   - ConcurrentMarkSweepThread
 162 //   - JavaThread
 163 //     - CompilerThread
 164 
 165 // ======= Thread ========
 166 // Support for forcing alignment of thread objects for biased locking
 167 void* Thread::allocate(size_t size, bool throw_excpt, MEMFLAGS flags) {
 168   if (UseBiasedLocking) {
 169     const int alignment = markOopDesc::biased_lock_alignment;
 170     size_t aligned_size = size + (alignment - sizeof(intptr_t));
 171     void* real_malloc_addr = throw_excpt? AllocateHeap(aligned_size, flags, CURRENT_PC)
 172                                           : AllocateHeap(aligned_size, flags, CURRENT_PC,
 173                                                          AllocFailStrategy::RETURN_NULL);
 174     void* aligned_addr     = (void*) align_size_up((intptr_t) real_malloc_addr, alignment);
 175     assert(((uintptr_t) aligned_addr + (uintptr_t) size) &lt;=
 176            ((uintptr_t) real_malloc_addr + (uintptr_t) aligned_size),
 177            "JavaThread alignment code overflowed allocated storage");
 178     if (aligned_addr != real_malloc_addr) {
 179       log_info(biasedlocking)("Aligned thread " INTPTR_FORMAT " to " INTPTR_FORMAT,
 180                               p2i(real_malloc_addr),
 181                               p2i(aligned_addr));
 182     }
 183     ((Thread*) aligned_addr)-&gt;_real_malloc_address = real_malloc_addr;
 184     return aligned_addr;
 185   } else {
 186     return throw_excpt? AllocateHeap(size, flags, CURRENT_PC)
 187                        : AllocateHeap(size, flags, CURRENT_PC, AllocFailStrategy::RETURN_NULL);
 188   }
 189 }
 190 
 191 void Thread::operator delete(void* p) {
 192   if (UseBiasedLocking) {
 193     void* real_malloc_addr = ((Thread*) p)-&gt;_real_malloc_address;
 194     FreeHeap(real_malloc_addr);
 195   } else {
 196     FreeHeap(p);
 197   }
 198 }
 199 
 200 
 201 // Base class for all threads: VMThread, WatcherThread, ConcurrentMarkSweepThread,
 202 // JavaThread
 203 
 204 
 205 Thread::Thread() {
 206   // stack and get_thread
 207   set_stack_base(NULL);
 208   set_stack_size(0);
 209   set_self_raw_id(0);
 210   set_lgrp_id(-1);
 211   DEBUG_ONLY(clear_suspendible_thread();)
 212 
 213   // allocated data structures
 214   set_osthread(NULL);
 215   set_resource_area(new (mtThread)ResourceArea());
 216   DEBUG_ONLY(_current_resource_mark = NULL;)
 217   set_handle_area(new (mtThread) HandleArea(NULL));
 218   set_metadata_handles(new (ResourceObj::C_HEAP, mtClass) GrowableArray&lt;Metadata*&gt;(30, true));
 219   set_active_handles(NULL);
 220   set_free_handle_block(NULL);
 221   set_last_handle_mark(NULL);
 222 
 223   // This initial value ==&gt; never claimed.
 224   _oops_do_parity = 0;
 225 
 226   // the handle mark links itself to last_handle_mark
 227   new HandleMark(this);
 228 
 229   // plain initialization
 230   debug_only(_owned_locks = NULL;)
 231   debug_only(_allow_allocation_count = 0;)
 232   NOT_PRODUCT(_allow_safepoint_count = 0;)
 233   NOT_PRODUCT(_skip_gcalot = false;)
 234   _jvmti_env_iteration_count = 0;
 235   set_allocated_bytes(0);
 236   _vm_operation_started_count = 0;
 237   _vm_operation_completed_count = 0;
 238   _current_pending_monitor = NULL;
 239   _current_pending_monitor_is_from_java = true;
 240   _current_waiting_monitor = NULL;
 241   _num_nested_signal = 0;
 242   omFreeList = NULL;
 243   omFreeCount = 0;
 244   omFreeProvision = 32;
 245   omInUseList = NULL;
 246   omInUseCount = 0;
 247 
 248 #ifdef ASSERT
 249   _visited_for_critical_count = false;
 250 #endif
 251 
 252   _SR_lock = new Monitor(Mutex::suspend_resume, "SR_lock", true,
 253                          Monitor::_safepoint_check_sometimes);
 254   _suspend_flags = 0;
 255 
 256   // thread-specific hashCode stream generator state - Marsaglia shift-xor form
 257   _hashStateX = os::random();
 258   _hashStateY = 842502087;
 259   _hashStateZ = 0x8767;    // (int)(3579807591LL &amp; 0xffff) ;
 260   _hashStateW = 273326509;
 261 
 262   _OnTrap   = 0;
 263   _schedctl = NULL;
 264   _Stalled  = 0;
 265   _TypeTag  = 0x2BAD;
 266 
 267   // Many of the following fields are effectively final - immutable
 268   // Note that nascent threads can't use the Native Monitor-Mutex
 269   // construct until the _MutexEvent is initialized ...
 270   // CONSIDER: instead of using a fixed set of purpose-dedicated ParkEvents
 271   // we might instead use a stack of ParkEvents that we could provision on-demand.
 272   // The stack would act as a cache to avoid calls to ParkEvent::Allocate()
 273   // and ::Release()
 274   _ParkEvent   = ParkEvent::Allocate(this);
 275   _SleepEvent  = ParkEvent::Allocate(this);
 276   _MutexEvent  = ParkEvent::Allocate(this);
 277   _MuxEvent    = ParkEvent::Allocate(this);
 278 
 279 #ifdef CHECK_UNHANDLED_OOPS
 280   if (CheckUnhandledOops) {
 281     _unhandled_oops = new UnhandledOops(this);
 282   }
 283 #endif // CHECK_UNHANDLED_OOPS
 284 #ifdef ASSERT
 285   if (UseBiasedLocking) {
 286     assert((((uintptr_t) this) &amp; (markOopDesc::biased_lock_alignment - 1)) == 0, "forced alignment of thread object failed");
 287     assert(this == _real_malloc_address ||
 288            this == (void*) align_size_up((intptr_t) _real_malloc_address, markOopDesc::biased_lock_alignment),
 289            "bug in forced alignment of thread objects");
 290   }
 291 #endif // ASSERT
 292 }
 293 
 294 void Thread::initialize_thread_current() {
 295 #ifndef USE_LIBRARY_BASED_TLS_ONLY
 296   assert(_thr_current == NULL, "Thread::current already initialized");
 297   _thr_current = this;
 298 #endif
 299   assert(ThreadLocalStorage::thread() == NULL, "ThreadLocalStorage::thread already initialized");
 300   ThreadLocalStorage::set_thread(this);
 301   assert(Thread::current() == ThreadLocalStorage::thread(), "TLS mismatch!");
 302 }
 303 
 304 void Thread::clear_thread_current() {
 305   assert(Thread::current() == ThreadLocalStorage::thread(), "TLS mismatch!");
 306 #ifndef USE_LIBRARY_BASED_TLS_ONLY
 307   _thr_current = NULL;
 308 #endif
 309   ThreadLocalStorage::set_thread(NULL);
 310 }
 311 
 312 void Thread::record_stack_base_and_size() {
 313   set_stack_base(os::current_stack_base());
 314   set_stack_size(os::current_stack_size());
 315   // CR 7190089: on Solaris, primordial thread's stack is adjusted
 316   // in initialize_thread(). Without the adjustment, stack size is
 317   // incorrect if stack is set to unlimited (ulimit -s unlimited).
 318   // So far, only Solaris has real implementation of initialize_thread().
 319   //
 320   // set up any platform-specific state.
 321   os::initialize_thread(this);
 322 
 323   // Set stack limits after thread is initialized.
 324   if (is_Java_thread()) {
 325     ((JavaThread*) this)-&gt;set_stack_overflow_limit();
 326     ((JavaThread*) this)-&gt;set_reserved_stack_activation(stack_base());
 327   }
 328 #if INCLUDE_NMT
 329   // record thread's native stack, stack grows downward
 330   MemTracker::record_thread_stack(stack_end(), stack_size());
 331 #endif // INCLUDE_NMT
 332   log_debug(os, thread)("Thread " UINTX_FORMAT " stack dimensions: "
 333     PTR_FORMAT "-" PTR_FORMAT " (" SIZE_FORMAT "k).",
 334     os::current_thread_id(), p2i(stack_base() - stack_size()),
 335     p2i(stack_base()), stack_size()/1024);
 336 }
 337 
 338 
 339 Thread::~Thread() {
 340   // Reclaim the objectmonitors from the omFreeList of the moribund thread.
 341   ObjectSynchronizer::omFlush(this);
 342 
 343   EVENT_THREAD_DESTRUCT(this);
 344 
 345   // stack_base can be NULL if the thread is never started or exited before
 346   // record_stack_base_and_size called. Although, we would like to ensure
 347   // that all started threads do call record_stack_base_and_size(), there is
 348   // not proper way to enforce that.
 349 #if INCLUDE_NMT
 350   if (_stack_base != NULL) {
 351     MemTracker::release_thread_stack(stack_end(), stack_size());
 352 #ifdef ASSERT
 353     set_stack_base(NULL);
 354 #endif
 355   }
 356 #endif // INCLUDE_NMT
 357 
 358   // deallocate data structures
 359   delete resource_area();
 360   // since the handle marks are using the handle area, we have to deallocated the root
 361   // handle mark before deallocating the thread's handle area,
 362   assert(last_handle_mark() != NULL, "check we have an element");
 363   delete last_handle_mark();
 364   assert(last_handle_mark() == NULL, "check we have reached the end");
 365 
 366   // It's possible we can encounter a null _ParkEvent, etc., in stillborn threads.
 367   // We NULL out the fields for good hygiene.
 368   ParkEvent::Release(_ParkEvent); _ParkEvent   = NULL;
 369   ParkEvent::Release(_SleepEvent); _SleepEvent  = NULL;
 370   ParkEvent::Release(_MutexEvent); _MutexEvent  = NULL;
 371   ParkEvent::Release(_MuxEvent); _MuxEvent    = NULL;
 372 
 373   delete handle_area();
 374   delete metadata_handles();
 375 
 376   // osthread() can be NULL, if creation of thread failed.
 377   if (osthread() != NULL) os::free_thread(osthread());
 378 
 379   delete _SR_lock;
 380 
 381   // clear Thread::current if thread is deleting itself.
 382   // Needed to ensure JNI correctly detects non-attached threads.
 383   if (this == Thread::current()) {
 384     clear_thread_current();
 385   }
 386 
 387   CHECK_UNHANDLED_OOPS_ONLY(if (CheckUnhandledOops) delete unhandled_oops();)
 388 }
 389 
 390 // NOTE: dummy function for assertion purpose.
 391 void Thread::run() {
 392   ShouldNotReachHere();
 393 }
 394 
 395 #ifdef ASSERT
 396 // Private method to check for dangling thread pointer
 397 void check_for_dangling_thread_pointer(Thread *thread) {
 398   assert(!thread-&gt;is_Java_thread() || Thread::current() == thread || Threads_lock-&gt;owned_by_self(),
 399          "possibility of dangling Thread pointer");
 400 }
 401 #endif
 402 
 403 ThreadPriority Thread::get_priority(const Thread* const thread) {
 404   ThreadPriority priority;
 405   // Can return an error!
 406   (void)os::get_priority(thread, priority);
 407   assert(MinPriority &lt;= priority &amp;&amp; priority &lt;= MaxPriority, "non-Java priority found");
 408   return priority;
 409 }
 410 
 411 void Thread::set_priority(Thread* thread, ThreadPriority priority) {
 412   debug_only(check_for_dangling_thread_pointer(thread);)
 413   // Can return an error!
 414   (void)os::set_priority(thread, priority);
 415 }
 416 
 417 
 418 void Thread::start(Thread* thread) {
 419   // Start is different from resume in that its safety is guaranteed by context or
 420   // being called from a Java method synchronized on the Thread object.
 421   if (!DisableStartThread) {
 422     if (thread-&gt;is_Java_thread()) {
 423       // Initialize the thread state to RUNNABLE before starting this thread.
 424       // Can not set it after the thread started because we do not know the
 425       // exact thread state at that time. It could be in MONITOR_WAIT or
 426       // in SLEEPING or some other state.
 427       java_lang_Thread::set_thread_status(((JavaThread*)thread)-&gt;threadObj(),
 428                                           java_lang_Thread::RUNNABLE);
 429     }
 430     os::start_thread(thread);
 431   }
 432 }
 433 
 434 // Enqueue a VM_Operation to do the job for us - sometime later
 435 void Thread::send_async_exception(oop java_thread, oop java_throwable) {
 436   VM_ThreadStop* vm_stop = new VM_ThreadStop(java_thread, java_throwable);
 437   VMThread::execute(vm_stop);
 438 }
 439 
 440 
 441 // Check if an external suspend request has completed (or has been
 442 // cancelled). Returns true if the thread is externally suspended and
 443 // false otherwise.
 444 //
 445 // The bits parameter returns information about the code path through
 446 // the routine. Useful for debugging:
 447 //
 448 // set in is_ext_suspend_completed():
 449 // 0x00000001 - routine was entered
 450 // 0x00000010 - routine return false at end
 451 // 0x00000100 - thread exited (return false)
 452 // 0x00000200 - suspend request cancelled (return false)
 453 // 0x00000400 - thread suspended (return true)
 454 // 0x00001000 - thread is in a suspend equivalent state (return true)
 455 // 0x00002000 - thread is native and walkable (return true)
 456 // 0x00004000 - thread is native_trans and walkable (needed retry)
 457 //
 458 // set in wait_for_ext_suspend_completion():
 459 // 0x00010000 - routine was entered
 460 // 0x00020000 - suspend request cancelled before loop (return false)
 461 // 0x00040000 - thread suspended before loop (return true)
 462 // 0x00080000 - suspend request cancelled in loop (return false)
 463 // 0x00100000 - thread suspended in loop (return true)
 464 // 0x00200000 - suspend not completed during retry loop (return false)
 465 
 466 // Helper class for tracing suspend wait debug bits.
 467 //
 468 // 0x00000100 indicates that the target thread exited before it could
 469 // self-suspend which is not a wait failure. 0x00000200, 0x00020000 and
 470 // 0x00080000 each indicate a cancelled suspend request so they don't
 471 // count as wait failures either.
 472 #define DEBUG_FALSE_BITS (0x00000010 | 0x00200000)
 473 
 474 class TraceSuspendDebugBits : public StackObj {
 475  private:
 476   JavaThread * jt;
 477   bool         is_wait;
 478   bool         called_by_wait;  // meaningful when !is_wait
 479   uint32_t *   bits;
 480 
 481  public:
 482   TraceSuspendDebugBits(JavaThread *_jt, bool _is_wait, bool _called_by_wait,
 483                         uint32_t *_bits) {
 484     jt             = _jt;
 485     is_wait        = _is_wait;
 486     called_by_wait = _called_by_wait;
 487     bits           = _bits;
 488   }
 489 
 490   ~TraceSuspendDebugBits() {
 491     if (!is_wait) {
 492 #if 1
 493       // By default, don't trace bits for is_ext_suspend_completed() calls.
 494       // That trace is very chatty.
 495       return;
 496 #else
 497       if (!called_by_wait) {
 498         // If tracing for is_ext_suspend_completed() is enabled, then only
 499         // trace calls to it from wait_for_ext_suspend_completion()
 500         return;
 501       }
 502 #endif
 503     }
 504 
 505     if (AssertOnSuspendWaitFailure || TraceSuspendWaitFailures) {
 506       if (bits != NULL &amp;&amp; (*bits &amp; DEBUG_FALSE_BITS) != 0) {
 507         MutexLocker ml(Threads_lock);  // needed for get_thread_name()
 508         ResourceMark rm;
 509 
 510         tty-&gt;print_cr(
 511                       "Failed wait_for_ext_suspend_completion(thread=%s, debug_bits=%x)",
 512                       jt-&gt;get_thread_name(), *bits);
 513 
 514         guarantee(!AssertOnSuspendWaitFailure, "external suspend wait failed");
 515       }
 516     }
 517   }
 518 };
 519 #undef DEBUG_FALSE_BITS
 520 
 521 
 522 bool JavaThread::is_ext_suspend_completed(bool called_by_wait, int delay,
 523                                           uint32_t *bits) {
 524   TraceSuspendDebugBits tsdb(this, false /* !is_wait */, called_by_wait, bits);
 525 
 526   bool did_trans_retry = false;  // only do thread_in_native_trans retry once
 527   bool do_trans_retry;           // flag to force the retry
 528 
 529   *bits |= 0x00000001;
 530 
 531   do {
 532     do_trans_retry = false;
 533 
 534     if (is_exiting()) {
 535       // Thread is in the process of exiting. This is always checked
 536       // first to reduce the risk of dereferencing a freed JavaThread.
 537       *bits |= 0x00000100;
 538       return false;
 539     }
 540 
 541     if (!is_external_suspend()) {
 542       // Suspend request is cancelled. This is always checked before
 543       // is_ext_suspended() to reduce the risk of a rogue resume
 544       // confusing the thread that made the suspend request.
 545       *bits |= 0x00000200;
 546       return false;
 547     }
 548 
 549     if (is_ext_suspended()) {
 550       // thread is suspended
 551       *bits |= 0x00000400;
 552       return true;
 553     }
 554 
 555     // Now that we no longer do hard suspends of threads running
 556     // native code, the target thread can be changing thread state
 557     // while we are in this routine:
 558     //
 559     //   _thread_in_native -&gt; _thread_in_native_trans -&gt; _thread_blocked
 560     //
 561     // We save a copy of the thread state as observed at this moment
 562     // and make our decision about suspend completeness based on the
 563     // copy. This closes the race where the thread state is seen as
 564     // _thread_in_native_trans in the if-thread_blocked check, but is
 565     // seen as _thread_blocked in if-thread_in_native_trans check.
 566     JavaThreadState save_state = thread_state();
 567 
 568     if (save_state == _thread_blocked &amp;&amp; is_suspend_equivalent()) {
 569       // If the thread's state is _thread_blocked and this blocking
 570       // condition is known to be equivalent to a suspend, then we can
 571       // consider the thread to be externally suspended. This means that
 572       // the code that sets _thread_blocked has been modified to do
 573       // self-suspension if the blocking condition releases. We also
 574       // used to check for CONDVAR_WAIT here, but that is now covered by
 575       // the _thread_blocked with self-suspension check.
 576       //
 577       // Return true since we wouldn't be here unless there was still an
 578       // external suspend request.
 579       *bits |= 0x00001000;
 580       return true;
 581     } else if (save_state == _thread_in_native &amp;&amp; frame_anchor()-&gt;walkable()) {
 582       // Threads running native code will self-suspend on native==&gt;VM/Java
 583       // transitions. If its stack is walkable (should always be the case
 584       // unless this function is called before the actual java_suspend()
 585       // call), then the wait is done.
 586       *bits |= 0x00002000;
 587       return true;
 588     } else if (!called_by_wait &amp;&amp; !did_trans_retry &amp;&amp;
 589                save_state == _thread_in_native_trans &amp;&amp;
 590                frame_anchor()-&gt;walkable()) {
 591       // The thread is transitioning from thread_in_native to another
 592       // thread state. check_safepoint_and_suspend_for_native_trans()
 593       // will force the thread to self-suspend. If it hasn't gotten
 594       // there yet we may have caught the thread in-between the native
 595       // code check above and the self-suspend. Lucky us. If we were
 596       // called by wait_for_ext_suspend_completion(), then it
 597       // will be doing the retries so we don't have to.
 598       //
 599       // Since we use the saved thread state in the if-statement above,
 600       // there is a chance that the thread has already transitioned to
 601       // _thread_blocked by the time we get here. In that case, we will
 602       // make a single unnecessary pass through the logic below. This
 603       // doesn't hurt anything since we still do the trans retry.
 604 
 605       *bits |= 0x00004000;
 606 
 607       // Once the thread leaves thread_in_native_trans for another
 608       // thread state, we break out of this retry loop. We shouldn't
 609       // need this flag to prevent us from getting back here, but
 610       // sometimes paranoia is good.
 611       did_trans_retry = true;
 612 
 613       // We wait for the thread to transition to a more usable state.
 614       for (int i = 1; i &lt;= SuspendRetryCount; i++) {
 615         // We used to do an "os::yield_all(i)" call here with the intention
 616         // that yielding would increase on each retry. However, the parameter
 617         // is ignored on Linux which means the yield didn't scale up. Waiting
 618         // on the SR_lock below provides a much more predictable scale up for
 619         // the delay. It also provides a simple/direct point to check for any
 620         // safepoint requests from the VMThread
 621 
 622         // temporarily drops SR_lock while doing wait with safepoint check
 623         // (if we're a JavaThread - the WatcherThread can also call this)
 624         // and increase delay with each retry
 625         SR_lock()-&gt;wait(!Thread::current()-&gt;is_Java_thread(), i * delay);
 626 
 627         // check the actual thread state instead of what we saved above
 628         if (thread_state() != _thread_in_native_trans) {
 629           // the thread has transitioned to another thread state so
 630           // try all the checks (except this one) one more time.
 631           do_trans_retry = true;
 632           break;
 633         }
 634       } // end retry loop
 635 
 636 
 637     }
 638   } while (do_trans_retry);
 639 
 640   *bits |= 0x00000010;
 641   return false;
 642 }
 643 
 644 // Wait for an external suspend request to complete (or be cancelled).
 645 // Returns true if the thread is externally suspended and false otherwise.
 646 //
 647 bool JavaThread::wait_for_ext_suspend_completion(int retries, int delay,
 648                                                  uint32_t *bits) {
 649   TraceSuspendDebugBits tsdb(this, true /* is_wait */,
 650                              false /* !called_by_wait */, bits);
 651 
 652   // local flag copies to minimize SR_lock hold time
 653   bool is_suspended;
 654   bool pending;
 655   uint32_t reset_bits;
 656 
 657   // set a marker so is_ext_suspend_completed() knows we are the caller
 658   *bits |= 0x00010000;
 659 
 660   // We use reset_bits to reinitialize the bits value at the top of
 661   // each retry loop. This allows the caller to make use of any
 662   // unused bits for their own marking purposes.
 663   reset_bits = *bits;
 664 
 665   {
 666     MutexLockerEx ml(SR_lock(), Mutex::_no_safepoint_check_flag);
 667     is_suspended = is_ext_suspend_completed(true /* called_by_wait */,
 668                                             delay, bits);
 669     pending = is_external_suspend();
 670   }
 671   // must release SR_lock to allow suspension to complete
 672 
 673   if (!pending) {
 674     // A cancelled suspend request is the only false return from
 675     // is_ext_suspend_completed() that keeps us from entering the
 676     // retry loop.
 677     *bits |= 0x00020000;
 678     return false;
 679   }
 680 
 681   if (is_suspended) {
 682     *bits |= 0x00040000;
 683     return true;
 684   }
 685 
 686   for (int i = 1; i &lt;= retries; i++) {
 687     *bits = reset_bits;  // reinit to only track last retry
 688 
 689     // We used to do an "os::yield_all(i)" call here with the intention
 690     // that yielding would increase on each retry. However, the parameter
 691     // is ignored on Linux which means the yield didn't scale up. Waiting
 692     // on the SR_lock below provides a much more predictable scale up for
 693     // the delay. It also provides a simple/direct point to check for any
 694     // safepoint requests from the VMThread
 695 
 696     {
 697       MutexLocker ml(SR_lock());
 698       // wait with safepoint check (if we're a JavaThread - the WatcherThread
 699       // can also call this)  and increase delay with each retry
 700       SR_lock()-&gt;wait(!Thread::current()-&gt;is_Java_thread(), i * delay);
 701 
 702       is_suspended = is_ext_suspend_completed(true /* called_by_wait */,
 703                                               delay, bits);
 704 
 705       // It is possible for the external suspend request to be cancelled
 706       // (by a resume) before the actual suspend operation is completed.
 707       // Refresh our local copy to see if we still need to wait.
 708       pending = is_external_suspend();
 709     }
 710 
 711     if (!pending) {
 712       // A cancelled suspend request is the only false return from
 713       // is_ext_suspend_completed() that keeps us from staying in the
 714       // retry loop.
 715       *bits |= 0x00080000;
 716       return false;
 717     }
 718 
 719     if (is_suspended) {
 720       *bits |= 0x00100000;
 721       return true;
 722     }
 723   } // end retry loop
 724 
 725   // thread did not suspend after all our retries
 726   *bits |= 0x00200000;
 727   return false;
 728 }
 729 
 730 #ifndef PRODUCT
 731 void JavaThread::record_jump(address target, address instr, const char* file,
 732                              int line) {
 733 
 734   // This should not need to be atomic as the only way for simultaneous
 735   // updates is via interrupts. Even then this should be rare or non-existent
 736   // and we don't care that much anyway.
 737 
 738   int index = _jmp_ring_index;
 739   _jmp_ring_index = (index + 1) &amp; (jump_ring_buffer_size - 1);
 740   _jmp_ring[index]._target = (intptr_t) target;
 741   _jmp_ring[index]._instruction = (intptr_t) instr;
 742   _jmp_ring[index]._file = file;
 743   _jmp_ring[index]._line = line;
 744 }
 745 #endif // PRODUCT
 746 
 747 // Called by flat profiler
 748 // Callers have already called wait_for_ext_suspend_completion
 749 // The assertion for that is currently too complex to put here:
 750 bool JavaThread::profile_last_Java_frame(frame* _fr) {
 751   bool gotframe = false;
 752   // self suspension saves needed state.
 753   if (has_last_Java_frame() &amp;&amp; _anchor.walkable()) {
 754     *_fr = pd_last_frame();
 755     gotframe = true;
 756   }
 757   return gotframe;
 758 }
 759 
 760 void Thread::interrupt(Thread* thread) {
 761   debug_only(check_for_dangling_thread_pointer(thread);)
 762   os::interrupt(thread);
 763 }
 764 
 765 bool Thread::is_interrupted(Thread* thread, bool clear_interrupted) {
 766   debug_only(check_for_dangling_thread_pointer(thread);)
 767   // Note:  If clear_interrupted==false, this simply fetches and
 768   // returns the value of the field osthread()-&gt;interrupted().
 769   return os::is_interrupted(thread, clear_interrupted);
 770 }
 771 
 772 
 773 // GC Support
 774 bool Thread::claim_oops_do_par_case(int strong_roots_parity) {
 775   jint thread_parity = _oops_do_parity;
 776   if (thread_parity != strong_roots_parity) {
 777     jint res = Atomic::cmpxchg(strong_roots_parity, &amp;_oops_do_parity, thread_parity);
 778     if (res == thread_parity) {
 779       return true;
 780     } else {
 781       guarantee(res == strong_roots_parity, "Or else what?");
 782       return false;
 783     }
 784   }
 785   return false;
 786 }
 787 
 788 void Thread::oops_do(OopClosure* f, CodeBlobClosure* cf) {
 789   active_handles()-&gt;oops_do(f);
 790   // Do oop for ThreadShadow
 791   f-&gt;do_oop((oop*)&amp;_pending_exception);
 792   handle_area()-&gt;oops_do(f);
 793 }
 794 
 795 void Thread::metadata_handles_do(void f(Metadata*)) {
 796   // Only walk the Handles in Thread.
 797   if (metadata_handles() != NULL) {
 798     for (int i = 0; i&lt; metadata_handles()-&gt;length(); i++) {
 799       f(metadata_handles()-&gt;at(i));
 800     }
 801   }
 802 }
 803 
 804 void Thread::print_on(outputStream* st) const {
 805   // get_priority assumes osthread initialized
 806   if (osthread() != NULL) {
 807     int os_prio;
 808     if (os::get_native_priority(this, &amp;os_prio) == OS_OK) {
 809       st-&gt;print("os_prio=%d ", os_prio);
 810     }
 811     st-&gt;print("tid=" INTPTR_FORMAT " ", p2i(this));
 812     ext().print_on(st);
 813     osthread()-&gt;print_on(st);
 814   }
 815   debug_only(if (WizardMode) print_owned_locks_on(st);)
 816 }
 817 
 818 // Thread::print_on_error() is called by fatal error handler. Don't use
 819 // any lock or allocate memory.
 820 void Thread::print_on_error(outputStream* st, char* buf, int buflen) const {
 821   assert(!(is_Compiler_thread() || is_Java_thread()), "Can't call name() here if it allocates");
 822 
 823   if (is_VM_thread())                 { st-&gt;print("VMThread"); }
 824   else if (is_GC_task_thread())       { st-&gt;print("GCTaskThread"); }
 825   else if (is_Watcher_thread())       { st-&gt;print("WatcherThread"); }
 826   else if (is_ConcurrentGC_thread())  { st-&gt;print("ConcurrentGCThread"); }
 827   else                                { st-&gt;print("Thread"); }
 828 
 829   if (is_Named_thread()) {
 830     st-&gt;print(" \"%s\"", name());
 831   }
 832 
 833   st-&gt;print(" [stack: " PTR_FORMAT "," PTR_FORMAT "]",
 834             p2i(stack_end()), p2i(stack_base()));
 835 
 836   if (osthread()) {
 837     st-&gt;print(" [id=%d]", osthread()-&gt;thread_id());
 838   }
 839 }
 840 
 841 #ifdef ASSERT
 842 void Thread::print_owned_locks_on(outputStream* st) const {
 843   Monitor *cur = _owned_locks;
 844   if (cur == NULL) {
 845     st-&gt;print(" (no locks) ");
 846   } else {
 847     st-&gt;print_cr(" Locks owned:");
 848     while (cur) {
 849       cur-&gt;print_on(st);
 850       cur = cur-&gt;next();
 851     }
 852   }
 853 }
 854 
 855 static int ref_use_count  = 0;
 856 
 857 bool Thread::owns_locks_but_compiled_lock() const {
 858   for (Monitor *cur = _owned_locks; cur; cur = cur-&gt;next()) {
 859     if (cur != Compile_lock) return true;
 860   }
 861   return false;
 862 }
 863 
 864 
 865 #endif
 866 
 867 #ifndef PRODUCT
 868 
 869 // The flag: potential_vm_operation notifies if this particular safepoint state could potential
 870 // invoke the vm-thread (i.e., and oop allocation). In that case, we also have to make sure that
 871 // no threads which allow_vm_block's are held
 872 void Thread::check_for_valid_safepoint_state(bool potential_vm_operation) {
 873   // Check if current thread is allowed to block at a safepoint
 874   if (!(_allow_safepoint_count == 0)) {
 875     fatal("Possible safepoint reached by thread that does not allow it");
 876   }
 877   if (is_Java_thread() &amp;&amp; ((JavaThread*)this)-&gt;thread_state() != _thread_in_vm) {
 878     fatal("LEAF method calling lock?");
 879   }
 880 
 881 #ifdef ASSERT
 882   if (potential_vm_operation &amp;&amp; is_Java_thread()
 883       &amp;&amp; !Universe::is_bootstrapping()) {
 884     // Make sure we do not hold any locks that the VM thread also uses.
 885     // This could potentially lead to deadlocks
 886     for (Monitor *cur = _owned_locks; cur; cur = cur-&gt;next()) {
 887       // Threads_lock is special, since the safepoint synchronization will not start before this is
 888       // acquired. Hence, a JavaThread cannot be holding it at a safepoint. So is VMOperationRequest_lock,
 889       // since it is used to transfer control between JavaThreads and the VMThread
 890       // Do not *exclude* any locks unless you are absolutely sure it is correct. Ask someone else first!
 891       if ((cur-&gt;allow_vm_block() &amp;&amp;
 892            cur != Threads_lock &amp;&amp;
 893            cur != Compile_lock &amp;&amp;               // Temporary: should not be necessary when we get separate compilation
 894            cur != VMOperationRequest_lock &amp;&amp;
 895            cur != VMOperationQueue_lock) ||
 896            cur-&gt;rank() == Mutex::special) {
 897         fatal("Thread holding lock at safepoint that vm can block on: %s", cur-&gt;name());
 898       }
 899     }
 900   }
 901 
 902   if (GCALotAtAllSafepoints) {
 903     // We could enter a safepoint here and thus have a gc
 904     InterfaceSupport::check_gc_alot();
 905   }
 906 #endif
 907 }
 908 #endif
 909 
 910 bool Thread::is_in_stack(address adr) const {
 911   assert(Thread::current() == this, "is_in_stack can only be called from current thread");
 912   address end = os::current_stack_pointer();
 913   // Allow non Java threads to call this without stack_base
 914   if (_stack_base == NULL) return true;
 915   if (stack_base() &gt;= adr &amp;&amp; adr &gt;= end) return true;
 916 
 917   return false;
 918 }
 919 
 920 bool Thread::is_in_usable_stack(address adr) const {
 921   size_t stack_guard_size = os::uses_stack_guard_pages() ? JavaThread::stack_guard_zone_size() : 0;
 922   size_t usable_stack_size = _stack_size - stack_guard_size;
 923 
 924   return ((adr &lt; stack_base()) &amp;&amp; (adr &gt;= stack_base() - usable_stack_size));
 925 }
 926 
 927 
 928 // We had to move these methods here, because vm threads get into ObjectSynchronizer::enter
 929 // However, there is a note in JavaThread::is_lock_owned() about the VM threads not being
 930 // used for compilation in the future. If that change is made, the need for these methods
 931 // should be revisited, and they should be removed if possible.
 932 
 933 bool Thread::is_lock_owned(address adr) const {
 934   return on_local_stack(adr);
 935 }
 936 
 937 bool Thread::set_as_starting_thread() {
 938   // NOTE: this must be called inside the main thread.
 939   return os::create_main_thread((JavaThread*)this);
 940 }
 941 
 942 static void initialize_class(Symbol* class_name, TRAPS) {
 943   Klass* klass = SystemDictionary::resolve_or_fail(class_name, true, CHECK);
 944   InstanceKlass::cast(klass)-&gt;initialize(CHECK);
 945 }
 946 
 947 
 948 // Creates the initial ThreadGroup
 949 static Handle create_initial_thread_group(TRAPS) {
 950   Klass* k = SystemDictionary::resolve_or_fail(vmSymbols::java_lang_ThreadGroup(), true, CHECK_NH);
 951   instanceKlassHandle klass (THREAD, k);
 952 
 953   Handle system_instance = klass-&gt;allocate_instance_handle(CHECK_NH);
 954   {
 955     JavaValue result(T_VOID);
 956     JavaCalls::call_special(&amp;result,
 957                             system_instance,
 958                             klass,
 959                             vmSymbols::object_initializer_name(),
 960                             vmSymbols::void_method_signature(),
 961                             CHECK_NH);
 962   }
 963   Universe::set_system_thread_group(system_instance());
 964 
 965   Handle main_instance = klass-&gt;allocate_instance_handle(CHECK_NH);
 966   {
 967     JavaValue result(T_VOID);
 968     Handle string = java_lang_String::create_from_str("main", CHECK_NH);
 969     JavaCalls::call_special(&amp;result,
 970                             main_instance,
 971                             klass,
 972                             vmSymbols::object_initializer_name(),
 973                             vmSymbols::threadgroup_string_void_signature(),
 974                             system_instance,
 975                             string,
 976                             CHECK_NH);
 977   }
 978   return main_instance;
 979 }
 980 
 981 // Creates the initial Thread
 982 static oop create_initial_thread(Handle thread_group, JavaThread* thread,
 983                                  TRAPS) {
 984   Klass* k = SystemDictionary::resolve_or_fail(vmSymbols::java_lang_Thread(), true, CHECK_NULL);
 985   instanceKlassHandle klass (THREAD, k);
 986   instanceHandle thread_oop = klass-&gt;allocate_instance_handle(CHECK_NULL);
 987 
 988   java_lang_Thread::set_thread(thread_oop(), thread);
 989   java_lang_Thread::set_priority(thread_oop(), NormPriority);
 990   thread-&gt;set_threadObj(thread_oop());
 991 
 992   Handle string = java_lang_String::create_from_str("main", CHECK_NULL);
 993 
 994   JavaValue result(T_VOID);
 995   JavaCalls::call_special(&amp;result, thread_oop,
 996                           klass,
 997                           vmSymbols::object_initializer_name(),
 998                           vmSymbols::threadgroup_string_void_signature(),
 999                           thread_group,
1000                           string,
1001                           CHECK_NULL);
1002   return thread_oop();
1003 }
1004 
1005 char java_runtime_name[128] = "";
1006 char java_runtime_version[128] = "";
1007 
1008 // extract the JRE name from java.lang.VersionProps.java_runtime_name
1009 static const char* get_java_runtime_name(TRAPS) {
1010   Klass* k = SystemDictionary::find(vmSymbols::java_lang_VersionProps(),
1011                                     Handle(), Handle(), CHECK_AND_CLEAR_NULL);
1012   fieldDescriptor fd;
1013   bool found = k != NULL &amp;&amp;
1014                InstanceKlass::cast(k)-&gt;find_local_field(vmSymbols::java_runtime_name_name(),
1015                                                         vmSymbols::string_signature(), &amp;fd);
1016   if (found) {
1017     oop name_oop = k-&gt;java_mirror()-&gt;obj_field(fd.offset());
1018     if (name_oop == NULL) {
1019       return NULL;
1020     }
1021     const char* name = java_lang_String::as_utf8_string(name_oop,
1022                                                         java_runtime_name,
1023                                                         sizeof(java_runtime_name));
1024     return name;
1025   } else {
1026     return NULL;
1027   }
1028 }
1029 
1030 // extract the JRE version from java.lang.VersionProps.java_runtime_version
1031 static const char* get_java_runtime_version(TRAPS) {
1032   Klass* k = SystemDictionary::find(vmSymbols::java_lang_VersionProps(),
1033                                     Handle(), Handle(), CHECK_AND_CLEAR_NULL);
1034   fieldDescriptor fd;
1035   bool found = k != NULL &amp;&amp;
1036                InstanceKlass::cast(k)-&gt;find_local_field(vmSymbols::java_runtime_version_name(),
1037                                                         vmSymbols::string_signature(), &amp;fd);
1038   if (found) {
1039     oop name_oop = k-&gt;java_mirror()-&gt;obj_field(fd.offset());
1040     if (name_oop == NULL) {
1041       return NULL;
1042     }
1043     const char* name = java_lang_String::as_utf8_string(name_oop,
1044                                                         java_runtime_version,
1045                                                         sizeof(java_runtime_version));
1046     return name;
1047   } else {
1048     return NULL;
1049   }
1050 }
1051 
1052 // General purpose hook into Java code, run once when the VM is initialized.
1053 // The Java library method itself may be changed independently from the VM.
1054 static void call_postVMInitHook(TRAPS) {
1055   Klass* k = SystemDictionary::resolve_or_null(vmSymbols::jdk_internal_vm_PostVMInitHook(), THREAD);
1056   instanceKlassHandle klass (THREAD, k);
1057   if (klass.not_null()) {
1058     JavaValue result(T_VOID);
1059     JavaCalls::call_static(&amp;result, klass, vmSymbols::run_method_name(),
1060                            vmSymbols::void_method_signature(),
1061                            CHECK);
1062   }
1063 }
1064 
1065 static void reset_vm_info_property(TRAPS) {
1066   // the vm info string
1067   ResourceMark rm(THREAD);
1068   const char *vm_info = VM_Version::vm_info_string();
1069 
1070   // java.lang.System class
1071   Klass* k =  SystemDictionary::resolve_or_fail(vmSymbols::java_lang_System(), true, CHECK);
1072   instanceKlassHandle klass (THREAD, k);
1073 
1074   // setProperty arguments
1075   Handle key_str    = java_lang_String::create_from_str("java.vm.info", CHECK);
1076   Handle value_str  = java_lang_String::create_from_str(vm_info, CHECK);
1077 
1078   // return value
1079   JavaValue r(T_OBJECT);
1080 
1081   // public static String setProperty(String key, String value);
1082   JavaCalls::call_static(&amp;r,
1083                          klass,
1084                          vmSymbols::setProperty_name(),
1085                          vmSymbols::string_string_string_signature(),
1086                          key_str,
1087                          value_str,
1088                          CHECK);
1089 }
1090 
1091 
1092 void JavaThread::allocate_threadObj(Handle thread_group, const char* thread_name,
1093                                     bool daemon, TRAPS) {
1094   assert(thread_group.not_null(), "thread group should be specified");
1095   assert(threadObj() == NULL, "should only create Java thread object once");
1096 
1097   Klass* k = SystemDictionary::resolve_or_fail(vmSymbols::java_lang_Thread(), true, CHECK);
1098   instanceKlassHandle klass (THREAD, k);
1099   instanceHandle thread_oop = klass-&gt;allocate_instance_handle(CHECK);
1100 
1101   java_lang_Thread::set_thread(thread_oop(), this);
1102   java_lang_Thread::set_priority(thread_oop(), NormPriority);
1103   set_threadObj(thread_oop());
1104 
1105   JavaValue result(T_VOID);
1106   if (thread_name != NULL) {
1107     Handle name = java_lang_String::create_from_str(thread_name, CHECK);
1108     // Thread gets assigned specified name and null target
1109     JavaCalls::call_special(&amp;result,
1110                             thread_oop,
1111                             klass,
1112                             vmSymbols::object_initializer_name(),
1113                             vmSymbols::threadgroup_string_void_signature(),
1114                             thread_group, // Argument 1
1115                             name,         // Argument 2
1116                             THREAD);
1117   } else {
1118     // Thread gets assigned name "Thread-nnn" and null target
1119     // (java.lang.Thread doesn't have a constructor taking only a ThreadGroup argument)
1120     JavaCalls::call_special(&amp;result,
1121                             thread_oop,
1122                             klass,
1123                             vmSymbols::object_initializer_name(),
1124                             vmSymbols::threadgroup_runnable_void_signature(),
1125                             thread_group, // Argument 1
1126                             Handle(),     // Argument 2
1127                             THREAD);
1128   }
1129 
1130 
1131   if (daemon) {
1132     java_lang_Thread::set_daemon(thread_oop());
1133   }
1134 
1135   if (HAS_PENDING_EXCEPTION) {
1136     return;
1137   }
1138 
1139   KlassHandle group(THREAD, SystemDictionary::ThreadGroup_klass());
1140   Handle threadObj(THREAD, this-&gt;threadObj());
1141 
1142   JavaCalls::call_special(&amp;result,
1143                           thread_group,
1144                           group,
1145                           vmSymbols::add_method_name(),
1146                           vmSymbols::thread_void_signature(),
1147                           threadObj,          // Arg 1
1148                           THREAD);
1149 }
1150 
1151 // NamedThread --  non-JavaThread subclasses with multiple
1152 // uniquely named instances should derive from this.
1153 NamedThread::NamedThread() : Thread() {
1154   _name = NULL;
1155   _processed_thread = NULL;
1156   _gc_id = GCId::undefined();
1157 }
1158 
1159 NamedThread::~NamedThread() {
1160   if (_name != NULL) {
1161     FREE_C_HEAP_ARRAY(char, _name);
1162     _name = NULL;
1163   }
1164 }
1165 
1166 void NamedThread::set_name(const char* format, ...) {
1167   guarantee(_name == NULL, "Only get to set name once.");
1168   _name = NEW_C_HEAP_ARRAY(char, max_name_len, mtThread);
1169   guarantee(_name != NULL, "alloc failure");
1170   va_list ap;
1171   va_start(ap, format);
1172   jio_vsnprintf(_name, max_name_len, format, ap);
1173   va_end(ap);
1174 }
1175 
1176 void NamedThread::initialize_named_thread() {
1177   set_native_thread_name(name());
1178 }
1179 
1180 void NamedThread::print_on(outputStream* st) const {
1181   st-&gt;print("\"%s\" ", name());
1182   Thread::print_on(st);
1183   st-&gt;cr();
1184 }
1185 
1186 
1187 // ======= WatcherThread ========
1188 
1189 // The watcher thread exists to simulate timer interrupts.  It should
1190 // be replaced by an abstraction over whatever native support for
1191 // timer interrupts exists on the platform.
1192 
1193 WatcherThread* WatcherThread::_watcher_thread   = NULL;
1194 bool WatcherThread::_startable = false;
1195 volatile bool  WatcherThread::_should_terminate = false;
1196 
1197 WatcherThread::WatcherThread() : Thread(), _crash_protection(NULL) {
1198   assert(watcher_thread() == NULL, "we can only allocate one WatcherThread");
1199   if (os::create_thread(this, os::watcher_thread)) {
1200     _watcher_thread = this;
1201 
1202     // Set the watcher thread to the highest OS priority which should not be
1203     // used, unless a Java thread with priority java.lang.Thread.MAX_PRIORITY
1204     // is created. The only normal thread using this priority is the reference
1205     // handler thread, which runs for very short intervals only.
1206     // If the VMThread's priority is not lower than the WatcherThread profiling
1207     // will be inaccurate.
1208     os::set_priority(this, MaxPriority);
1209     if (!DisableStartThread) {
1210       os::start_thread(this);
1211     }
1212   }
1213 }
1214 
1215 int WatcherThread::sleep() const {
1216   // The WatcherThread does not participate in the safepoint protocol
1217   // for the PeriodicTask_lock because it is not a JavaThread.
1218   MutexLockerEx ml(PeriodicTask_lock, Mutex::_no_safepoint_check_flag);
1219 
1220   if (_should_terminate) {
1221     // check for termination before we do any housekeeping or wait
1222     return 0;  // we did not sleep.
1223   }
1224 
1225   // remaining will be zero if there are no tasks,
1226   // causing the WatcherThread to sleep until a task is
1227   // enrolled
1228   int remaining = PeriodicTask::time_to_wait();
1229   int time_slept = 0;
1230 
1231   // we expect this to timeout - we only ever get unparked when
1232   // we should terminate or when a new task has been enrolled
1233   OSThreadWaitState osts(this-&gt;osthread(), false /* not Object.wait() */);
1234 
1235   jlong time_before_loop = os::javaTimeNanos();
1236 
1237   while (true) {
1238     bool timedout = PeriodicTask_lock-&gt;wait(Mutex::_no_safepoint_check_flag,
1239                                             remaining);
1240     jlong now = os::javaTimeNanos();
1241 
1242     if (remaining == 0) {
1243       // if we didn't have any tasks we could have waited for a long time
1244       // consider the time_slept zero and reset time_before_loop
1245       time_slept = 0;
1246       time_before_loop = now;
1247     } else {
1248       // need to recalculate since we might have new tasks in _tasks
1249       time_slept = (int) ((now - time_before_loop) / 1000000);
1250     }
1251 
1252     // Change to task list or spurious wakeup of some kind
1253     if (timedout || _should_terminate) {
1254       break;
1255     }
1256 
1257     remaining = PeriodicTask::time_to_wait();
1258     if (remaining == 0) {
1259       // Last task was just disenrolled so loop around and wait until
1260       // another task gets enrolled
1261       continue;
1262     }
1263 
1264     remaining -= time_slept;
1265     if (remaining &lt;= 0) {
1266       break;
1267     }
1268   }
1269 
1270   return time_slept;
1271 }
1272 
1273 void WatcherThread::run() {
1274   assert(this == watcher_thread(), "just checking");
1275 
1276   this-&gt;record_stack_base_and_size();
1277   this-&gt;set_native_thread_name(this-&gt;name());
1278   this-&gt;set_active_handles(JNIHandleBlock::allocate_block());
1279   while (true) {
1280     assert(watcher_thread() == Thread::current(), "thread consistency check");
1281     assert(watcher_thread() == this, "thread consistency check");
1282 
1283     // Calculate how long it'll be until the next PeriodicTask work
1284     // should be done, and sleep that amount of time.
1285     int time_waited = sleep();
1286 
1287     if (is_error_reported()) {
1288       // A fatal error has happened, the error handler(VMError::report_and_die)
1289       // should abort JVM after creating an error log file. However in some
1290       // rare cases, the error handler itself might deadlock. Here we try to
1291       // kill JVM if the fatal error handler fails to abort in 2 minutes.
1292       //
1293       // This code is in WatcherThread because WatcherThread wakes up
1294       // periodically so the fatal error handler doesn't need to do anything;
1295       // also because the WatcherThread is less likely to crash than other
1296       // threads.
1297 
1298       for (;;) {
1299         if (!ShowMessageBoxOnError
1300             &amp;&amp; (OnError == NULL || OnError[0] == '\0')
1301             &amp;&amp; Arguments::abort_hook() == NULL) {
1302           os::sleep(this, (jlong)ErrorLogTimeout * 1000, false); // in seconds
1303           fdStream err(defaultStream::output_fd());
1304           err.print_raw_cr("# [ timer expired, abort... ]");
1305           // skip atexit/vm_exit/vm_abort hooks
1306           os::die();
1307         }
1308 
1309         // Wake up 5 seconds later, the fatal handler may reset OnError or
1310         // ShowMessageBoxOnError when it is ready to abort.
1311         os::sleep(this, 5 * 1000, false);
1312       }
1313     }
1314 
1315     if (_should_terminate) {
1316       // check for termination before posting the next tick
1317       break;
1318     }
1319 
1320     PeriodicTask::real_time_tick(time_waited);
1321   }
1322 
1323   // Signal that it is terminated
1324   {
1325     MutexLockerEx mu(Terminator_lock, Mutex::_no_safepoint_check_flag);
1326     _watcher_thread = NULL;
1327     Terminator_lock-&gt;notify();
1328   }
1329 }
1330 
1331 void WatcherThread::start() {
1332   assert(PeriodicTask_lock-&gt;owned_by_self(), "PeriodicTask_lock required");
1333 
1334   if (watcher_thread() == NULL &amp;&amp; _startable) {
1335     _should_terminate = false;
1336     // Create the single instance of WatcherThread
1337     new WatcherThread();
1338   }
1339 }
1340 
1341 void WatcherThread::make_startable() {
1342   assert(PeriodicTask_lock-&gt;owned_by_self(), "PeriodicTask_lock required");
1343   _startable = true;
1344 }
1345 
1346 void WatcherThread::stop() {
1347   {
1348     // Follow normal safepoint aware lock enter protocol since the
1349     // WatcherThread is stopped by another JavaThread.
1350     MutexLocker ml(PeriodicTask_lock);
1351     _should_terminate = true;
1352 
1353     WatcherThread* watcher = watcher_thread();
1354     if (watcher != NULL) {
1355       // unpark the WatcherThread so it can see that it should terminate
1356       watcher-&gt;unpark();
1357     }
1358   }
1359 
1360   MutexLocker mu(Terminator_lock);
1361 
1362   while (watcher_thread() != NULL) {
1363     // This wait should make safepoint checks, wait without a timeout,
1364     // and wait as a suspend-equivalent condition.
1365     //
1366     // Note: If the FlatProfiler is running, then this thread is waiting
1367     // for the WatcherThread to terminate and the WatcherThread, via the
1368     // FlatProfiler task, is waiting for the external suspend request on
1369     // this thread to complete. wait_for_ext_suspend_completion() will
1370     // eventually timeout, but that takes time. Making this wait a
1371     // suspend-equivalent condition solves that timeout problem.
1372     //
1373     Terminator_lock-&gt;wait(!Mutex::_no_safepoint_check_flag, 0,
1374                           Mutex::_as_suspend_equivalent_flag);
1375   }
1376 }
1377 
1378 void WatcherThread::unpark() {
1379   assert(PeriodicTask_lock-&gt;owned_by_self(), "PeriodicTask_lock required");
1380   PeriodicTask_lock-&gt;notify();
1381 }
1382 
1383 void WatcherThread::print_on(outputStream* st) const {
1384   st-&gt;print("\"%s\" ", name());
1385   Thread::print_on(st);
1386   st-&gt;cr();
1387 }
1388 
1389 // ======= JavaThread ========
1390 
1391 #if INCLUDE_JVMCI
1392 
1393 jlong* JavaThread::_jvmci_old_thread_counters;
1394 
1395 bool jvmci_counters_include(JavaThread* thread) {
1396   oop threadObj = thread-&gt;threadObj();
1397   return !JVMCICountersExcludeCompiler || !thread-&gt;is_Compiler_thread();
1398 }
1399 
1400 void JavaThread::collect_counters(typeArrayOop array) {
1401   if (JVMCICounterSize &gt; 0) {
1402     MutexLocker tl(Threads_lock);
1403     for (int i = 0; i &lt; array-&gt;length(); i++) {
1404       array-&gt;long_at_put(i, _jvmci_old_thread_counters[i]);
1405     }
1406     for (JavaThread* tp = Threads::first(); tp != NULL; tp = tp-&gt;next()) {
1407       if (jvmci_counters_include(tp)) {
1408         for (int i = 0; i &lt; array-&gt;length(); i++) {
1409           array-&gt;long_at_put(i, array-&gt;long_at(i) + tp-&gt;_jvmci_counters[i]);
1410         }
1411       }
1412     }
1413   }
1414 }
1415 
1416 #endif // INCLUDE_JVMCI
1417 
1418 // A JavaThread is a normal Java thread
1419 
1420 void JavaThread::initialize() {
1421   // Initialize fields
1422 
1423   set_saved_exception_pc(NULL);
1424   set_threadObj(NULL);
1425   _anchor.clear();
1426   set_entry_point(NULL);
1427   set_jni_functions(jni_functions());
1428   set_callee_target(NULL);
1429   set_vm_result(NULL);
1430   set_vm_result_2(NULL);
1431   set_vframe_array_head(NULL);
1432   set_vframe_array_last(NULL);
1433   set_deferred_locals(NULL);
1434   set_deopt_mark(NULL);
1435   set_deopt_compiled_method(NULL);
1436   clear_must_deopt_id();
1437   set_monitor_chunks(NULL);
1438   set_next(NULL);
1439   set_thread_state(_thread_new);
1440   _terminated = _not_terminated;
1441   _privileged_stack_top = NULL;
1442   _array_for_gc = NULL;
1443   _suspend_equivalent = false;
1444   _in_deopt_handler = 0;
1445   _doing_unsafe_access = false;
1446   _stack_guard_state = stack_guard_unused;
1447 #if INCLUDE_JVMCI
1448   _pending_monitorenter = false;
1449   _pending_deoptimization = -1;
1450   _pending_failed_speculation = NULL;
1451   _pending_transfer_to_interpreter = false;
1452   _adjusting_comp_level = false;
1453   _jvmci._alternate_call_target = NULL;
1454   assert(_jvmci._implicit_exception_pc == NULL, "must be");
1455   if (JVMCICounterSize &gt; 0) {
1456     _jvmci_counters = NEW_C_HEAP_ARRAY(jlong, JVMCICounterSize, mtInternal);
1457     memset(_jvmci_counters, 0, sizeof(jlong) * JVMCICounterSize);
1458   } else {
1459     _jvmci_counters = NULL;
1460   }
1461 #endif // INCLUDE_JVMCI
1462   _reserved_stack_activation = NULL;  // stack base not known yet
1463   (void)const_cast&lt;oop&amp;&gt;(_exception_oop = oop(NULL));
1464   _exception_pc  = 0;
1465   _exception_handler_pc = 0;
1466   _is_method_handle_return = 0;
1467   _jvmti_thread_state= NULL;
1468   _should_post_on_exceptions_flag = JNI_FALSE;
1469   _jvmti_get_loaded_classes_closure = NULL;
1470   _interp_only_mode    = 0;
1471   _special_runtime_exit_condition = _no_async_condition;
1472   _pending_async_exception = NULL;
1473   _thread_stat = NULL;
1474   _thread_stat = new ThreadStatistics();
1475   _blocked_on_compilation = false;
1476   _jni_active_critical = 0;
1477   _pending_jni_exception_check_fn = NULL;
1478   _do_not_unlock_if_synchronized = false;
1479   _cached_monitor_info = NULL;
1480   _parker = Parker::Allocate(this);
1481 
1482 #ifndef PRODUCT
1483   _jmp_ring_index = 0;
1484   for (int ji = 0; ji &lt; jump_ring_buffer_size; ji++) {
1485     record_jump(NULL, NULL, NULL, 0);
1486   }
1487 #endif // PRODUCT
1488 
1489   set_thread_profiler(NULL);
1490   if (FlatProfiler::is_active()) {
1491     // This is where we would decide to either give each thread it's own profiler
1492     // or use one global one from FlatProfiler,
1493     // or up to some count of the number of profiled threads, etc.
1494     ThreadProfiler* pp = new ThreadProfiler();
1495     pp-&gt;engage();
1496     set_thread_profiler(pp);
1497   }
1498 
1499   // Setup safepoint state info for this thread
1500   ThreadSafepointState::create(this);
1501 
1502   debug_only(_java_call_counter = 0);
1503 
1504   // JVMTI PopFrame support
1505   _popframe_condition = popframe_inactive;
1506   _popframe_preserved_args = NULL;
1507   _popframe_preserved_args_size = 0;
1508   _frames_to_pop_failed_realloc = 0;
1509 
1510   pd_initialize();
1511 }
1512 
1513 #if INCLUDE_ALL_GCS
1514 SATBMarkQueueSet JavaThread::_satb_mark_queue_set;
1515 DirtyCardQueueSet JavaThread::_dirty_card_queue_set;
1516 #endif // INCLUDE_ALL_GCS
1517 
1518 JavaThread::JavaThread(bool is_attaching_via_jni) :
1519                        Thread()
1520 #if INCLUDE_ALL_GCS
1521                        , _satb_mark_queue(&amp;_satb_mark_queue_set),
1522                        _dirty_card_queue(&amp;_dirty_card_queue_set)
1523 #endif // INCLUDE_ALL_GCS
1524 {
1525   initialize();
1526   if (is_attaching_via_jni) {
1527     _jni_attach_state = _attaching_via_jni;
1528   } else {
1529     _jni_attach_state = _not_attaching_via_jni;
1530   }
1531   assert(deferred_card_mark().is_empty(), "Default MemRegion ctor");
1532 }
1533 
1534 bool JavaThread::reguard_stack(address cur_sp) {
1535   if (_stack_guard_state != stack_guard_yellow_reserved_disabled
1536       &amp;&amp; _stack_guard_state != stack_guard_reserved_disabled) {
1537     return true; // Stack already guarded or guard pages not needed.
1538   }
1539 
1540   if (register_stack_overflow()) {
1541     // For those architectures which have separate register and
1542     // memory stacks, we must check the register stack to see if
1543     // it has overflowed.
1544     return false;
1545   }
1546 
1547   // Java code never executes within the yellow zone: the latter is only
1548   // there to provoke an exception during stack banging.  If java code
1549   // is executing there, either StackShadowPages should be larger, or
1550   // some exception code in c1, c2 or the interpreter isn't unwinding
1551   // when it should.
1552   guarantee(cur_sp &gt; stack_reserved_zone_base(),
1553             "not enough space to reguard - increase StackShadowPages");
1554   if (_stack_guard_state == stack_guard_yellow_reserved_disabled) {
1555     enable_stack_yellow_reserved_zone();
1556     if (reserved_stack_activation() != stack_base()) {
1557       set_reserved_stack_activation(stack_base());
1558     }
1559   } else if (_stack_guard_state == stack_guard_reserved_disabled) {
1560     set_reserved_stack_activation(stack_base());
1561     enable_stack_reserved_zone();
1562   }
1563   return true;
1564 }
1565 
1566 bool JavaThread::reguard_stack(void) {
1567   return reguard_stack(os::current_stack_pointer());
1568 }
1569 
1570 
1571 void JavaThread::block_if_vm_exited() {
1572   if (_terminated == _vm_exited) {
1573     // _vm_exited is set at safepoint, and Threads_lock is never released
1574     // we will block here forever
1575     Threads_lock-&gt;lock_without_safepoint_check();
1576     ShouldNotReachHere();
1577   }
1578 }
1579 
1580 
1581 // Remove this ifdef when C1 is ported to the compiler interface.
1582 static void compiler_thread_entry(JavaThread* thread, TRAPS);
1583 static void sweeper_thread_entry(JavaThread* thread, TRAPS);
1584 
1585 JavaThread::JavaThread(ThreadFunction entry_point, size_t stack_sz) :
1586                        Thread()
1587 #if INCLUDE_ALL_GCS
1588                        , _satb_mark_queue(&amp;_satb_mark_queue_set),
1589                        _dirty_card_queue(&amp;_dirty_card_queue_set)
1590 #endif // INCLUDE_ALL_GCS
1591 {
1592   initialize();
1593   _jni_attach_state = _not_attaching_via_jni;
1594   set_entry_point(entry_point);
1595   // Create the native thread itself.
1596   // %note runtime_23
1597   os::ThreadType thr_type = os::java_thread;
1598   thr_type = entry_point == &amp;compiler_thread_entry ? os::compiler_thread :
1599                                                      os::java_thread;
1600   os::create_thread(this, thr_type, stack_sz);
1601   // The _osthread may be NULL here because we ran out of memory (too many threads active).
1602   // We need to throw and OutOfMemoryError - however we cannot do this here because the caller
1603   // may hold a lock and all locks must be unlocked before throwing the exception (throwing
1604   // the exception consists of creating the exception object &amp; initializing it, initialization
1605   // will leave the VM via a JavaCall and then all locks must be unlocked).
1606   //
1607   // The thread is still suspended when we reach here. Thread must be explicit started
1608   // by creator! Furthermore, the thread must also explicitly be added to the Threads list
1609   // by calling Threads:add. The reason why this is not done here, is because the thread
1610   // object must be fully initialized (take a look at JVM_Start)
1611 }
1612 
1613 JavaThread::~JavaThread() {
1614 
1615   // JSR166 -- return the parker to the free list
1616   Parker::Release(_parker);
1617   _parker = NULL;
1618 
1619   // Free any remaining  previous UnrollBlock
1620   vframeArray* old_array = vframe_array_last();
1621 
1622   if (old_array != NULL) {
1623     Deoptimization::UnrollBlock* old_info = old_array-&gt;unroll_block();
1624     old_array-&gt;set_unroll_block(NULL);
1625     delete old_info;
1626     delete old_array;
1627   }
1628 
1629   GrowableArray&lt;jvmtiDeferredLocalVariableSet*&gt;* deferred = deferred_locals();
1630   if (deferred != NULL) {
1631     // This can only happen if thread is destroyed before deoptimization occurs.
1632     assert(deferred-&gt;length() != 0, "empty array!");
1633     do {
1634       jvmtiDeferredLocalVariableSet* dlv = deferred-&gt;at(0);
1635       deferred-&gt;remove_at(0);
1636       // individual jvmtiDeferredLocalVariableSet are CHeapObj's
1637       delete dlv;
1638     } while (deferred-&gt;length() != 0);
1639     delete deferred;
1640   }
1641 
1642   // All Java related clean up happens in exit
1643   ThreadSafepointState::destroy(this);
1644   if (_thread_profiler != NULL) delete _thread_profiler;
1645   if (_thread_stat != NULL) delete _thread_stat;
1646 
1647 #if INCLUDE_JVMCI
1648   if (JVMCICounterSize &gt; 0) {
1649     if (jvmci_counters_include(this)) {
1650       for (int i = 0; i &lt; JVMCICounterSize; i++) {
1651         _jvmci_old_thread_counters[i] += _jvmci_counters[i];
1652       }
1653     }
1654     FREE_C_HEAP_ARRAY(jlong, _jvmci_counters);
1655   }
1656 #endif // INCLUDE_JVMCI
1657 }
1658 
1659 
1660 // The first routine called by a new Java thread
1661 void JavaThread::run() {
1662   // initialize thread-local alloc buffer related fields
1663   this-&gt;initialize_tlab();
1664 
1665   // used to test validity of stack trace backs
1666   this-&gt;record_base_of_stack_pointer();
1667 
1668   // Record real stack base and size.
1669   this-&gt;record_stack_base_and_size();
1670 
1671   this-&gt;create_stack_guard_pages();
1672 
1673   this-&gt;cache_global_variables();
1674 
1675   // Thread is now sufficient initialized to be handled by the safepoint code as being
1676   // in the VM. Change thread state from _thread_new to _thread_in_vm
1677   ThreadStateTransition::transition_and_fence(this, _thread_new, _thread_in_vm);
1678 
1679   assert(JavaThread::current() == this, "sanity check");
1680   assert(!Thread::current()-&gt;owns_locks(), "sanity check");
1681 
1682   DTRACE_THREAD_PROBE(start, this);
1683 
1684   // This operation might block. We call that after all safepoint checks for a new thread has
1685   // been completed.
1686   this-&gt;set_active_handles(JNIHandleBlock::allocate_block());
1687 
1688   if (JvmtiExport::should_post_thread_life()) {
1689     JvmtiExport::post_thread_start(this);
1690   }
1691 
1692   EventThreadStart event;
1693   if (event.should_commit()) {
1694     event.set_thread(THREAD_TRACE_ID(this));
1695     event.commit();
1696   }
1697 
1698   // We call another function to do the rest so we are sure that the stack addresses used
1699   // from there will be lower than the stack base just computed
1700   thread_main_inner();
1701 
1702   // Note, thread is no longer valid at this point!
1703 }
1704 
1705 
1706 void JavaThread::thread_main_inner() {
1707   assert(JavaThread::current() == this, "sanity check");
1708   assert(this-&gt;threadObj() != NULL, "just checking");
1709 
1710   // Execute thread entry point unless this thread has a pending exception
1711   // or has been stopped before starting.
1712   // Note: Due to JVM_StopThread we can have pending exceptions already!
1713   if (!this-&gt;has_pending_exception() &amp;&amp;
1714       !java_lang_Thread::is_stillborn(this-&gt;threadObj())) {
1715     {
1716       ResourceMark rm(this);
1717       this-&gt;set_native_thread_name(this-&gt;get_thread_name());
1718     }
1719     HandleMark hm(this);
1720     this-&gt;entry_point()(this, this);
1721   }
1722 
1723   DTRACE_THREAD_PROBE(stop, this);
1724 
1725   this-&gt;exit(false);
1726   delete this;
1727 }
1728 
1729 
1730 static void ensure_join(JavaThread* thread) {
1731   // We do not need to grap the Threads_lock, since we are operating on ourself.
1732   Handle threadObj(thread, thread-&gt;threadObj());
1733   assert(threadObj.not_null(), "java thread object must exist");
1734   ObjectLocker lock(threadObj, thread);
1735   // Ignore pending exception (ThreadDeath), since we are exiting anyway
1736   thread-&gt;clear_pending_exception();
1737   // Thread is exiting. So set thread_status field in  java.lang.Thread class to TERMINATED.
1738   java_lang_Thread::set_thread_status(threadObj(), java_lang_Thread::TERMINATED);
1739   // Clear the native thread instance - this makes isAlive return false and allows the join()
1740   // to complete once we've done the notify_all below
1741   java_lang_Thread::set_thread(threadObj(), NULL);
1742   lock.notify_all(thread);
1743   // Ignore pending exception (ThreadDeath), since we are exiting anyway
1744   thread-&gt;clear_pending_exception();
1745 }
1746 
1747 
1748 // For any new cleanup additions, please check to see if they need to be applied to
1749 // cleanup_failed_attach_current_thread as well.
1750 void JavaThread::exit(bool destroy_vm, ExitType exit_type) {
1751   assert(this == JavaThread::current(), "thread consistency check");
1752 
1753   HandleMark hm(this);
1754   Handle uncaught_exception(this, this-&gt;pending_exception());
1755   this-&gt;clear_pending_exception();
1756   Handle threadObj(this, this-&gt;threadObj());
1757   assert(threadObj.not_null(), "Java thread object should be created");
1758 
1759   if (get_thread_profiler() != NULL) {
1760     get_thread_profiler()-&gt;disengage();
1761     ResourceMark rm;
1762     get_thread_profiler()-&gt;print(get_thread_name());
1763   }
1764 
1765 
1766   // FIXIT: This code should be moved into else part, when reliable 1.2/1.3 check is in place
1767   {
1768     EXCEPTION_MARK;
1769 
1770     CLEAR_PENDING_EXCEPTION;
1771   }
1772   if (!destroy_vm) {
1773     if (uncaught_exception.not_null()) {
1774       EXCEPTION_MARK;
1775       // Call method Thread.dispatchUncaughtException().
1776       KlassHandle thread_klass(THREAD, SystemDictionary::Thread_klass());
1777       JavaValue result(T_VOID);
1778       JavaCalls::call_virtual(&amp;result,
1779                               threadObj, thread_klass,
1780                               vmSymbols::dispatchUncaughtException_name(),
1781                               vmSymbols::throwable_void_signature(),
1782                               uncaught_exception,
1783                               THREAD);
1784       if (HAS_PENDING_EXCEPTION) {
1785         ResourceMark rm(this);
1786         jio_fprintf(defaultStream::error_stream(),
1787                     "\nException: %s thrown from the UncaughtExceptionHandler"
1788                     " in thread \"%s\"\n",
1789                     pending_exception()-&gt;klass()-&gt;external_name(),
1790                     get_thread_name());
1791         CLEAR_PENDING_EXCEPTION;
1792       }
1793     }
1794 
1795     // Called before the java thread exit since we want to read info
1796     // from java_lang_Thread object
1797     EventThreadEnd event;
1798     if (event.should_commit()) {
1799       event.set_thread(THREAD_TRACE_ID(this));
1800       event.commit();
1801     }
1802 
1803     // Call after last event on thread
1804     EVENT_THREAD_EXIT(this);
1805 
1806     // Call Thread.exit(). We try 3 times in case we got another Thread.stop during
1807     // the execution of the method. If that is not enough, then we don't really care. Thread.stop
1808     // is deprecated anyhow.
1809     if (!is_Compiler_thread()) {
1810       int count = 3;
1811       while (java_lang_Thread::threadGroup(threadObj()) != NULL &amp;&amp; (count-- &gt; 0)) {
1812         EXCEPTION_MARK;
1813         JavaValue result(T_VOID);
1814         KlassHandle thread_klass(THREAD, SystemDictionary::Thread_klass());
1815         JavaCalls::call_virtual(&amp;result,
1816                                 threadObj, thread_klass,
1817                                 vmSymbols::exit_method_name(),
1818                                 vmSymbols::void_method_signature(),
1819                                 THREAD);
1820         CLEAR_PENDING_EXCEPTION;
1821       }
1822     }
1823     // notify JVMTI
1824     if (JvmtiExport::should_post_thread_life()) {
1825       JvmtiExport::post_thread_end(this);
1826     }
1827 
1828     // We have notified the agents that we are exiting, before we go on,
1829     // we must check for a pending external suspend request and honor it
1830     // in order to not surprise the thread that made the suspend request.
1831     while (true) {
1832       {
1833         MutexLockerEx ml(SR_lock(), Mutex::_no_safepoint_check_flag);
1834         if (!is_external_suspend()) {
1835           set_terminated(_thread_exiting);
1836           ThreadService::current_thread_exiting(this);
1837           break;
1838         }
1839         // Implied else:
1840         // Things get a little tricky here. We have a pending external
1841         // suspend request, but we are holding the SR_lock so we
1842         // can't just self-suspend. So we temporarily drop the lock
1843         // and then self-suspend.
1844       }
1845 
1846       ThreadBlockInVM tbivm(this);
1847       java_suspend_self();
1848 
1849       // We're done with this suspend request, but we have to loop around
1850       // and check again. Eventually we will get SR_lock without a pending
1851       // external suspend request and will be able to mark ourselves as
1852       // exiting.
1853     }
1854     // no more external suspends are allowed at this point
1855   } else {
1856     // before_exit() has already posted JVMTI THREAD_END events
1857   }
1858 
1859   // Notify waiters on thread object. This has to be done after exit() is called
1860   // on the thread (if the thread is the last thread in a daemon ThreadGroup the
1861   // group should have the destroyed bit set before waiters are notified).
1862   ensure_join(this);
1863   assert(!this-&gt;has_pending_exception(), "ensure_join should have cleared");
1864 
1865   // 6282335 JNI DetachCurrentThread spec states that all Java monitors
1866   // held by this thread must be released. The spec does not distinguish
1867   // between JNI-acquired and regular Java monitors. We can only see
1868   // regular Java monitors here if monitor enter-exit matching is broken.
1869   //
1870   // Optionally release any monitors for regular JavaThread exits. This
1871   // is provided as a work around for any bugs in monitor enter-exit
1872   // matching. This can be expensive so it is not enabled by default.
1873   //
1874   // ensure_join() ignores IllegalThreadStateExceptions, and so does
1875   // ObjectSynchronizer::release_monitors_owned_by_thread().
1876   if (exit_type == jni_detach || ObjectMonitor::Knob_ExitRelease) {
1877     // Sanity check even though JNI DetachCurrentThread() would have
1878     // returned JNI_ERR if there was a Java frame. JavaThread exit
1879     // should be done executing Java code by the time we get here.
1880     assert(!this-&gt;has_last_Java_frame(),
1881            "should not have a Java frame when detaching or exiting");
1882     ObjectSynchronizer::release_monitors_owned_by_thread(this);
1883     assert(!this-&gt;has_pending_exception(), "release_monitors should have cleared");
1884   }
1885 
1886   // These things needs to be done while we are still a Java Thread. Make sure that thread
1887   // is in a consistent state, in case GC happens
1888   assert(_privileged_stack_top == NULL, "must be NULL when we get here");
1889 
1890   if (active_handles() != NULL) {
1891     JNIHandleBlock* block = active_handles();
1892     set_active_handles(NULL);
1893     JNIHandleBlock::release_block(block);
1894   }
1895 
1896   if (free_handle_block() != NULL) {
1897     JNIHandleBlock* block = free_handle_block();
1898     set_free_handle_block(NULL);
1899     JNIHandleBlock::release_block(block);
1900   }
1901 
1902   // These have to be removed while this is still a valid thread.
1903   remove_stack_guard_pages();
1904 
1905   if (UseTLAB) {
1906     tlab().make_parsable(true);  // retire TLAB
1907   }
1908 
1909   if (JvmtiEnv::environments_might_exist()) {
1910     JvmtiExport::cleanup_thread(this);
1911   }
1912 
1913   // We must flush any deferred card marks before removing a thread from
1914   // the list of active threads.
1915   Universe::heap()-&gt;flush_deferred_store_barrier(this);
1916   assert(deferred_card_mark().is_empty(), "Should have been flushed");
1917 
1918 #if INCLUDE_ALL_GCS
1919   // We must flush the G1-related buffers before removing a thread
1920   // from the list of active threads. We must do this after any deferred
1921   // card marks have been flushed (above) so that any entries that are
1922   // added to the thread's dirty card queue as a result are not lost.
1923   if (UseG1GC) {
1924     flush_barrier_queues();
1925   }
1926 #endif // INCLUDE_ALL_GCS
1927 
1928   log_info(os, thread)("JavaThread %s (tid: " UINTX_FORMAT ").",
1929     exit_type == JavaThread::normal_exit ? "exiting" : "detaching",
1930     os::current_thread_id());
1931 
1932   // Remove from list of active threads list, and notify VM thread if we are the last non-daemon thread
1933   Threads::remove(this);
1934 }
1935 
1936 #if INCLUDE_ALL_GCS
1937 // Flush G1-related queues.
1938 void JavaThread::flush_barrier_queues() {
1939   satb_mark_queue().flush();
1940   dirty_card_queue().flush();
1941 }
1942 
1943 void JavaThread::initialize_queues() {
1944   assert(!SafepointSynchronize::is_at_safepoint(),
1945          "we should not be at a safepoint");
1946 
1947   SATBMarkQueue&amp; satb_queue = satb_mark_queue();
1948   SATBMarkQueueSet&amp; satb_queue_set = satb_mark_queue_set();
1949   // The SATB queue should have been constructed with its active
1950   // field set to false.
1951   assert(!satb_queue.is_active(), "SATB queue should not be active");
1952   assert(satb_queue.is_empty(), "SATB queue should be empty");
1953   // If we are creating the thread during a marking cycle, we should
1954   // set the active field of the SATB queue to true.
1955   if (satb_queue_set.is_active()) {
1956     satb_queue.set_active(true);
1957   }
1958 
1959   DirtyCardQueue&amp; dirty_queue = dirty_card_queue();
1960   // The dirty card queue should have been constructed with its
1961   // active field set to true.
1962   assert(dirty_queue.is_active(), "dirty card queue should be active");
1963 }
1964 #endif // INCLUDE_ALL_GCS
1965 
1966 void JavaThread::cleanup_failed_attach_current_thread() {
1967   if (get_thread_profiler() != NULL) {
1968     get_thread_profiler()-&gt;disengage();
1969     ResourceMark rm;
1970     get_thread_profiler()-&gt;print(get_thread_name());
1971   }
1972 
1973   if (active_handles() != NULL) {
1974     JNIHandleBlock* block = active_handles();
1975     set_active_handles(NULL);
1976     JNIHandleBlock::release_block(block);
1977   }
1978 
1979   if (free_handle_block() != NULL) {
1980     JNIHandleBlock* block = free_handle_block();
1981     set_free_handle_block(NULL);
1982     JNIHandleBlock::release_block(block);
1983   }
1984 
1985   // These have to be removed while this is still a valid thread.
1986   remove_stack_guard_pages();
1987 
1988   if (UseTLAB) {
1989     tlab().make_parsable(true);  // retire TLAB, if any
1990   }
1991 
1992 #if INCLUDE_ALL_GCS
1993   if (UseG1GC) {
1994     flush_barrier_queues();
1995   }
1996 #endif // INCLUDE_ALL_GCS
1997 
1998   Threads::remove(this);
1999   delete this;
2000 }
2001 
2002 
2003 
2004 
2005 JavaThread* JavaThread::active() {
2006   Thread* thread = Thread::current();
2007   if (thread-&gt;is_Java_thread()) {
2008     return (JavaThread*) thread;
2009   } else {
2010     assert(thread-&gt;is_VM_thread(), "this must be a vm thread");
2011     VM_Operation* op = ((VMThread*) thread)-&gt;vm_operation();
2012     JavaThread *ret=op == NULL ? NULL : (JavaThread *)op-&gt;calling_thread();
2013     assert(ret-&gt;is_Java_thread(), "must be a Java thread");
2014     return ret;
2015   }
2016 }
2017 
2018 bool JavaThread::is_lock_owned(address adr) const {
2019   if (Thread::is_lock_owned(adr)) return true;
2020 
2021   for (MonitorChunk* chunk = monitor_chunks(); chunk != NULL; chunk = chunk-&gt;next()) {
2022     if (chunk-&gt;contains(adr)) return true;
2023   }
2024 
2025   return false;
2026 }
2027 
2028 
2029 void JavaThread::add_monitor_chunk(MonitorChunk* chunk) {
2030   chunk-&gt;set_next(monitor_chunks());
2031   set_monitor_chunks(chunk);
2032 }
2033 
2034 void JavaThread::remove_monitor_chunk(MonitorChunk* chunk) {
2035   guarantee(monitor_chunks() != NULL, "must be non empty");
2036   if (monitor_chunks() == chunk) {
2037     set_monitor_chunks(chunk-&gt;next());
2038   } else {
2039     MonitorChunk* prev = monitor_chunks();
2040     while (prev-&gt;next() != chunk) prev = prev-&gt;next();
2041     prev-&gt;set_next(chunk-&gt;next());
2042   }
2043 }
2044 
2045 // JVM support.
2046 
2047 // Note: this function shouldn't block if it's called in
2048 // _thread_in_native_trans state (such as from
2049 // check_special_condition_for_native_trans()).
2050 void JavaThread::check_and_handle_async_exceptions(bool check_unsafe_error) {
2051 
2052   if (has_last_Java_frame() &amp;&amp; has_async_condition()) {
2053     // If we are at a polling page safepoint (not a poll return)
2054     // then we must defer async exception because live registers
2055     // will be clobbered by the exception path. Poll return is
2056     // ok because the call we a returning from already collides
2057     // with exception handling registers and so there is no issue.
2058     // (The exception handling path kills call result registers but
2059     //  this is ok since the exception kills the result anyway).
2060 
2061     if (is_at_poll_safepoint()) {
2062       // if the code we are returning to has deoptimized we must defer
2063       // the exception otherwise live registers get clobbered on the
2064       // exception path before deoptimization is able to retrieve them.
2065       //
2066       RegisterMap map(this, false);
2067       frame caller_fr = last_frame().sender(&amp;map);
2068       assert(caller_fr.is_compiled_frame(), "what?");
2069       if (caller_fr.is_deoptimized_frame()) {
2070         log_info(exceptions)("deferred async exception at compiled safepoint");
2071         return;
2072       }
2073     }
2074   }
2075 
2076   JavaThread::AsyncRequests condition = clear_special_runtime_exit_condition();
2077   if (condition == _no_async_condition) {
2078     // Conditions have changed since has_special_runtime_exit_condition()
2079     // was called:
2080     // - if we were here only because of an external suspend request,
2081     //   then that was taken care of above (or cancelled) so we are done
2082     // - if we were here because of another async request, then it has
2083     //   been cleared between the has_special_runtime_exit_condition()
2084     //   and now so again we are done
2085     return;
2086   }
2087 
2088   // Check for pending async. exception
2089   if (_pending_async_exception != NULL) {
2090     // Only overwrite an already pending exception, if it is not a threadDeath.
2091     if (!has_pending_exception() || !pending_exception()-&gt;is_a(SystemDictionary::ThreadDeath_klass())) {
2092 
2093       // We cannot call Exceptions::_throw(...) here because we cannot block
2094       set_pending_exception(_pending_async_exception, __FILE__, __LINE__);
2095 
2096       if (log_is_enabled(Info, exceptions)) {
2097         ResourceMark rm;
2098         outputStream* logstream = Log(exceptions)::info_stream();
2099         logstream-&gt;print("Async. exception installed at runtime exit (" INTPTR_FORMAT ")", p2i(this));
2100           if (has_last_Java_frame()) {
2101             frame f = last_frame();
2102            logstream-&gt;print(" (pc: " INTPTR_FORMAT " sp: " INTPTR_FORMAT " )", p2i(f.pc()), p2i(f.sp()));
2103           }
2104         logstream-&gt;print_cr(" of type: %s", _pending_async_exception-&gt;klass()-&gt;external_name());
2105       }
2106       _pending_async_exception = NULL;
2107       clear_has_async_exception();
2108     }
2109   }
2110 
2111   if (check_unsafe_error &amp;&amp;
2112       condition == _async_unsafe_access_error &amp;&amp; !has_pending_exception()) {
2113     condition = _no_async_condition;  // done
2114     switch (thread_state()) {
2115     case _thread_in_vm: {
2116       JavaThread* THREAD = this;
2117       THROW_MSG(vmSymbols::java_lang_InternalError(), "a fault occurred in an unsafe memory access operation");
2118     }
2119     case _thread_in_native: {
2120       ThreadInVMfromNative tiv(this);
2121       JavaThread* THREAD = this;
2122       THROW_MSG(vmSymbols::java_lang_InternalError(), "a fault occurred in an unsafe memory access operation");
2123     }
2124     case _thread_in_Java: {
2125       ThreadInVMfromJava tiv(this);
2126       JavaThread* THREAD = this;
2127       THROW_MSG(vmSymbols::java_lang_InternalError(), "a fault occurred in a recent unsafe memory access operation in compiled Java code");
2128     }
2129     default:
2130       ShouldNotReachHere();
2131     }
2132   }
2133 
2134   assert(condition == _no_async_condition || has_pending_exception() ||
2135          (!check_unsafe_error &amp;&amp; condition == _async_unsafe_access_error),
2136          "must have handled the async condition, if no exception");
2137 }
2138 
2139 void JavaThread::handle_special_runtime_exit_condition(bool check_asyncs) {
2140   //
2141   // Check for pending external suspend. Internal suspend requests do
2142   // not use handle_special_runtime_exit_condition().
2143   // If JNIEnv proxies are allowed, don't self-suspend if the target
2144   // thread is not the current thread. In older versions of jdbx, jdbx
2145   // threads could call into the VM with another thread's JNIEnv so we
2146   // can be here operating on behalf of a suspended thread (4432884).
2147   bool do_self_suspend = is_external_suspend_with_lock();
2148   if (do_self_suspend &amp;&amp; (!AllowJNIEnvProxy || this == JavaThread::current())) {
2149     //
2150     // Because thread is external suspended the safepoint code will count
2151     // thread as at a safepoint. This can be odd because we can be here
2152     // as _thread_in_Java which would normally transition to _thread_blocked
2153     // at a safepoint. We would like to mark the thread as _thread_blocked
2154     // before calling java_suspend_self like all other callers of it but
2155     // we must then observe proper safepoint protocol. (We can't leave
2156     // _thread_blocked with a safepoint in progress). However we can be
2157     // here as _thread_in_native_trans so we can't use a normal transition
2158     // constructor/destructor pair because they assert on that type of
2159     // transition. We could do something like:
2160     //
2161     // JavaThreadState state = thread_state();
2162     // set_thread_state(_thread_in_vm);
2163     // {
2164     //   ThreadBlockInVM tbivm(this);
2165     //   java_suspend_self()
2166     // }
2167     // set_thread_state(_thread_in_vm_trans);
2168     // if (safepoint) block;
2169     // set_thread_state(state);
2170     //
2171     // but that is pretty messy. Instead we just go with the way the
2172     // code has worked before and note that this is the only path to
2173     // java_suspend_self that doesn't put the thread in _thread_blocked
2174     // mode.
2175 
2176     frame_anchor()-&gt;make_walkable(this);
2177     java_suspend_self();
2178 
2179     // We might be here for reasons in addition to the self-suspend request
2180     // so check for other async requests.
2181   }
2182 
2183   if (check_asyncs) {
2184     check_and_handle_async_exceptions();
2185   }
2186 }
2187 
2188 void JavaThread::send_thread_stop(oop java_throwable)  {
2189   assert(Thread::current()-&gt;is_VM_thread(), "should be in the vm thread");
2190   assert(Threads_lock-&gt;is_locked(), "Threads_lock should be locked by safepoint code");
2191   assert(SafepointSynchronize::is_at_safepoint(), "all threads are stopped");
2192 
2193   // Do not throw asynchronous exceptions against the compiler thread
2194   // (the compiler thread should not be a Java thread -- fix in 1.4.2)
2195   if (!can_call_java()) return;
2196 
2197   {
2198     // Actually throw the Throwable against the target Thread - however
2199     // only if there is no thread death exception installed already.
2200     if (_pending_async_exception == NULL || !_pending_async_exception-&gt;is_a(SystemDictionary::ThreadDeath_klass())) {
2201       // If the topmost frame is a runtime stub, then we are calling into
2202       // OptoRuntime from compiled code. Some runtime stubs (new, monitor_exit..)
2203       // must deoptimize the caller before continuing, as the compiled  exception handler table
2204       // may not be valid
2205       if (has_last_Java_frame()) {
2206         frame f = last_frame();
2207         if (f.is_runtime_frame() || f.is_safepoint_blob_frame()) {
2208           // BiasedLocking needs an updated RegisterMap for the revoke monitors pass
2209           RegisterMap reg_map(this, UseBiasedLocking);
2210           frame compiled_frame = f.sender(&amp;reg_map);
2211           if (!StressCompiledExceptionHandlers &amp;&amp; compiled_frame.can_be_deoptimized()) {
2212             Deoptimization::deoptimize(this, compiled_frame, &amp;reg_map);
2213           }
2214         }
2215       }
2216 
2217       // Set async. pending exception in thread.
2218       set_pending_async_exception(java_throwable);
2219 
2220       if (log_is_enabled(Info, exceptions)) {
2221          ResourceMark rm;
2222         log_info(exceptions)("Pending Async. exception installed of type: %s",
2223                              InstanceKlass::cast(_pending_async_exception-&gt;klass())-&gt;external_name());
2224       }
2225       // for AbortVMOnException flag
2226       Exceptions::debug_check_abort(_pending_async_exception-&gt;klass()-&gt;external_name());
2227     }
2228   }
2229 
2230 
2231   // Interrupt thread so it will wake up from a potential wait()
2232   Thread::interrupt(this);
2233 }
2234 
2235 // External suspension mechanism.
2236 //
2237 // Tell the VM to suspend a thread when ever it knows that it does not hold on
2238 // to any VM_locks and it is at a transition
2239 // Self-suspension will happen on the transition out of the vm.
2240 // Catch "this" coming in from JNIEnv pointers when the thread has been freed
2241 //
2242 // Guarantees on return:
2243 //   + Target thread will not execute any new bytecode (that's why we need to
2244 //     force a safepoint)
2245 //   + Target thread will not enter any new monitors
2246 //
2247 void JavaThread::java_suspend() {
2248   { MutexLocker mu(Threads_lock);
2249     if (!Threads::includes(this) || is_exiting() || this-&gt;threadObj() == NULL) {
2250       return;
2251     }
2252   }
2253 
2254   { MutexLockerEx ml(SR_lock(), Mutex::_no_safepoint_check_flag);
2255     if (!is_external_suspend()) {
2256       // a racing resume has cancelled us; bail out now
2257       return;
2258     }
2259 
2260     // suspend is done
2261     uint32_t debug_bits = 0;
2262     // Warning: is_ext_suspend_completed() may temporarily drop the
2263     // SR_lock to allow the thread to reach a stable thread state if
2264     // it is currently in a transient thread state.
2265     if (is_ext_suspend_completed(false /* !called_by_wait */,
2266                                  SuspendRetryDelay, &amp;debug_bits)) {
2267       return;
2268     }
2269   }
2270 
2271   VM_ForceSafepoint vm_suspend;
2272   VMThread::execute(&amp;vm_suspend);
2273 }
2274 
2275 // Part II of external suspension.
2276 // A JavaThread self suspends when it detects a pending external suspend
2277 // request. This is usually on transitions. It is also done in places
2278 // where continuing to the next transition would surprise the caller,
2279 // e.g., monitor entry.
2280 //
2281 // Returns the number of times that the thread self-suspended.
2282 //
2283 // Note: DO NOT call java_suspend_self() when you just want to block current
2284 //       thread. java_suspend_self() is the second stage of cooperative
2285 //       suspension for external suspend requests and should only be used
2286 //       to complete an external suspend request.
2287 //
2288 int JavaThread::java_suspend_self() {
2289   int ret = 0;
2290 
2291   // we are in the process of exiting so don't suspend
2292   if (is_exiting()) {
2293     clear_external_suspend();
2294     return ret;
2295   }
2296 
2297   assert(_anchor.walkable() ||
2298          (is_Java_thread() &amp;&amp; !((JavaThread*)this)-&gt;has_last_Java_frame()),
2299          "must have walkable stack");
2300 
2301   MutexLockerEx ml(SR_lock(), Mutex::_no_safepoint_check_flag);
2302 
2303   assert(!this-&gt;is_ext_suspended(),
2304          "a thread trying to self-suspend should not already be suspended");
2305 
2306   if (this-&gt;is_suspend_equivalent()) {
2307     // If we are self-suspending as a result of the lifting of a
2308     // suspend equivalent condition, then the suspend_equivalent
2309     // flag is not cleared until we set the ext_suspended flag so
2310     // that wait_for_ext_suspend_completion() returns consistent
2311     // results.
2312     this-&gt;clear_suspend_equivalent();
2313   }
2314 
2315   // A racing resume may have cancelled us before we grabbed SR_lock
2316   // above. Or another external suspend request could be waiting for us
2317   // by the time we return from SR_lock()-&gt;wait(). The thread
2318   // that requested the suspension may already be trying to walk our
2319   // stack and if we return now, we can change the stack out from under
2320   // it. This would be a "bad thing (TM)" and cause the stack walker
2321   // to crash. We stay self-suspended until there are no more pending
2322   // external suspend requests.
2323   while (is_external_suspend()) {
2324     ret++;
2325     this-&gt;set_ext_suspended();
2326 
2327     // _ext_suspended flag is cleared by java_resume()
2328     while (is_ext_suspended()) {
2329       this-&gt;SR_lock()-&gt;wait(Mutex::_no_safepoint_check_flag);
2330     }
2331   }
2332 
2333   return ret;
2334 }
2335 
2336 #ifdef ASSERT
2337 // verify the JavaThread has not yet been published in the Threads::list, and
2338 // hence doesn't need protection from concurrent access at this stage
2339 void JavaThread::verify_not_published() {
2340   if (!Threads_lock-&gt;owned_by_self()) {
2341     MutexLockerEx ml(Threads_lock,  Mutex::_no_safepoint_check_flag);
2342     assert(!Threads::includes(this),
2343            "java thread shouldn't have been published yet!");
2344   } else {
2345     assert(!Threads::includes(this),
2346            "java thread shouldn't have been published yet!");
2347   }
2348 }
2349 #endif
2350 
2351 // Slow path when the native==&gt;VM/Java barriers detect a safepoint is in
2352 // progress or when _suspend_flags is non-zero.
2353 // Current thread needs to self-suspend if there is a suspend request and/or
2354 // block if a safepoint is in progress.
2355 // Async exception ISN'T checked.
2356 // Note only the ThreadInVMfromNative transition can call this function
2357 // directly and when thread state is _thread_in_native_trans
2358 void JavaThread::check_safepoint_and_suspend_for_native_trans(JavaThread *thread) {
2359   assert(thread-&gt;thread_state() == _thread_in_native_trans, "wrong state");
2360 
2361   JavaThread *curJT = JavaThread::current();
2362   bool do_self_suspend = thread-&gt;is_external_suspend();
2363 
2364   assert(!curJT-&gt;has_last_Java_frame() || curJT-&gt;frame_anchor()-&gt;walkable(), "Unwalkable stack in native-&gt;vm transition");
2365 
2366   // If JNIEnv proxies are allowed, don't self-suspend if the target
2367   // thread is not the current thread. In older versions of jdbx, jdbx
2368   // threads could call into the VM with another thread's JNIEnv so we
2369   // can be here operating on behalf of a suspended thread (4432884).
2370   if (do_self_suspend &amp;&amp; (!AllowJNIEnvProxy || curJT == thread)) {
2371     JavaThreadState state = thread-&gt;thread_state();
2372 
2373     // We mark this thread_blocked state as a suspend-equivalent so
2374     // that a caller to is_ext_suspend_completed() won't be confused.
2375     // The suspend-equivalent state is cleared by java_suspend_self().
2376     thread-&gt;set_suspend_equivalent();
2377 
2378     // If the safepoint code sees the _thread_in_native_trans state, it will
2379     // wait until the thread changes to other thread state. There is no
2380     // guarantee on how soon we can obtain the SR_lock and complete the
2381     // self-suspend request. It would be a bad idea to let safepoint wait for
2382     // too long. Temporarily change the state to _thread_blocked to
2383     // let the VM thread know that this thread is ready for GC. The problem
2384     // of changing thread state is that safepoint could happen just after
2385     // java_suspend_self() returns after being resumed, and VM thread will
2386     // see the _thread_blocked state. We must check for safepoint
2387     // after restoring the state and make sure we won't leave while a safepoint
2388     // is in progress.
2389     thread-&gt;set_thread_state(_thread_blocked);
2390     thread-&gt;java_suspend_self();
2391     thread-&gt;set_thread_state(state);
2392     // Make sure new state is seen by VM thread
2393     if (os::is_MP()) {
2394       if (UseMembar) {
2395         // Force a fence between the write above and read below
2396         OrderAccess::fence();
2397       } else {
2398         // Must use this rather than serialization page in particular on Windows
2399         InterfaceSupport::serialize_memory(thread);
2400       }
2401     }
2402   }
2403 
2404   if (SafepointSynchronize::do_call_back()) {
2405     // If we are safepointing, then block the caller which may not be
2406     // the same as the target thread (see above).
2407     SafepointSynchronize::block(curJT);
2408   }
2409 
2410   if (thread-&gt;is_deopt_suspend()) {
2411     thread-&gt;clear_deopt_suspend();
2412     RegisterMap map(thread, false);
2413     frame f = thread-&gt;last_frame();
2414     while (f.id() != thread-&gt;must_deopt_id() &amp;&amp; ! f.is_first_frame()) {
2415       f = f.sender(&amp;map);
2416     }
2417     if (f.id() == thread-&gt;must_deopt_id()) {
2418       thread-&gt;clear_must_deopt_id();
2419       f.deoptimize(thread);
2420     } else {
2421       fatal("missed deoptimization!");
2422     }
2423   }
2424 }
2425 
2426 // Slow path when the native==&gt;VM/Java barriers detect a safepoint is in
2427 // progress or when _suspend_flags is non-zero.
2428 // Current thread needs to self-suspend if there is a suspend request and/or
2429 // block if a safepoint is in progress.
2430 // Also check for pending async exception (not including unsafe access error).
2431 // Note only the native==&gt;VM/Java barriers can call this function and when
2432 // thread state is _thread_in_native_trans.
2433 void JavaThread::check_special_condition_for_native_trans(JavaThread *thread) {
2434   check_safepoint_and_suspend_for_native_trans(thread);
2435 
2436   if (thread-&gt;has_async_exception()) {
2437     // We are in _thread_in_native_trans state, don't handle unsafe
2438     // access error since that may block.
2439     thread-&gt;check_and_handle_async_exceptions(false);
2440   }
2441 }
2442 
2443 // This is a variant of the normal
2444 // check_special_condition_for_native_trans with slightly different
2445 // semantics for use by critical native wrappers.  It does all the
2446 // normal checks but also performs the transition back into
2447 // thread_in_Java state.  This is required so that critical natives
2448 // can potentially block and perform a GC if they are the last thread
2449 // exiting the GCLocker.
2450 void JavaThread::check_special_condition_for_native_trans_and_transition(JavaThread *thread) {
2451   check_special_condition_for_native_trans(thread);
2452 
2453   // Finish the transition
2454   thread-&gt;set_thread_state(_thread_in_Java);
2455 
2456   if (thread-&gt;do_critical_native_unlock()) {
2457     ThreadInVMfromJavaNoAsyncException tiv(thread);
2458     GCLocker::unlock_critical(thread);
2459     thread-&gt;clear_critical_native_unlock();
2460   }
2461 }
2462 
2463 // We need to guarantee the Threads_lock here, since resumes are not
2464 // allowed during safepoint synchronization
2465 // Can only resume from an external suspension
2466 void JavaThread::java_resume() {
2467   assert_locked_or_safepoint(Threads_lock);
2468 
2469   // Sanity check: thread is gone, has started exiting or the thread
2470   // was not externally suspended.
2471   if (!Threads::includes(this) || is_exiting() || !is_external_suspend()) {
2472     return;
2473   }
2474 
2475   MutexLockerEx ml(SR_lock(), Mutex::_no_safepoint_check_flag);
2476 
2477   clear_external_suspend();
2478 
2479   if (is_ext_suspended()) {
2480     clear_ext_suspended();
2481     SR_lock()-&gt;notify_all();
2482   }
2483 }
2484 
2485 size_t JavaThread::_stack_red_zone_size = 0;
2486 size_t JavaThread::_stack_yellow_zone_size = 0;
2487 size_t JavaThread::_stack_reserved_zone_size = 0;
2488 size_t JavaThread::_stack_shadow_zone_size = 0;
2489 
2490 void JavaThread::create_stack_guard_pages() {
2491   if (!os::uses_stack_guard_pages() || _stack_guard_state != stack_guard_unused) { return; }
2492   address low_addr = stack_end();
2493   size_t len = stack_guard_zone_size();
2494 
2495   int allocate = os::allocate_stack_guard_pages();
2496   // warning("Guarding at " PTR_FORMAT " for len " SIZE_FORMAT "\n", low_addr, len);
2497 
2498   if (allocate &amp;&amp; !os::create_stack_guard_pages((char *) low_addr, len)) {
2499     log_warning(os, thread)("Attempt to allocate stack guard pages failed.");
2500     return;
2501   }
2502 
2503   if (os::guard_memory((char *) low_addr, len)) {
2504     _stack_guard_state = stack_guard_enabled;
2505   } else {
2506     log_warning(os, thread)("Attempt to protect stack guard pages failed ("
2507       PTR_FORMAT "-" PTR_FORMAT ").", p2i(low_addr), p2i(low_addr + len));
2508     if (os::uncommit_memory((char *) low_addr, len)) {
2509       log_warning(os, thread)("Attempt to deallocate stack guard pages failed.");
2510     }
2511     return;
2512   }
2513 
2514   log_debug(os, thread)("Thread " UINTX_FORMAT " stack guard pages activated: "
2515     PTR_FORMAT "-" PTR_FORMAT ".",
2516     os::current_thread_id(), p2i(low_addr), p2i(low_addr + len));
2517 
2518 }
2519 
2520 void JavaThread::remove_stack_guard_pages() {
2521   assert(Thread::current() == this, "from different thread");
2522   if (_stack_guard_state == stack_guard_unused) return;
2523   address low_addr = stack_end();
2524   size_t len = stack_guard_zone_size();
2525 
2526   if (os::allocate_stack_guard_pages()) {
2527     if (os::remove_stack_guard_pages((char *) low_addr, len)) {
2528       _stack_guard_state = stack_guard_unused;
2529     } else {
2530       log_warning(os, thread)("Attempt to deallocate stack guard pages failed ("
2531         PTR_FORMAT "-" PTR_FORMAT ").", p2i(low_addr), p2i(low_addr + len));
2532       return;
2533     }
2534   } else {
2535     if (_stack_guard_state == stack_guard_unused) return;
2536     if (os::unguard_memory((char *) low_addr, len)) {
2537       _stack_guard_state = stack_guard_unused;
2538     } else {
2539       log_warning(os, thread)("Attempt to unprotect stack guard pages failed ("
2540         PTR_FORMAT "-" PTR_FORMAT ").", p2i(low_addr), p2i(low_addr + len));
2541       return;
2542     }
2543   }
2544 
2545   log_debug(os, thread)("Thread " UINTX_FORMAT " stack guard pages removed: "
2546     PTR_FORMAT "-" PTR_FORMAT ".",
2547     os::current_thread_id(), p2i(low_addr), p2i(low_addr + len));
2548 
2549 }
2550 
2551 void JavaThread::enable_stack_reserved_zone() {
2552   assert(_stack_guard_state != stack_guard_unused, "must be using guard pages.");
2553   assert(_stack_guard_state != stack_guard_enabled, "already enabled");
2554 
2555   // The base notation is from the stack's point of view, growing downward.
2556   // We need to adjust it to work correctly with guard_memory()
2557   address base = stack_reserved_zone_base() - stack_reserved_zone_size();
2558 
2559   guarantee(base &lt; stack_base(),"Error calculating stack reserved zone");
2560   guarantee(base &lt; os::current_stack_pointer(),"Error calculating stack reserved zone");
2561 
2562   if (os::guard_memory((char *) base, stack_reserved_zone_size())) {
2563     _stack_guard_state = stack_guard_enabled;
2564   } else {
2565     warning("Attempt to guard stack reserved zone failed.");
2566   }
2567   enable_register_stack_guard();
2568 }
2569 
2570 void JavaThread::disable_stack_reserved_zone() {
2571   assert(_stack_guard_state != stack_guard_unused, "must be using guard pages.");
2572   assert(_stack_guard_state != stack_guard_reserved_disabled, "already disabled");
2573 
2574   // Simply return if called for a thread that does not use guard pages.
2575   if (_stack_guard_state == stack_guard_unused) return;
2576 
2577   // The base notation is from the stack's point of view, growing downward.
2578   // We need to adjust it to work correctly with guard_memory()
2579   address base = stack_reserved_zone_base() - stack_reserved_zone_size();
2580 
2581   if (os::unguard_memory((char *)base, stack_reserved_zone_size())) {
2582     _stack_guard_state = stack_guard_reserved_disabled;
2583   } else {
2584     warning("Attempt to unguard stack reserved zone failed.");
2585   }
2586   disable_register_stack_guard();
2587 }
2588 
2589 void JavaThread::enable_stack_yellow_reserved_zone() {
2590   assert(_stack_guard_state != stack_guard_unused, "must be using guard pages.");
2591   assert(_stack_guard_state != stack_guard_enabled, "already enabled");
2592 
2593   // The base notation is from the stacks point of view, growing downward.
2594   // We need to adjust it to work correctly with guard_memory()
2595   address base = stack_red_zone_base();
2596 
2597   guarantee(base &lt; stack_base(), "Error calculating stack yellow zone");
2598   guarantee(base &lt; os::current_stack_pointer(), "Error calculating stack yellow zone");
2599 
2600   if (os::guard_memory((char *) base, stack_yellow_reserved_zone_size())) {
2601     _stack_guard_state = stack_guard_enabled;
2602   } else {
2603     warning("Attempt to guard stack yellow zone failed.");
2604   }
2605   enable_register_stack_guard();
2606 }
2607 
2608 void JavaThread::disable_stack_yellow_reserved_zone() {
2609   assert(_stack_guard_state != stack_guard_unused, "must be using guard pages.");
2610   assert(_stack_guard_state != stack_guard_yellow_reserved_disabled, "already disabled");
2611 
2612   // Simply return if called for a thread that does not use guard pages.
2613   if (_stack_guard_state == stack_guard_unused) return;
2614 
2615   // The base notation is from the stacks point of view, growing downward.
2616   // We need to adjust it to work correctly with guard_memory()
2617   address base = stack_red_zone_base();
2618 
2619   if (os::unguard_memory((char *)base, stack_yellow_reserved_zone_size())) {
2620     _stack_guard_state = stack_guard_yellow_reserved_disabled;
2621   } else {
2622     warning("Attempt to unguard stack yellow zone failed.");
2623   }
2624   disable_register_stack_guard();
2625 }
2626 
2627 void JavaThread::enable_stack_red_zone() {
2628   // The base notation is from the stacks point of view, growing downward.
2629   // We need to adjust it to work correctly with guard_memory()
2630   assert(_stack_guard_state != stack_guard_unused, "must be using guard pages.");
2631   address base = stack_red_zone_base() - stack_red_zone_size();
2632 
2633   guarantee(base &lt; stack_base(), "Error calculating stack red zone");
2634   guarantee(base &lt; os::current_stack_pointer(), "Error calculating stack red zone");
2635 
2636   if (!os::guard_memory((char *) base, stack_red_zone_size())) {
2637     warning("Attempt to guard stack red zone failed.");
2638   }
2639 }
2640 
2641 void JavaThread::disable_stack_red_zone() {
2642   // The base notation is from the stacks point of view, growing downward.
2643   // We need to adjust it to work correctly with guard_memory()
2644   assert(_stack_guard_state != stack_guard_unused, "must be using guard pages.");
2645   address base = stack_red_zone_base() - stack_red_zone_size();
2646   if (!os::unguard_memory((char *)base, stack_red_zone_size())) {
2647     warning("Attempt to unguard stack red zone failed.");
2648   }
2649 }
2650 
2651 void JavaThread::frames_do(void f(frame*, const RegisterMap* map)) {
2652   // ignore is there is no stack
2653   if (!has_last_Java_frame()) return;
2654   // traverse the stack frames. Starts from top frame.
2655   for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {
2656     frame* fr = fst.current();
2657     f(fr, fst.register_map());
2658   }
2659 }
2660 
2661 
2662 #ifndef PRODUCT
2663 // Deoptimization
2664 // Function for testing deoptimization
2665 void JavaThread::deoptimize() {
2666   // BiasedLocking needs an updated RegisterMap for the revoke monitors pass
2667   StackFrameStream fst(this, UseBiasedLocking);
2668   bool deopt = false;           // Dump stack only if a deopt actually happens.
2669   bool only_at = strlen(DeoptimizeOnlyAt) &gt; 0;
2670   // Iterate over all frames in the thread and deoptimize
2671   for (; !fst.is_done(); fst.next()) {
2672     if (fst.current()-&gt;can_be_deoptimized()) {
2673 
2674       if (only_at) {
2675         // Deoptimize only at particular bcis.  DeoptimizeOnlyAt
2676         // consists of comma or carriage return separated numbers so
2677         // search for the current bci in that string.
2678         address pc = fst.current()-&gt;pc();
2679         nmethod* nm =  (nmethod*) fst.current()-&gt;cb();
2680         ScopeDesc* sd = nm-&gt;scope_desc_at(pc);
2681         char buffer[8];
2682         jio_snprintf(buffer, sizeof(buffer), "%d", sd-&gt;bci());
2683         size_t len = strlen(buffer);
2684         const char * found = strstr(DeoptimizeOnlyAt, buffer);
2685         while (found != NULL) {
2686           if ((found[len] == ',' || found[len] == '\n' || found[len] == '\0') &amp;&amp;
2687               (found == DeoptimizeOnlyAt || found[-1] == ',' || found[-1] == '\n')) {
2688             // Check that the bci found is bracketed by terminators.
2689             break;
2690           }
2691           found = strstr(found + 1, buffer);
2692         }
2693         if (!found) {
2694           continue;
2695         }
2696       }
2697 
2698       if (DebugDeoptimization &amp;&amp; !deopt) {
2699         deopt = true; // One-time only print before deopt
2700         tty-&gt;print_cr("[BEFORE Deoptimization]");
2701         trace_frames();
2702         trace_stack();
2703       }
2704       Deoptimization::deoptimize(this, *fst.current(), fst.register_map());
2705     }
2706   }
2707 
2708   if (DebugDeoptimization &amp;&amp; deopt) {
2709     tty-&gt;print_cr("[AFTER Deoptimization]");
2710     trace_frames();
2711   }
2712 }
2713 
2714 
2715 // Make zombies
2716 void JavaThread::make_zombies() {
2717   for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {
2718     if (fst.current()-&gt;can_be_deoptimized()) {
2719       // it is a Java nmethod
2720       nmethod* nm = CodeCache::find_nmethod(fst.current()-&gt;pc());
2721       nm-&gt;make_not_entrant();
2722     }
2723   }
2724 }
2725 #endif // PRODUCT
2726 
2727 
2728 void JavaThread::deoptimized_wrt_marked_nmethods() {
2729   if (!has_last_Java_frame()) return;
2730   // BiasedLocking needs an updated RegisterMap for the revoke monitors pass
2731   StackFrameStream fst(this, UseBiasedLocking);
2732   for (; !fst.is_done(); fst.next()) {
2733     if (fst.current()-&gt;should_be_deoptimized()) {
2734       Deoptimization::deoptimize(this, *fst.current(), fst.register_map());
2735     }
2736   }
2737 }
2738 
2739 
2740 // If the caller is a NamedThread, then remember, in the current scope,
2741 // the given JavaThread in its _processed_thread field.
2742 class RememberProcessedThread: public StackObj {
2743   NamedThread* _cur_thr;
2744  public:
2745   RememberProcessedThread(JavaThread* jthr) {
2746     Thread* thread = Thread::current();
2747     if (thread-&gt;is_Named_thread()) {
2748       _cur_thr = (NamedThread *)thread;
2749       _cur_thr-&gt;set_processed_thread(jthr);
2750     } else {
2751       _cur_thr = NULL;
2752     }
2753   }
2754 
2755   ~RememberProcessedThread() {
2756     if (_cur_thr) {
2757       _cur_thr-&gt;set_processed_thread(NULL);
2758     }
2759   }
2760 };
2761 
2762 void JavaThread::oops_do(OopClosure* f, CodeBlobClosure* cf) {
2763   // Verify that the deferred card marks have been flushed.
2764   assert(deferred_card_mark().is_empty(), "Should be empty during GC");
2765 
2766   // The ThreadProfiler oops_do is done from FlatProfiler::oops_do
2767   // since there may be more than one thread using each ThreadProfiler.
2768 
2769   // Traverse the GCHandles
2770   Thread::oops_do(f, cf);
2771 
2772   JVMCI_ONLY(f-&gt;do_oop((oop*)&amp;_pending_failed_speculation);)
2773 
2774   assert((!has_last_Java_frame() &amp;&amp; java_call_counter() == 0) ||
2775          (has_last_Java_frame() &amp;&amp; java_call_counter() &gt; 0), "wrong java_sp info!");
2776 
2777   if (has_last_Java_frame()) {
2778     // Record JavaThread to GC thread
2779     RememberProcessedThread rpt(this);
2780 
2781     // Traverse the privileged stack
2782     if (_privileged_stack_top != NULL) {
2783       _privileged_stack_top-&gt;oops_do(f);
2784     }
2785 
2786     // traverse the registered growable array
2787     if (_array_for_gc != NULL) {
2788       for (int index = 0; index &lt; _array_for_gc-&gt;length(); index++) {
2789         f-&gt;do_oop(_array_for_gc-&gt;adr_at(index));
2790       }
2791     }
2792 
2793     // Traverse the monitor chunks
2794     for (MonitorChunk* chunk = monitor_chunks(); chunk != NULL; chunk = chunk-&gt;next()) {
2795       chunk-&gt;oops_do(f);
2796     }
2797 
2798     // Traverse the execution stack
2799     for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {
2800       fst.current()-&gt;oops_do(f, cf, fst.register_map());
2801     }
2802   }
2803 
2804   // callee_target is never live across a gc point so NULL it here should
2805   // it still contain a methdOop.
2806 
2807   set_callee_target(NULL);
2808 
2809   assert(vframe_array_head() == NULL, "deopt in progress at a safepoint!");
2810   // If we have deferred set_locals there might be oops waiting to be
2811   // written
2812   GrowableArray&lt;jvmtiDeferredLocalVariableSet*&gt;* list = deferred_locals();
2813   if (list != NULL) {
2814     for (int i = 0; i &lt; list-&gt;length(); i++) {
2815       list-&gt;at(i)-&gt;oops_do(f);
2816     }
2817   }
2818 
2819   // Traverse instance variables at the end since the GC may be moving things
2820   // around using this function
2821   f-&gt;do_oop((oop*) &amp;_threadObj);
2822   f-&gt;do_oop((oop*) &amp;_vm_result);
2823   f-&gt;do_oop((oop*) &amp;_exception_oop);
2824   f-&gt;do_oop((oop*) &amp;_pending_async_exception);
2825 
2826   if (jvmti_thread_state() != NULL) {
2827     jvmti_thread_state()-&gt;oops_do(f);
2828   }
2829 }
2830 
2831 void JavaThread::nmethods_do(CodeBlobClosure* cf) {
2832   assert((!has_last_Java_frame() &amp;&amp; java_call_counter() == 0) ||
2833          (has_last_Java_frame() &amp;&amp; java_call_counter() &gt; 0), "wrong java_sp info!");
2834 
2835   if (has_last_Java_frame()) {
2836     // Traverse the execution stack
2837     for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {
2838       fst.current()-&gt;nmethods_do(cf);
2839     }
2840   }
2841 }
2842 
2843 void JavaThread::metadata_do(void f(Metadata*)) {
2844   if (has_last_Java_frame()) {
2845     // Traverse the execution stack to call f() on the methods in the stack
2846     for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {
2847       fst.current()-&gt;metadata_do(f);
2848     }
2849   } else if (is_Compiler_thread()) {
2850     // need to walk ciMetadata in current compile tasks to keep alive.
2851     CompilerThread* ct = (CompilerThread*)this;
2852     if (ct-&gt;env() != NULL) {
2853       ct-&gt;env()-&gt;metadata_do(f);
2854     }
2855     if (ct-&gt;task() != NULL) {
2856       ct-&gt;task()-&gt;metadata_do(f);
2857     }
2858   }
2859 }
2860 
2861 // Printing
2862 const char* _get_thread_state_name(JavaThreadState _thread_state) {
2863   switch (_thread_state) {
2864   case _thread_uninitialized:     return "_thread_uninitialized";
2865   case _thread_new:               return "_thread_new";
2866   case _thread_new_trans:         return "_thread_new_trans";
2867   case _thread_in_native:         return "_thread_in_native";
2868   case _thread_in_native_trans:   return "_thread_in_native_trans";
2869   case _thread_in_vm:             return "_thread_in_vm";
2870   case _thread_in_vm_trans:       return "_thread_in_vm_trans";
2871   case _thread_in_Java:           return "_thread_in_Java";
2872   case _thread_in_Java_trans:     return "_thread_in_Java_trans";
2873   case _thread_blocked:           return "_thread_blocked";
2874   case _thread_blocked_trans:     return "_thread_blocked_trans";
2875   default:                        return "unknown thread state";
2876   }
2877 }
2878 
2879 #ifndef PRODUCT
2880 void JavaThread::print_thread_state_on(outputStream *st) const {
2881   st-&gt;print_cr("   JavaThread state: %s", _get_thread_state_name(_thread_state));
2882 };
2883 void JavaThread::print_thread_state() const {
2884   print_thread_state_on(tty);
2885 }
2886 #endif // PRODUCT
2887 
2888 // Called by Threads::print() for VM_PrintThreads operation
2889 void JavaThread::print_on(outputStream *st) const {
2890   st-&gt;print_raw("\"");
2891   st-&gt;print_raw(get_thread_name());
2892   st-&gt;print_raw("\" ");
2893   oop thread_oop = threadObj();
2894   if (thread_oop != NULL) {
2895     st-&gt;print("#" INT64_FORMAT " ", java_lang_Thread::thread_id(thread_oop));
2896     if (java_lang_Thread::is_daemon(thread_oop))  st-&gt;print("daemon ");
2897     st-&gt;print("prio=%d ", java_lang_Thread::priority(thread_oop));
2898   }
2899   Thread::print_on(st);
2900   // print guess for valid stack memory region (assume 4K pages); helps lock debugging
2901   st-&gt;print_cr("[" INTPTR_FORMAT "]", (intptr_t)last_Java_sp() &amp; ~right_n_bits(12));
2902   if (thread_oop != NULL) {
2903     st-&gt;print_cr("   java.lang.Thread.State: %s", java_lang_Thread::thread_status_name(thread_oop));
2904   }
2905 #ifndef PRODUCT
2906   print_thread_state_on(st);
2907   _safepoint_state-&gt;print_on(st);
2908 #endif // PRODUCT
2909   if (is_Compiler_thread()) {
2910     CompilerThread* ct = (CompilerThread*)this;
2911     if (ct-&gt;task() != NULL) {
2912       st-&gt;print("   Compiling: ");
2913       ct-&gt;task()-&gt;print(st, NULL, true, false);
2914     } else {
2915       st-&gt;print("   No compile task");
2916     }
2917     st-&gt;cr();
2918   }
2919 }
2920 
2921 void JavaThread::print_name_on_error(outputStream* st, char *buf, int buflen) const {
2922   st-&gt;print("%s", get_thread_name_string(buf, buflen));
2923 }
2924 
2925 // Called by fatal error handler. The difference between this and
2926 // JavaThread::print() is that we can't grab lock or allocate memory.
2927 void JavaThread::print_on_error(outputStream* st, char *buf, int buflen) const {
2928   st-&gt;print("JavaThread \"%s\"", get_thread_name_string(buf, buflen));
2929   oop thread_obj = threadObj();
2930   if (thread_obj != NULL) {
2931     if (java_lang_Thread::is_daemon(thread_obj)) st-&gt;print(" daemon");
2932   }
2933   st-&gt;print(" [");
2934   st-&gt;print("%s", _get_thread_state_name(_thread_state));
2935   if (osthread()) {
2936     st-&gt;print(", id=%d", osthread()-&gt;thread_id());
2937   }
2938   st-&gt;print(", stack(" PTR_FORMAT "," PTR_FORMAT ")",
2939             p2i(stack_end()), p2i(stack_base()));
2940   st-&gt;print("]");
2941   return;
2942 }
2943 
2944 // Verification
2945 
2946 static void frame_verify(frame* f, const RegisterMap *map) { f-&gt;verify(map); }
2947 
2948 void JavaThread::verify() {
2949   // Verify oops in the thread.
2950   oops_do(&amp;VerifyOopClosure::verify_oop, NULL);
2951 
2952   // Verify the stack frames.
2953   frames_do(frame_verify);
2954 }
2955 
2956 // CR 6300358 (sub-CR 2137150)
2957 // Most callers of this method assume that it can't return NULL but a
2958 // thread may not have a name whilst it is in the process of attaching to
2959 // the VM - see CR 6412693, and there are places where a JavaThread can be
2960 // seen prior to having it's threadObj set (eg JNI attaching threads and
2961 // if vm exit occurs during initialization). These cases can all be accounted
2962 // for such that this method never returns NULL.
2963 const char* JavaThread::get_thread_name() const {
2964 #ifdef ASSERT
2965   // early safepoints can hit while current thread does not yet have TLS
2966   if (!SafepointSynchronize::is_at_safepoint()) {
2967     Thread *cur = Thread::current();
2968     if (!(cur-&gt;is_Java_thread() &amp;&amp; cur == this)) {
2969       // Current JavaThreads are allowed to get their own name without
2970       // the Threads_lock.
2971       assert_locked_or_safepoint(Threads_lock);
2972     }
2973   }
2974 #endif // ASSERT
2975   return get_thread_name_string();
2976 }
2977 
2978 // Returns a non-NULL representation of this thread's name, or a suitable
2979 // descriptive string if there is no set name
2980 const char* JavaThread::get_thread_name_string(char* buf, int buflen) const {
2981   const char* name_str;
2982   oop thread_obj = threadObj();
2983   if (thread_obj != NULL) {
2984     oop name = java_lang_Thread::name(thread_obj);
2985     if (name != NULL) {
2986       if (buf == NULL) {
2987         name_str = java_lang_String::as_utf8_string(name);
2988       } else {
2989         name_str = java_lang_String::as_utf8_string(name, buf, buflen);
2990       }
2991     } else if (is_attaching_via_jni()) { // workaround for 6412693 - see 6404306
2992       name_str = "&lt;no-name - thread is attaching&gt;";
2993     } else {
2994       name_str = Thread::name();
2995     }
2996   } else {
2997     name_str = Thread::name();
2998   }
2999   assert(name_str != NULL, "unexpected NULL thread name");
3000   return name_str;
3001 }
3002 
3003 
3004 const char* JavaThread::get_threadgroup_name() const {
3005   debug_only(if (JavaThread::current() != this) assert_locked_or_safepoint(Threads_lock);)
3006   oop thread_obj = threadObj();
3007   if (thread_obj != NULL) {
3008     oop thread_group = java_lang_Thread::threadGroup(thread_obj);
3009     if (thread_group != NULL) {
3010       // ThreadGroup.name can be null
3011       return java_lang_ThreadGroup::name(thread_group);
3012     }
3013   }
3014   return NULL;
3015 }
3016 
3017 const char* JavaThread::get_parent_name() const {
3018   debug_only(if (JavaThread::current() != this) assert_locked_or_safepoint(Threads_lock);)
3019   oop thread_obj = threadObj();
3020   if (thread_obj != NULL) {
3021     oop thread_group = java_lang_Thread::threadGroup(thread_obj);
3022     if (thread_group != NULL) {
3023       oop parent = java_lang_ThreadGroup::parent(thread_group);
3024       if (parent != NULL) {
3025         // ThreadGroup.name can be null
3026         return java_lang_ThreadGroup::name(parent);
3027       }
3028     }
3029   }
3030   return NULL;
3031 }
3032 
3033 ThreadPriority JavaThread::java_priority() const {
3034   oop thr_oop = threadObj();
3035   if (thr_oop == NULL) return NormPriority; // Bootstrapping
3036   ThreadPriority priority = java_lang_Thread::priority(thr_oop);
3037   assert(MinPriority &lt;= priority &amp;&amp; priority &lt;= MaxPriority, "sanity check");
3038   return priority;
3039 }
3040 
3041 void JavaThread::prepare(jobject jni_thread, ThreadPriority prio) {
3042 
3043   assert(Threads_lock-&gt;owner() == Thread::current(), "must have threads lock");
3044   // Link Java Thread object &lt;-&gt; C++ Thread
3045 
3046   // Get the C++ thread object (an oop) from the JNI handle (a jthread)
3047   // and put it into a new Handle.  The Handle "thread_oop" can then
3048   // be used to pass the C++ thread object to other methods.
3049 
3050   // Set the Java level thread object (jthread) field of the
3051   // new thread (a JavaThread *) to C++ thread object using the
3052   // "thread_oop" handle.
3053 
3054   // Set the thread field (a JavaThread *) of the
3055   // oop representing the java_lang_Thread to the new thread (a JavaThread *).
3056 
3057   Handle thread_oop(Thread::current(),
3058                     JNIHandles::resolve_non_null(jni_thread));
3059   assert(InstanceKlass::cast(thread_oop-&gt;klass())-&gt;is_linked(),
3060          "must be initialized");
3061   set_threadObj(thread_oop());
3062   java_lang_Thread::set_thread(thread_oop(), this);
3063 
3064   if (prio == NoPriority) {
3065     prio = java_lang_Thread::priority(thread_oop());
3066     assert(prio != NoPriority, "A valid priority should be present");
3067   }
3068 
3069   // Push the Java priority down to the native thread; needs Threads_lock
3070   Thread::set_priority(this, prio);
3071 
3072   prepare_ext();
3073 
3074   // Add the new thread to the Threads list and set it in motion.
3075   // We must have threads lock in order to call Threads::add.
3076   // It is crucial that we do not block before the thread is
3077   // added to the Threads list for if a GC happens, then the java_thread oop
3078   // will not be visited by GC.
3079   Threads::add(this);
3080 }
3081 
3082 oop JavaThread::current_park_blocker() {
3083   // Support for JSR-166 locks
3084   oop thread_oop = threadObj();
3085   if (thread_oop != NULL &amp;&amp;
3086       JDK_Version::current().supports_thread_park_blocker()) {
3087     return java_lang_Thread::park_blocker(thread_oop);
3088   }
3089   return NULL;
3090 }
3091 
3092 
3093 void JavaThread::print_stack_on(outputStream* st) {
3094   if (!has_last_Java_frame()) return;
3095   ResourceMark rm;
3096   HandleMark   hm;
3097 
3098   RegisterMap reg_map(this);
3099   vframe* start_vf = last_java_vframe(&amp;reg_map);
3100   int count = 0;
3101   for (vframe* f = start_vf; f; f = f-&gt;sender()) {
3102     if (f-&gt;is_java_frame()) {
3103       javaVFrame* jvf = javaVFrame::cast(f);
3104       java_lang_Throwable::print_stack_element(st, jvf-&gt;method(), jvf-&gt;bci());
3105 
3106       // Print out lock information
3107       if (JavaMonitorsInStackTrace) {
3108         jvf-&gt;print_lock_info_on(st, count);
3109       }
3110     } else {
3111       // Ignore non-Java frames
3112     }
3113 
3114     // Bail-out case for too deep stacks
3115     count++;
3116     if (MaxJavaStackTraceDepth == count) return;
3117   }
3118 }
3119 
3120 
3121 // JVMTI PopFrame support
3122 void JavaThread::popframe_preserve_args(ByteSize size_in_bytes, void* start) {
3123   assert(_popframe_preserved_args == NULL, "should not wipe out old PopFrame preserved arguments");
3124   if (in_bytes(size_in_bytes) != 0) {
3125     _popframe_preserved_args = NEW_C_HEAP_ARRAY(char, in_bytes(size_in_bytes), mtThread);
3126     _popframe_preserved_args_size = in_bytes(size_in_bytes);
3127     Copy::conjoint_jbytes(start, _popframe_preserved_args, _popframe_preserved_args_size);
3128   }
3129 }
3130 
3131 void* JavaThread::popframe_preserved_args() {
3132   return _popframe_preserved_args;
3133 }
3134 
3135 ByteSize JavaThread::popframe_preserved_args_size() {
3136   return in_ByteSize(_popframe_preserved_args_size);
3137 }
3138 
3139 WordSize JavaThread::popframe_preserved_args_size_in_words() {
3140   int sz = in_bytes(popframe_preserved_args_size());
3141   assert(sz % wordSize == 0, "argument size must be multiple of wordSize");
3142   return in_WordSize(sz / wordSize);
3143 }
3144 
3145 void JavaThread::popframe_free_preserved_args() {
3146   assert(_popframe_preserved_args != NULL, "should not free PopFrame preserved arguments twice");
3147   FREE_C_HEAP_ARRAY(char, (char*) _popframe_preserved_args);
3148   _popframe_preserved_args = NULL;
3149   _popframe_preserved_args_size = 0;
3150 }
3151 
3152 #ifndef PRODUCT
3153 
3154 void JavaThread::trace_frames() {
3155   tty-&gt;print_cr("[Describe stack]");
3156   int frame_no = 1;
3157   for (StackFrameStream fst(this); !fst.is_done(); fst.next()) {
3158     tty-&gt;print("  %d. ", frame_no++);
3159     fst.current()-&gt;print_value_on(tty, this);
3160     tty-&gt;cr();
3161   }
3162 }
3163 
3164 class PrintAndVerifyOopClosure: public OopClosure {
3165  protected:
3166   template &lt;class T&gt; inline void do_oop_work(T* p) {
3167     oop obj = oopDesc::load_decode_heap_oop(p);
3168     if (obj == NULL) return;
3169     tty-&gt;print(INTPTR_FORMAT ": ", p2i(p));
3170     if (obj-&gt;is_oop_or_null()) {
3171       if (obj-&gt;is_objArray()) {
3172         tty-&gt;print_cr("valid objArray: " INTPTR_FORMAT, p2i(obj));
3173       } else {
3174         obj-&gt;print();
3175       }
3176     } else {
3177       tty-&gt;print_cr("invalid oop: " INTPTR_FORMAT, p2i(obj));
3178     }
3179     tty-&gt;cr();
3180   }
3181  public:
3182   virtual void do_oop(oop* p) { do_oop_work(p); }
3183   virtual void do_oop(narrowOop* p)  { do_oop_work(p); }
3184 };
3185 
3186 
3187 static void oops_print(frame* f, const RegisterMap *map) {
3188   PrintAndVerifyOopClosure print;
3189   f-&gt;print_value();
3190   f-&gt;oops_do(&amp;print, NULL, (RegisterMap*)map);
3191 }
3192 
3193 // Print our all the locations that contain oops and whether they are
3194 // valid or not.  This useful when trying to find the oldest frame
3195 // where an oop has gone bad since the frame walk is from youngest to
3196 // oldest.
3197 void JavaThread::trace_oops() {
3198   tty-&gt;print_cr("[Trace oops]");
3199   frames_do(oops_print);
3200 }
3201 
3202 
3203 #ifdef ASSERT
3204 // Print or validate the layout of stack frames
3205 void JavaThread::print_frame_layout(int depth, bool validate_only) {
3206   ResourceMark rm;
3207   PRESERVE_EXCEPTION_MARK;
3208   FrameValues values;
3209   int frame_no = 0;
3210   for (StackFrameStream fst(this, false); !fst.is_done(); fst.next()) {
3211     fst.current()-&gt;describe(values, ++frame_no);
3212     if (depth == frame_no) break;
3213   }
3214   if (validate_only) {
3215     values.validate();
3216   } else {
3217     tty-&gt;print_cr("[Describe stack layout]");
3218     values.print(this);
3219   }
3220 }
3221 #endif
3222 
3223 void JavaThread::trace_stack_from(vframe* start_vf) {
3224   ResourceMark rm;
3225   int vframe_no = 1;
3226   for (vframe* f = start_vf; f; f = f-&gt;sender()) {
3227     if (f-&gt;is_java_frame()) {
3228       javaVFrame::cast(f)-&gt;print_activation(vframe_no++);
3229     } else {
3230       f-&gt;print();
3231     }
3232     if (vframe_no &gt; StackPrintLimit) {
3233       tty-&gt;print_cr("...&lt;more frames&gt;...");
3234       return;
3235     }
3236   }
3237 }
3238 
3239 
3240 void JavaThread::trace_stack() {
3241   if (!has_last_Java_frame()) return;
3242   ResourceMark rm;
3243   HandleMark   hm;
3244   RegisterMap reg_map(this);
3245   trace_stack_from(last_java_vframe(&amp;reg_map));
3246 }
3247 
3248 
3249 #endif // PRODUCT
3250 
3251 
3252 javaVFrame* JavaThread::last_java_vframe(RegisterMap *reg_map) {
3253   assert(reg_map != NULL, "a map must be given");
3254   frame f = last_frame();
3255   for (vframe* vf = vframe::new_vframe(&amp;f, reg_map, this); vf; vf = vf-&gt;sender()) {
3256     if (vf-&gt;is_java_frame()) return javaVFrame::cast(vf);
3257   }
3258   return NULL;
3259 }
3260 
3261 
3262 Klass* JavaThread::security_get_caller_class(int depth) {
3263   vframeStream vfst(this);
3264   vfst.security_get_caller_frame(depth);
3265   if (!vfst.at_end()) {
3266     return vfst.method()-&gt;method_holder();
3267   }
3268   return NULL;
3269 }
3270 
3271 static void compiler_thread_entry(JavaThread* thread, TRAPS) {
3272   assert(thread-&gt;is_Compiler_thread(), "must be compiler thread");
3273   CompileBroker::compiler_thread_loop();
3274 }
3275 
3276 static void sweeper_thread_entry(JavaThread* thread, TRAPS) {
3277   NMethodSweeper::sweeper_loop();
3278 }
3279 
3280 // Create a CompilerThread
3281 CompilerThread::CompilerThread(CompileQueue* queue,
3282                                CompilerCounters* counters)
3283                                : JavaThread(&amp;compiler_thread_entry) {
3284   _env   = NULL;
3285   _log   = NULL;
3286   _task  = NULL;
3287   _queue = queue;
3288   _counters = counters;
3289   _buffer_blob = NULL;
3290   _compiler = NULL;
3291 
3292 #ifndef PRODUCT
3293   _ideal_graph_printer = NULL;
3294 #endif
3295 }
3296 
3297 bool CompilerThread::can_call_java() const {
3298   return _compiler != NULL &amp;&amp; _compiler-&gt;is_jvmci();
3299 }
3300 
3301 // Create sweeper thread
3302 CodeCacheSweeperThread::CodeCacheSweeperThread()
3303 : JavaThread(&amp;sweeper_thread_entry) {
3304   _scanned_compiled_method = NULL;
3305 }
3306 
3307 void CodeCacheSweeperThread::oops_do(OopClosure* f, CodeBlobClosure* cf) {
3308   JavaThread::oops_do(f, cf);
3309   if (_scanned_compiled_method != NULL &amp;&amp; cf != NULL) {
3310     // Safepoints can occur when the sweeper is scanning an nmethod so
3311     // process it here to make sure it isn't unloaded in the middle of
3312     // a scan.
3313     cf-&gt;do_code_blob(_scanned_compiled_method);
3314   }
3315 }
3316 
3317 void CodeCacheSweeperThread::nmethods_do(CodeBlobClosure* cf) {
3318   JavaThread::nmethods_do(cf);
3319   if (_scanned_compiled_method != NULL &amp;&amp; cf != NULL) {
3320     // Safepoints can occur when the sweeper is scanning an nmethod so
3321     // process it here to make sure it isn't unloaded in the middle of
3322     // a scan.
3323     cf-&gt;do_code_blob(_scanned_compiled_method);
3324   }
3325 }
3326 
3327 
3328 // ======= Threads ========
3329 
3330 // The Threads class links together all active threads, and provides
3331 // operations over all threads.  It is protected by its own Mutex
3332 // lock, which is also used in other contexts to protect thread
3333 // operations from having the thread being operated on from exiting
3334 // and going away unexpectedly (e.g., safepoint synchronization)
3335 
3336 JavaThread* Threads::_thread_list = NULL;
3337 int         Threads::_number_of_threads = 0;
3338 int         Threads::_number_of_non_daemon_threads = 0;
3339 int         Threads::_return_code = 0;
3340 int         Threads::_thread_claim_parity = 0;
3341 size_t      JavaThread::_stack_size_at_create = 0;
3342 #ifdef ASSERT
3343 bool        Threads::_vm_complete = false;
3344 #endif
3345 
3346 // All JavaThreads
3347 #define ALL_JAVA_THREADS(X) for (JavaThread* X = _thread_list; X; X = X-&gt;next())
3348 
3349 // All JavaThreads + all non-JavaThreads (i.e., every thread in the system)
3350 void Threads::threads_do(ThreadClosure* tc) {
3351   assert_locked_or_safepoint(Threads_lock);
3352   // ALL_JAVA_THREADS iterates through all JavaThreads
3353   ALL_JAVA_THREADS(p) {
3354     tc-&gt;do_thread(p);
3355   }
3356   // Someday we could have a table or list of all non-JavaThreads.
3357   // For now, just manually iterate through them.
3358   tc-&gt;do_thread(VMThread::vm_thread());
3359   Universe::heap()-&gt;gc_threads_do(tc);
3360   WatcherThread *wt = WatcherThread::watcher_thread();
3361   // Strictly speaking, the following NULL check isn't sufficient to make sure
3362   // the data for WatcherThread is still valid upon being examined. However,
3363   // considering that WatchThread terminates when the VM is on the way to
3364   // exit at safepoint, the chance of the above is extremely small. The right
3365   // way to prevent termination of WatcherThread would be to acquire
3366   // Terminator_lock, but we can't do that without violating the lock rank
3367   // checking in some cases.
3368   if (wt != NULL) {
3369     tc-&gt;do_thread(wt);
3370   }
3371 
3372   // If CompilerThreads ever become non-JavaThreads, add them here
3373 }
3374 
3375 // The system initialization in the library has three phases.
3376 //
3377 // Phase 1: java.lang.System class initialization
3378 //     java.lang.System is a primordial class loaded and initialized
3379 //     by the VM early during startup.  java.lang.System.&lt;clinit&gt;
3380 //     only does registerNatives and keeps the rest of the class
3381 //     initialization work later until thread initialization completes.
3382 //
3383 //     System.initPhase1 initializes the system properties, the static
3384 //     fields in, out, and err. Set up java signal handlers, OS-specific
3385 //     system settings, and thread group of the main thread.
3386 static void call_initPhase1(TRAPS) {
3387   Klass* k =  SystemDictionary::resolve_or_fail(vmSymbols::java_lang_System(), true, CHECK);
3388   instanceKlassHandle klass (THREAD, k);
3389 
3390   JavaValue result(T_VOID);
3391   JavaCalls::call_static(&amp;result, klass, vmSymbols::initPhase1_name(),
3392                                          vmSymbols::void_method_signature(), CHECK);
3393 }
3394 
3395 // Phase 2. Module system initialization
3396 //     This will initialize the module system.  Only java.base classes
3397 //     can be loaded until phase 2 completes.
3398 //
3399 //     Call System.initPhase2 after the compiler initialization and jsr292
3400 //     classes get initialized because module initialization runs a lot of java
3401 //     code, that for performance reasons, should be compiled.  Also, this will
3402 //     enable the startup code to use lambda and other language features in this
3403 //     phase and onward.
3404 //
3405 //     After phase 2, The VM will begin search classes from -Xbootclasspath/a.
3406 static void call_initPhase2(TRAPS) {
3407   Klass* k = SystemDictionary::resolve_or_fail(vmSymbols::java_lang_System(), true, CHECK);
3408   instanceKlassHandle klass (THREAD, k);
3409 
3410   JavaValue result(T_VOID);
3411   JavaCalls::call_static(&amp;result, klass, vmSymbols::initPhase2_name(),
3412                                          vmSymbols::void_method_signature(), CHECK);
3413   universe_post_module_init();
3414 }
3415 
3416 // Phase 3. final setup - set security manager, system class loader and TCCL
3417 //
3418 //     This will instantiate and set the security manager, set the system class
3419 //     loader as well as the thread context class loader.  The security manager
3420 //     and system class loader may be a custom class loaded from -Xbootclasspath/a,
3421 //     other modules or the application's classpath.
3422 static void call_initPhase3(TRAPS) {
3423   Klass* k = SystemDictionary::resolve_or_fail(vmSymbols::java_lang_System(), true, CHECK);
3424   instanceKlassHandle klass (THREAD, k);
3425 
3426   JavaValue result(T_VOID);
3427   JavaCalls::call_static(&amp;result, klass, vmSymbols::initPhase3_name(),
3428                                          vmSymbols::void_method_signature(), CHECK);
3429 }
3430 
3431 void Threads::initialize_java_lang_classes(JavaThread* main_thread, TRAPS) {
3432   TraceTime timer("Initialize java.lang classes", TRACETIME_LOG(Info, startuptime));
3433 
3434   if (EagerXrunInit &amp;&amp; Arguments::init_libraries_at_startup()) {
3435     create_vm_init_libraries();
3436   }
3437 
3438   initialize_class(vmSymbols::java_lang_String(), CHECK);
3439 
3440   // Inject CompactStrings value after the static initializers for String ran.
3441   java_lang_String::set_compact_strings(CompactStrings);
3442 
3443   // Initialize java_lang.System (needed before creating the thread)
3444   initialize_class(vmSymbols::java_lang_System(), CHECK);
3445   // The VM creates &amp; returns objects of this class. Make sure it's initialized.
3446   initialize_class(vmSymbols::java_lang_Class(), CHECK);
3447   initialize_class(vmSymbols::java_lang_ThreadGroup(), CHECK);
3448   Handle thread_group = create_initial_thread_group(CHECK);
3449   Universe::set_main_thread_group(thread_group());
3450   initialize_class(vmSymbols::java_lang_Thread(), CHECK);
3451   oop thread_object = create_initial_thread(thread_group, main_thread, CHECK);
3452   main_thread-&gt;set_threadObj(thread_object);
3453   // Set thread status to running since main thread has
3454   // been started and running.
3455   java_lang_Thread::set_thread_status(thread_object,
3456                                       java_lang_Thread::RUNNABLE);
3457 
3458   // The VM creates objects of this class.
3459   initialize_class(vmSymbols::java_lang_reflect_Module(), CHECK);
3460 
3461   // The VM preresolves methods to these classes. Make sure that they get initialized
3462   initialize_class(vmSymbols::java_lang_reflect_Method(), CHECK);
3463   initialize_class(vmSymbols::java_lang_ref_Finalizer(), CHECK);
3464 
3465   // Phase 1 of the system initialization in the library, java.lang.System class initialization
3466   call_initPhase1(CHECK);
3467 
3468   // get the Java runtime name after java.lang.System is initialized
3469   JDK_Version::set_runtime_name(get_java_runtime_name(THREAD));
3470   JDK_Version::set_runtime_version(get_java_runtime_version(THREAD));
3471 
3472   // an instance of OutOfMemory exception has been allocated earlier
3473   initialize_class(vmSymbols::java_lang_OutOfMemoryError(), CHECK);
3474   initialize_class(vmSymbols::java_lang_NullPointerException(), CHECK);
3475   initialize_class(vmSymbols::java_lang_ClassCastException(), CHECK);
3476   initialize_class(vmSymbols::java_lang_ArrayStoreException(), CHECK);
3477   initialize_class(vmSymbols::java_lang_ArithmeticException(), CHECK);
3478   initialize_class(vmSymbols::java_lang_StackOverflowError(), CHECK);
3479   initialize_class(vmSymbols::java_lang_IllegalMonitorStateException(), CHECK);
3480   initialize_class(vmSymbols::java_lang_IllegalArgumentException(), CHECK);
3481 }
3482 
3483 void Threads::initialize_jsr292_core_classes(TRAPS) {
3484   TraceTime timer("Initialize java.lang.invoke classes", TRACETIME_LOG(Info, startuptime));
3485 
3486   initialize_class(vmSymbols::java_lang_invoke_MethodHandle(), CHECK);
3487   initialize_class(vmSymbols::java_lang_invoke_MemberName(), CHECK);
3488   initialize_class(vmSymbols::java_lang_invoke_MethodHandleNatives(), CHECK);
3489 }
3490 
3491 jint Threads::create_vm(JavaVMInitArgs* args, bool* canTryAgain) {
3492   extern void JDK_Version_init();
3493 
3494   // Preinitialize version info.
3495   VM_Version::early_initialize();
3496 
3497   // Check version
3498   if (!is_supported_jni_version(args-&gt;version)) return JNI_EVERSION;
3499 
3500   // Initialize library-based TLS
3501   ThreadLocalStorage::init();
3502 
3503   // Initialize the output stream module
3504   ostream_init();
3505 
3506   // Process java launcher properties.
3507   Arguments::process_sun_java_launcher_properties(args);
3508 
3509   // Initialize the os module
3510   os::init();
3511 
3512   // Record VM creation timing statistics
3513   TraceVmCreationTime create_vm_timer;
3514   create_vm_timer.start();
3515 
3516   // Initialize system properties.
3517   Arguments::init_system_properties();
3518 
3519   // So that JDK version can be used as a discriminator when parsing arguments
3520   JDK_Version_init();
3521 
3522   // Update/Initialize System properties after JDK version number is known
3523   Arguments::init_version_specific_system_properties();
3524 
3525   // Make sure to initialize log configuration *before* parsing arguments
3526   LogConfiguration::initialize(create_vm_timer.begin_time());
3527 
3528   // Parse arguments
3529   jint parse_result = Arguments::parse(args);
3530   if (parse_result != JNI_OK) return parse_result;
3531 
3532   os::init_before_ergo();
3533 
3534   jint ergo_result = Arguments::apply_ergo();
3535   if (ergo_result != JNI_OK) return ergo_result;
3536 
3537   // Final check of all ranges after ergonomics which may change values.
3538   if (!CommandLineFlagRangeList::check_ranges()) {
3539     return JNI_EINVAL;
3540   }
3541 
3542   // Final check of all 'AfterErgo' constraints after ergonomics which may change values.
3543   bool constraint_result = CommandLineFlagConstraintList::check_constraints(CommandLineFlagConstraint::AfterErgo);
3544   if (!constraint_result) {
3545     return JNI_EINVAL;
3546   }
3547 
3548   if (PauseAtStartup) {
3549     os::pause();
3550   }
3551 
3552   HOTSPOT_VM_INIT_BEGIN();
3553 
3554   // Timing (must come after argument parsing)
3555   TraceTime timer("Create VM", TRACETIME_LOG(Info, startuptime));
3556 
3557   // Initialize the os module after parsing the args
3558   jint os_init_2_result = os::init_2();
3559   if (os_init_2_result != JNI_OK) return os_init_2_result;
3560 
3561   jint adjust_after_os_result = Arguments::adjust_after_os();
3562   if (adjust_after_os_result != JNI_OK) return adjust_after_os_result;
3563 
3564   // Initialize output stream logging
3565   ostream_init_log();
3566 
3567   // Convert -Xrun to -agentlib: if there is no JVM_OnLoad
3568   // Must be before create_vm_init_agents()
3569   if (Arguments::init_libraries_at_startup()) {
3570     convert_vm_init_libraries_to_agents();
3571   }
3572 
3573   // Launch -agentlib/-agentpath and converted -Xrun agents
3574   if (Arguments::init_agents_at_startup()) {
3575     create_vm_init_agents();
3576   }
3577 
3578   // Initialize Threads state
3579   _thread_list = NULL;
3580   _number_of_threads = 0;
3581   _number_of_non_daemon_threads = 0;
3582 
3583   // Initialize global data structures and create system classes in heap
3584   vm_init_globals();
3585 
3586 #if INCLUDE_JVMCI
3587   if (JVMCICounterSize &gt; 0) {
3588     JavaThread::_jvmci_old_thread_counters = NEW_C_HEAP_ARRAY(jlong, JVMCICounterSize, mtInternal);
3589     memset(JavaThread::_jvmci_old_thread_counters, 0, sizeof(jlong) * JVMCICounterSize);
3590   } else {
3591     JavaThread::_jvmci_old_thread_counters = NULL;
3592   }
3593 #endif // INCLUDE_JVMCI
3594 
3595   // Attach the main thread to this os thread
3596   JavaThread* main_thread = new JavaThread();
3597   main_thread-&gt;set_thread_state(_thread_in_vm);
3598   main_thread-&gt;initialize_thread_current();
3599   // must do this before set_active_handles
3600   main_thread-&gt;record_stack_base_and_size();
3601   main_thread-&gt;set_active_handles(JNIHandleBlock::allocate_block());
3602 
3603   if (!main_thread-&gt;set_as_starting_thread()) {
3604     vm_shutdown_during_initialization(
3605                                       "Failed necessary internal allocation. Out of swap space");
3606     delete main_thread;
3607     *canTryAgain = false; // don't let caller call JNI_CreateJavaVM again
3608     return JNI_ENOMEM;
3609   }
3610 
3611   // Enable guard page *after* os::create_main_thread(), otherwise it would
3612   // crash Linux VM, see notes in os_linux.cpp.
3613   main_thread-&gt;create_stack_guard_pages();
3614 
3615   // Initialize Java-Level synchronization subsystem
3616   ObjectMonitor::Initialize();
3617 
3618   // Initialize global modules
3619   jint status = init_globals();
3620   if (status != JNI_OK) {
3621     delete main_thread;
3622     *canTryAgain = false; // don't let caller call JNI_CreateJavaVM again
3623     return status;
3624   }
3625 
3626   if (TRACE_INITIALIZE() != JNI_OK) {
3627     vm_exit_during_initialization("Failed to initialize tracing backend");
3628   }
3629 
3630   // Should be done after the heap is fully created
3631   main_thread-&gt;cache_global_variables();
3632 
3633   HandleMark hm;
3634 
3635   { MutexLocker mu(Threads_lock);
3636     Threads::add(main_thread);
3637   }
3638 
3639   // Any JVMTI raw monitors entered in onload will transition into
3640   // real raw monitor. VM is setup enough here for raw monitor enter.
3641   JvmtiExport::transition_pending_onload_raw_monitors();
3642 
3643   // Create the VMThread
3644   { TraceTime timer("Start VMThread", TRACETIME_LOG(Info, startuptime));
3645 
3646   VMThread::create();
3647     Thread* vmthread = VMThread::vm_thread();
3648 
3649     if (!os::create_thread(vmthread, os::vm_thread)) {
3650       vm_exit_during_initialization("Cannot create VM thread. "
3651                                     "Out of system resources.");
3652     }
3653 
3654     // Wait for the VM thread to become ready, and VMThread::run to initialize
3655     // Monitors can have spurious returns, must always check another state flag
3656     {
3657       MutexLocker ml(Notify_lock);
3658       os::start_thread(vmthread);
3659       while (vmthread-&gt;active_handles() == NULL) {
3660         Notify_lock-&gt;wait();
3661       }
3662     }
3663   }
3664 
3665   assert(Universe::is_fully_initialized(), "not initialized");
3666   if (VerifyDuringStartup) {
3667     // Make sure we're starting with a clean slate.
3668     VM_Verify verify_op;
3669     VMThread::execute(&amp;verify_op);
3670   }
3671 
3672   Thread* THREAD = Thread::current();
3673 
3674   // At this point, the Universe is initialized, but we have not executed
3675   // any byte code.  Now is a good time (the only time) to dump out the
3676   // internal state of the JVM for sharing.
3677   if (DumpSharedSpaces) {
3678     MetaspaceShared::preload_and_dump(CHECK_JNI_ERR);
3679     ShouldNotReachHere();
3680   }
3681 
3682   // Always call even when there are not JVMTI environments yet, since environments
3683   // may be attached late and JVMTI must track phases of VM execution
3684   JvmtiExport::enter_early_start_phase();
3685 
3686   // Notify JVMTI agents that VM has started (JNI is up) - nop if no agents.
3687   JvmtiExport::post_early_vm_start();
3688 
3689   initialize_java_lang_classes(main_thread, CHECK_JNI_ERR);
3690 
3691   // We need this for ClassDataSharing - the initial vm.info property is set
3692   // with the default value of CDS "sharing" which may be reset through
3693   // command line options.
3694   reset_vm_info_property(CHECK_JNI_ERR);
3695 
3696   quicken_jni_functions();
3697 
3698   // No more stub generation allowed after that point.
3699   StubCodeDesc::freeze();
3700 
3701   // Set flag that basic initialization has completed. Used by exceptions and various
3702   // debug stuff, that does not work until all basic classes have been initialized.
3703   set_init_completed();
3704 
3705   LogConfiguration::post_initialize();
3706   Metaspace::post_initialize();
3707 
3708   HOTSPOT_VM_INIT_END();
3709 
3710   // record VM initialization completion time
3711 #if INCLUDE_MANAGEMENT
3712   Management::record_vm_init_completed();
3713 #endif // INCLUDE_MANAGEMENT
3714 
3715   // Note that we do not use CHECK_0 here since we are inside an EXCEPTION_MARK and
3716   // set_init_completed has just been called, causing exceptions not to be shortcut
3717   // anymore. We call vm_exit_during_initialization directly instead.
3718 
3719   // Initialize reference pending list locker
3720   bool needs_locker_thread = Universe::heap()-&gt;needs_reference_pending_list_locker_thread();
3721   ReferencePendingListLocker::initialize(needs_locker_thread, CHECK_JNI_ERR);
3722 
3723   // Signal Dispatcher needs to be started before VMInit event is posted
3724   os::signal_init();
3725 
3726   // Start Attach Listener if +StartAttachListener or it can't be started lazily
3727   if (!DisableAttachMechanism) {
3728     AttachListener::vm_start();
3729     if (StartAttachListener || AttachListener::init_at_startup()) {
3730       AttachListener::init();
3731     }
3732   }
3733 
3734   // Launch -Xrun agents
3735   // Must be done in the JVMTI live phase so that for backward compatibility the JDWP
3736   // back-end can launch with -Xdebug -Xrunjdwp.
3737   if (!EagerXrunInit &amp;&amp; Arguments::init_libraries_at_startup()) {
3738     create_vm_init_libraries();
3739   }
3740 
3741   if (CleanChunkPoolAsync) {
3742     Chunk::start_chunk_pool_cleaner_task();
3743   }
3744 
3745   // initialize compiler(s)
3746 #if defined(COMPILER1) || defined(COMPILER2) || defined(SHARK) || INCLUDE_JVMCI
3747   CompileBroker::compilation_init(CHECK_JNI_ERR);
3748 #endif
3749 
3750   // Pre-initialize some JSR292 core classes to avoid deadlock during class loading.
3751   // It is done after compilers are initialized, because otherwise compilations of
3752   // signature polymorphic MH intrinsics can be missed
3753   // (see SystemDictionary::find_method_handle_intrinsic).
3754   initialize_jsr292_core_classes(CHECK_JNI_ERR);
3755 
3756   // This will initialize the module system.  Only java.base classes can be
3757   // loaded until phase 2 completes
3758   call_initPhase2(CHECK_JNI_ERR);
3759 
3760   // Always call even when there are not JVMTI environments yet, since environments
3761   // may be attached late and JVMTI must track phases of VM execution
3762   JvmtiExport::enter_start_phase();
3763 
3764   // Notify JVMTI agents that VM has started (JNI is up) - nop if no agents.
3765   JvmtiExport::post_vm_start();
3766 
3767   // Final system initialization including security manager and system class loader
3768   call_initPhase3(CHECK_JNI_ERR);
3769 
3770   // cache the system class loader
3771   SystemDictionary::compute_java_system_loader(CHECK_(JNI_ERR));
3772 
3773   // Always call even when there are not JVMTI environments yet, since environments
3774   // may be attached late and JVMTI must track phases of VM execution
3775   JvmtiExport::enter_live_phase();
3776 
3777   // Notify JVMTI agents that VM initialization is complete - nop if no agents.
3778   JvmtiExport::post_vm_initialized();
3779 
3780   if (TRACE_START() != JNI_OK) {
3781     vm_exit_during_initialization("Failed to start tracing backend.");
3782   }
3783 
3784 #if INCLUDE_MANAGEMENT
3785   Management::initialize(THREAD);
3786 
3787   if (HAS_PENDING_EXCEPTION) {
3788     // management agent fails to start possibly due to
3789     // configuration problem and is responsible for printing
3790     // stack trace if appropriate. Simply exit VM.
3791     vm_exit(1);
3792   }
3793 #endif // INCLUDE_MANAGEMENT
3794 
3795   if (Arguments::has_profile())       FlatProfiler::engage(main_thread, true);
3796   if (MemProfiling)                   MemProfiler::engage();
3797   StatSampler::engage();
3798   if (CheckJNICalls)                  JniPeriodicChecker::engage();
3799 
3800   BiasedLocking::init();
3801 
3802 #if INCLUDE_RTM_OPT
3803   RTMLockingCounters::init();
3804 #endif
3805 
3806   if (JDK_Version::current().post_vm_init_hook_enabled()) {
3807     call_postVMInitHook(THREAD);
3808     // The Java side of PostVMInitHook.run must deal with all
3809     // exceptions and provide means of diagnosis.
3810     if (HAS_PENDING_EXCEPTION) {
3811       CLEAR_PENDING_EXCEPTION;
3812     }
3813   }
3814 
3815   {
3816     MutexLocker ml(PeriodicTask_lock);
3817     // Make sure the WatcherThread can be started by WatcherThread::start()
3818     // or by dynamic enrollment.
3819     WatcherThread::make_startable();
3820     // Start up the WatcherThread if there are any periodic tasks
3821     // NOTE:  All PeriodicTasks should be registered by now. If they
3822     //   aren't, late joiners might appear to start slowly (we might
3823     //   take a while to process their first tick).
3824     if (PeriodicTask::num_tasks() &gt; 0) {
3825       WatcherThread::start();
3826     }
3827   }
3828 
3829   CodeCacheExtensions::complete_step(CodeCacheExtensionsSteps::CreateVM);
3830 
3831   create_vm_timer.end();
3832 #ifdef ASSERT
3833   _vm_complete = true;
3834 #endif
3835   return JNI_OK;
3836 }
3837 
3838 // type for the Agent_OnLoad and JVM_OnLoad entry points
3839 extern "C" {
3840   typedef jint (JNICALL *OnLoadEntry_t)(JavaVM *, char *, void *);
3841 }
3842 // Find a command line agent library and return its entry point for
3843 //         -agentlib:  -agentpath:   -Xrun
3844 // num_symbol_entries must be passed-in since only the caller knows the number of symbols in the array.
3845 static OnLoadEntry_t lookup_on_load(AgentLibrary* agent,
3846                                     const char *on_load_symbols[],
3847                                     size_t num_symbol_entries) {
3848   OnLoadEntry_t on_load_entry = NULL;
3849   void *library = NULL;
3850 
3851   if (!agent-&gt;valid()) {
3852     char buffer[JVM_MAXPATHLEN];
3853     char ebuf[1024] = "";
3854     const char *name = agent-&gt;name();
3855     const char *msg = "Could not find agent library ";
3856 
3857     // First check to see if agent is statically linked into executable
3858     if (os::find_builtin_agent(agent, on_load_symbols, num_symbol_entries)) {
3859       library = agent-&gt;os_lib();
3860     } else if (agent-&gt;is_absolute_path()) {
3861       library = os::dll_load(name, ebuf, sizeof ebuf);
3862       if (library == NULL) {
3863         const char *sub_msg = " in absolute path, with error: ";
3864         size_t len = strlen(msg) + strlen(name) + strlen(sub_msg) + strlen(ebuf) + 1;
3865         char *buf = NEW_C_HEAP_ARRAY(char, len, mtThread);
3866         jio_snprintf(buf, len, "%s%s%s%s", msg, name, sub_msg, ebuf);
3867         // If we can't find the agent, exit.
3868         vm_exit_during_initialization(buf, NULL);
3869         FREE_C_HEAP_ARRAY(char, buf);
3870       }
3871     } else {
3872       // Try to load the agent from the standard dll directory
3873       if (os::dll_build_name(buffer, sizeof(buffer), Arguments::get_dll_dir(),
3874                              name)) {
3875         library = os::dll_load(buffer, ebuf, sizeof ebuf);
3876       }
3877       if (library == NULL) { // Try the local directory
3878         char ns[1] = {0};
3879         if (os::dll_build_name(buffer, sizeof(buffer), ns, name)) {
3880           library = os::dll_load(buffer, ebuf, sizeof ebuf);
3881         }
3882         if (library == NULL) {
3883           const char *sub_msg = " on the library path, with error: ";
3884           size_t len = strlen(msg) + strlen(name) + strlen(sub_msg) + strlen(ebuf) + 1;
3885           char *buf = NEW_C_HEAP_ARRAY(char, len, mtThread);
3886           jio_snprintf(buf, len, "%s%s%s%s", msg, name, sub_msg, ebuf);
3887           // If we can't find the agent, exit.
3888           vm_exit_during_initialization(buf, NULL);
3889           FREE_C_HEAP_ARRAY(char, buf);
3890         }
3891       }
3892     }
3893     agent-&gt;set_os_lib(library);
3894     agent-&gt;set_valid();
3895   }
3896 
3897   // Find the OnLoad function.
3898   on_load_entry =
3899     CAST_TO_FN_PTR(OnLoadEntry_t, os::find_agent_function(agent,
3900                                                           false,
3901                                                           on_load_symbols,
3902                                                           num_symbol_entries));
3903   return on_load_entry;
3904 }
3905 
3906 // Find the JVM_OnLoad entry point
3907 static OnLoadEntry_t lookup_jvm_on_load(AgentLibrary* agent) {
3908   const char *on_load_symbols[] = JVM_ONLOAD_SYMBOLS;
3909   return lookup_on_load(agent, on_load_symbols, sizeof(on_load_symbols) / sizeof(char*));
3910 }
3911 
3912 // Find the Agent_OnLoad entry point
3913 static OnLoadEntry_t lookup_agent_on_load(AgentLibrary* agent) {
3914   const char *on_load_symbols[] = AGENT_ONLOAD_SYMBOLS;
3915   return lookup_on_load(agent, on_load_symbols, sizeof(on_load_symbols) / sizeof(char*));
3916 }
3917 
3918 // For backwards compatibility with -Xrun
3919 // Convert libraries with no JVM_OnLoad, but which have Agent_OnLoad to be
3920 // treated like -agentpath:
3921 // Must be called before agent libraries are created
3922 void Threads::convert_vm_init_libraries_to_agents() {
3923   AgentLibrary* agent;
3924   AgentLibrary* next;
3925 
3926   for (agent = Arguments::libraries(); agent != NULL; agent = next) {
3927     next = agent-&gt;next();  // cache the next agent now as this agent may get moved off this list
3928     OnLoadEntry_t on_load_entry = lookup_jvm_on_load(agent);
3929 
3930     // If there is an JVM_OnLoad function it will get called later,
3931     // otherwise see if there is an Agent_OnLoad
3932     if (on_load_entry == NULL) {
3933       on_load_entry = lookup_agent_on_load(agent);
3934       if (on_load_entry != NULL) {
3935         // switch it to the agent list -- so that Agent_OnLoad will be called,
3936         // JVM_OnLoad won't be attempted and Agent_OnUnload will
3937         Arguments::convert_library_to_agent(agent);
3938       } else {
3939         vm_exit_during_initialization("Could not find JVM_OnLoad or Agent_OnLoad function in the library", agent-&gt;name());
3940       }
3941     }
3942   }
3943 }
3944 
3945 // Create agents for -agentlib:  -agentpath:  and converted -Xrun
3946 // Invokes Agent_OnLoad
3947 // Called very early -- before JavaThreads exist
3948 void Threads::create_vm_init_agents() {
3949   extern struct JavaVM_ main_vm;
3950   AgentLibrary* agent;
3951 
3952   JvmtiExport::enter_onload_phase();
3953 
3954   for (agent = Arguments::agents(); agent != NULL; agent = agent-&gt;next()) {
3955     OnLoadEntry_t  on_load_entry = lookup_agent_on_load(agent);
3956 
3957     if (on_load_entry != NULL) {
3958       // Invoke the Agent_OnLoad function
3959       jint err = (*on_load_entry)(&amp;main_vm, agent-&gt;options(), NULL);
3960       if (err != JNI_OK) {
3961         vm_exit_during_initialization("agent library failed to init", agent-&gt;name());
3962       }
3963     } else {
3964       vm_exit_during_initialization("Could not find Agent_OnLoad function in the agent library", agent-&gt;name());
3965     }
3966   }
3967   JvmtiExport::enter_primordial_phase();
3968 }
3969 
3970 extern "C" {
3971   typedef void (JNICALL *Agent_OnUnload_t)(JavaVM *);
3972 }
3973 
3974 void Threads::shutdown_vm_agents() {
3975   // Send any Agent_OnUnload notifications
3976   const char *on_unload_symbols[] = AGENT_ONUNLOAD_SYMBOLS;
3977   size_t num_symbol_entries = ARRAY_SIZE(on_unload_symbols);
3978   extern struct JavaVM_ main_vm;
3979   for (AgentLibrary* agent = Arguments::agents(); agent != NULL; agent = agent-&gt;next()) {
3980 
3981     // Find the Agent_OnUnload function.
3982     Agent_OnUnload_t unload_entry = CAST_TO_FN_PTR(Agent_OnUnload_t,
3983                                                    os::find_agent_function(agent,
3984                                                    false,
3985                                                    on_unload_symbols,
3986                                                    num_symbol_entries));
3987 
3988     // Invoke the Agent_OnUnload function
3989     if (unload_entry != NULL) {
3990       JavaThread* thread = JavaThread::current();
3991       ThreadToNativeFromVM ttn(thread);
3992       HandleMark hm(thread);
3993       (*unload_entry)(&amp;main_vm);
3994     }
3995   }
3996 }
3997 
3998 // Called for after the VM is initialized for -Xrun libraries which have not been converted to agent libraries
3999 // Invokes JVM_OnLoad
4000 void Threads::create_vm_init_libraries() {
4001   extern struct JavaVM_ main_vm;
4002   AgentLibrary* agent;
4003 
4004   for (agent = Arguments::libraries(); agent != NULL; agent = agent-&gt;next()) {
4005     OnLoadEntry_t on_load_entry = lookup_jvm_on_load(agent);
4006 
4007     if (on_load_entry != NULL) {
4008       // Invoke the JVM_OnLoad function
4009       JavaThread* thread = JavaThread::current();
4010       ThreadToNativeFromVM ttn(thread);
4011       HandleMark hm(thread);
4012       jint err = (*on_load_entry)(&amp;main_vm, agent-&gt;options(), NULL);
4013       if (err != JNI_OK) {
4014         vm_exit_during_initialization("-Xrun library failed to init", agent-&gt;name());
4015       }
4016     } else {
4017       vm_exit_during_initialization("Could not find JVM_OnLoad function in -Xrun library", agent-&gt;name());
4018     }
4019   }
4020 }
4021 
4022 JavaThread* Threads::find_java_thread_from_java_tid(jlong java_tid) {
4023   assert(Threads_lock-&gt;owned_by_self(), "Must hold Threads_lock");
4024 
4025   JavaThread* java_thread = NULL;
4026   // Sequential search for now.  Need to do better optimization later.
4027   for (JavaThread* thread = Threads::first(); thread != NULL; thread = thread-&gt;next()) {
4028     oop tobj = thread-&gt;threadObj();
4029     if (!thread-&gt;is_exiting() &amp;&amp;
4030         tobj != NULL &amp;&amp;
4031         java_tid == java_lang_Thread::thread_id(tobj)) {
4032       java_thread = thread;
4033       break;
4034     }
4035   }
4036   return java_thread;
4037 }
4038 
4039 
4040 // Last thread running calls java.lang.Shutdown.shutdown()
4041 void JavaThread::invoke_shutdown_hooks() {
4042   HandleMark hm(this);
4043 
4044   // We could get here with a pending exception, if so clear it now.
4045   if (this-&gt;has_pending_exception()) {
4046     this-&gt;clear_pending_exception();
4047   }
4048 
4049   EXCEPTION_MARK;
4050   Klass* k =
4051     SystemDictionary::resolve_or_null(vmSymbols::java_lang_Shutdown(),
4052                                       THREAD);
4053   if (k != NULL) {
4054     // SystemDictionary::resolve_or_null will return null if there was
4055     // an exception.  If we cannot load the Shutdown class, just don't
4056     // call Shutdown.shutdown() at all.  This will mean the shutdown hooks
4057     // and finalizers (if runFinalizersOnExit is set) won't be run.
4058     // Note that if a shutdown hook was registered or runFinalizersOnExit
4059     // was called, the Shutdown class would have already been loaded
4060     // (Runtime.addShutdownHook and runFinalizersOnExit will load it).
4061     instanceKlassHandle shutdown_klass (THREAD, k);
4062     JavaValue result(T_VOID);
4063     JavaCalls::call_static(&amp;result,
4064                            shutdown_klass,
4065                            vmSymbols::shutdown_method_name(),
4066                            vmSymbols::void_method_signature(),
4067                            THREAD);
4068   }
4069   CLEAR_PENDING_EXCEPTION;
4070 }
4071 
4072 // Threads::destroy_vm() is normally called from jni_DestroyJavaVM() when
4073 // the program falls off the end of main(). Another VM exit path is through
4074 // vm_exit() when the program calls System.exit() to return a value or when
4075 // there is a serious error in VM. The two shutdown paths are not exactly
4076 // the same, but they share Shutdown.shutdown() at Java level and before_exit()
4077 // and VM_Exit op at VM level.
4078 //
4079 // Shutdown sequence:
4080 //   + Shutdown native memory tracking if it is on
4081 //   + Wait until we are the last non-daemon thread to execute
4082 //     &lt;-- every thing is still working at this moment --&gt;
4083 //   + Call java.lang.Shutdown.shutdown(), which will invoke Java level
4084 //        shutdown hooks, run finalizers if finalization-on-exit
4085 //   + Call before_exit(), prepare for VM exit
4086 //      &gt; run VM level shutdown hooks (they are registered through JVM_OnExit(),
4087 //        currently the only user of this mechanism is File.deleteOnExit())
4088 //      &gt; stop flat profiler, StatSampler, watcher thread, CMS threads,
4089 //        post thread end and vm death events to JVMTI,
4090 //        stop signal thread
4091 //   + Call JavaThread::exit(), it will:
4092 //      &gt; release JNI handle blocks, remove stack guard pages
4093 //      &gt; remove this thread from Threads list
4094 //     &lt;-- no more Java code from this thread after this point --&gt;
4095 //   + Stop VM thread, it will bring the remaining VM to a safepoint and stop
4096 //     the compiler threads at safepoint
4097 //     &lt;-- do not use anything that could get blocked by Safepoint --&gt;
4098 //   + Disable tracing at JNI/JVM barriers
4099 //   + Set _vm_exited flag for threads that are still running native code
4100 //   + Delete this thread
4101 //   + Call exit_globals()
4102 //      &gt; deletes tty
4103 //      &gt; deletes PerfMemory resources
4104 //   + Return to caller
4105 
4106 bool Threads::destroy_vm() {
4107   JavaThread* thread = JavaThread::current();
4108 
4109 #ifdef ASSERT
4110   _vm_complete = false;
4111 #endif
4112   // Wait until we are the last non-daemon thread to execute
4113   { MutexLocker nu(Threads_lock);
4114     while (Threads::number_of_non_daemon_threads() &gt; 1)
4115       // This wait should make safepoint checks, wait without a timeout,
4116       // and wait as a suspend-equivalent condition.
4117       //
4118       // Note: If the FlatProfiler is running and this thread is waiting
4119       // for another non-daemon thread to finish, then the FlatProfiler
4120       // is waiting for the external suspend request on this thread to
4121       // complete. wait_for_ext_suspend_completion() will eventually
4122       // timeout, but that takes time. Making this wait a suspend-
4123       // equivalent condition solves that timeout problem.
4124       //
4125       Threads_lock-&gt;wait(!Mutex::_no_safepoint_check_flag, 0,
4126                          Mutex::_as_suspend_equivalent_flag);
4127   }
4128 
4129   // Hang forever on exit if we are reporting an error.
4130   if (ShowMessageBoxOnError &amp;&amp; is_error_reported()) {
4131     os::infinite_sleep();
4132   }
4133   os::wait_for_keypress_at_exit();
4134 
4135   // run Java level shutdown hooks
4136   thread-&gt;invoke_shutdown_hooks();
4137 
4138   before_exit(thread);
4139 
4140   thread-&gt;exit(true);
4141 
4142   // Stop VM thread.
4143   {
4144     // 4945125 The vm thread comes to a safepoint during exit.
4145     // GC vm_operations can get caught at the safepoint, and the
4146     // heap is unparseable if they are caught. Grab the Heap_lock
4147     // to prevent this. The GC vm_operations will not be able to
4148     // queue until after the vm thread is dead. After this point,
4149     // we'll never emerge out of the safepoint before the VM exits.
4150 
4151     MutexLocker ml(Heap_lock);
4152 
4153     VMThread::wait_for_vm_thread_exit();
4154     assert(SafepointSynchronize::is_at_safepoint(), "VM thread should exit at Safepoint");
4155     VMThread::destroy();
4156   }
4157 
4158   // clean up ideal graph printers
4159 #if defined(COMPILER2) &amp;&amp; !defined(PRODUCT)
4160   IdealGraphPrinter::clean_up();
4161 #endif
4162 
4163   // Now, all Java threads are gone except daemon threads. Daemon threads
4164   // running Java code or in VM are stopped by the Safepoint. However,
4165   // daemon threads executing native code are still running.  But they
4166   // will be stopped at native=&gt;Java/VM barriers. Note that we can't
4167   // simply kill or suspend them, as it is inherently deadlock-prone.
4168 
4169   VM_Exit::set_vm_exited();
4170 
4171   notify_vm_shutdown();
4172 
4173   delete thread;
4174 
4175 #if INCLUDE_JVMCI
4176   if (JVMCICounterSize &gt; 0) {
4177     FREE_C_HEAP_ARRAY(jlong, JavaThread::_jvmci_old_thread_counters);
4178   }
4179 #endif
4180 
4181   // exit_globals() will delete tty
4182   exit_globals();
4183 
4184   LogConfiguration::finalize();
4185 
4186   return true;
4187 }
4188 
4189 
4190 jboolean Threads::is_supported_jni_version_including_1_1(jint version) {
4191   if (version == JNI_VERSION_1_1) return JNI_TRUE;
4192   return is_supported_jni_version(version);
4193 }
4194 
4195 
4196 jboolean Threads::is_supported_jni_version(jint version) {
4197   if (version == JNI_VERSION_1_2) return JNI_TRUE;
4198   if (version == JNI_VERSION_1_4) return JNI_TRUE;
4199   if (version == JNI_VERSION_1_6) return JNI_TRUE;
4200   if (version == JNI_VERSION_1_8) return JNI_TRUE;
4201   if (version == JNI_VERSION_9) return JNI_TRUE;
4202   return JNI_FALSE;
4203 }
4204 
4205 
4206 void Threads::add(JavaThread* p, bool force_daemon) {
4207   // The threads lock must be owned at this point
4208   assert_locked_or_safepoint(Threads_lock);
4209 
4210   // See the comment for this method in thread.hpp for its purpose and
4211   // why it is called here.
4212   p-&gt;initialize_queues();
4213   p-&gt;set_next(_thread_list);
4214   _thread_list = p;
4215   _number_of_threads++;
4216   oop threadObj = p-&gt;threadObj();
4217   bool daemon = true;
4218   // Bootstrapping problem: threadObj can be null for initial
4219   // JavaThread (or for threads attached via JNI)
4220   if ((!force_daemon) &amp;&amp; (threadObj == NULL || !java_lang_Thread::is_daemon(threadObj))) {
4221     _number_of_non_daemon_threads++;
4222     daemon = false;
4223   }
4224 
4225   ThreadService::add_thread(p, daemon);
4226 
4227   // Possible GC point.
4228   Events::log(p, "Thread added: " INTPTR_FORMAT, p2i(p));
4229 }
4230 
4231 void Threads::remove(JavaThread* p) {
4232   // Extra scope needed for Thread_lock, so we can check
4233   // that we do not remove thread without safepoint code notice
4234   { MutexLocker ml(Threads_lock);
4235 
4236     assert(includes(p), "p must be present");
4237 
4238     JavaThread* current = _thread_list;
4239     JavaThread* prev    = NULL;
4240 
4241     while (current != p) {
4242       prev    = current;
4243       current = current-&gt;next();
4244     }
4245 
4246     if (prev) {
4247       prev-&gt;set_next(current-&gt;next());
4248     } else {
4249       _thread_list = p-&gt;next();
4250     }
4251     _number_of_threads--;
4252     oop threadObj = p-&gt;threadObj();
4253     bool daemon = true;
4254     if (threadObj == NULL || !java_lang_Thread::is_daemon(threadObj)) {
4255       _number_of_non_daemon_threads--;
4256       daemon = false;
4257 
4258       // Only one thread left, do a notify on the Threads_lock so a thread waiting
4259       // on destroy_vm will wake up.
4260       if (number_of_non_daemon_threads() == 1) {
4261         Threads_lock-&gt;notify_all();
4262       }
4263     }
4264     ThreadService::remove_thread(p, daemon);
4265 
4266     // Make sure that safepoint code disregard this thread. This is needed since
4267     // the thread might mess around with locks after this point. This can cause it
4268     // to do callbacks into the safepoint code. However, the safepoint code is not aware
4269     // of this thread since it is removed from the queue.
4270     p-&gt;set_terminated_value();
4271   } // unlock Threads_lock
4272 
4273   // Since Events::log uses a lock, we grab it outside the Threads_lock
4274   Events::log(p, "Thread exited: " INTPTR_FORMAT, p2i(p));
4275 }
4276 
4277 // Threads_lock must be held when this is called (or must be called during a safepoint)
4278 bool Threads::includes(JavaThread* p) {
4279   assert(Threads_lock-&gt;is_locked(), "sanity check");
4280   ALL_JAVA_THREADS(q) {
4281     if (q == p) {
4282       return true;
4283     }
4284   }
4285   return false;
4286 }
4287 
4288 // Operations on the Threads list for GC.  These are not explicitly locked,
4289 // but the garbage collector must provide a safe context for them to run.
4290 // In particular, these things should never be called when the Threads_lock
4291 // is held by some other thread. (Note: the Safepoint abstraction also
4292 // uses the Threads_lock to guarantee this property. It also makes sure that
4293 // all threads gets blocked when exiting or starting).
4294 
4295 void Threads::oops_do(OopClosure* f, CodeBlobClosure* cf) {
4296   ALL_JAVA_THREADS(p) {
4297     p-&gt;oops_do(f, cf);
4298   }
4299   VMThread::vm_thread()-&gt;oops_do(f, cf);
4300 }
4301 
4302 void Threads::change_thread_claim_parity() {
4303   // Set the new claim parity.
4304   assert(_thread_claim_parity &gt;= 0 &amp;&amp; _thread_claim_parity &lt;= 2,
4305          "Not in range.");
4306   _thread_claim_parity++;
4307   if (_thread_claim_parity == 3) _thread_claim_parity = 1;
4308   assert(_thread_claim_parity &gt;= 1 &amp;&amp; _thread_claim_parity &lt;= 2,
4309          "Not in range.");
4310 }
4311 
4312 #ifdef ASSERT
4313 void Threads::assert_all_threads_claimed() {
4314   ALL_JAVA_THREADS(p) {
4315     const int thread_parity = p-&gt;oops_do_parity();
4316     assert((thread_parity == _thread_claim_parity),
4317            "Thread " PTR_FORMAT " has incorrect parity %d != %d", p2i(p), thread_parity, _thread_claim_parity);
4318   }
4319 }
4320 #endif // ASSERT
4321 
4322 void Threads::possibly_parallel_oops_do(bool is_par, OopClosure* f, CodeBlobClosure* cf) {
4323   int cp = Threads::thread_claim_parity();
4324   ALL_JAVA_THREADS(p) {
4325     if (p-&gt;claim_oops_do(is_par, cp)) {
4326       p-&gt;oops_do(f, cf);
4327     }
4328   }
4329   VMThread* vmt = VMThread::vm_thread();
4330   if (vmt-&gt;claim_oops_do(is_par, cp)) {
4331     vmt-&gt;oops_do(f, cf);
4332   }
4333 }
4334 
4335 #if INCLUDE_ALL_GCS
4336 // Used by ParallelScavenge
4337 void Threads::create_thread_roots_tasks(GCTaskQueue* q) {
4338   ALL_JAVA_THREADS(p) {
4339     q-&gt;enqueue(new ThreadRootsTask(p));
4340   }
4341   q-&gt;enqueue(new ThreadRootsTask(VMThread::vm_thread()));
4342 }
4343 
4344 // Used by Parallel Old
4345 void Threads::create_thread_roots_marking_tasks(GCTaskQueue* q) {
4346   ALL_JAVA_THREADS(p) {
4347     q-&gt;enqueue(new ThreadRootsMarkingTask(p));
4348   }
4349   q-&gt;enqueue(new ThreadRootsMarkingTask(VMThread::vm_thread()));
4350 }
4351 #endif // INCLUDE_ALL_GCS
4352 
4353 void Threads::nmethods_do(CodeBlobClosure* cf) {
4354   ALL_JAVA_THREADS(p) {
4355     // This is used by the code cache sweeper to mark nmethods that are active
4356     // on the stack of a Java thread. Ignore the sweeper thread itself to avoid
4357     // marking CodeCacheSweeperThread::_scanned_compiled_method as active.
4358     if(!p-&gt;is_Code_cache_sweeper_thread()) {
4359       p-&gt;nmethods_do(cf);
4360     }
4361   }
4362 }
4363 
4364 void Threads::metadata_do(void f(Metadata*)) {
4365   ALL_JAVA_THREADS(p) {
4366     p-&gt;metadata_do(f);
4367   }
4368 }
4369 
4370 class ThreadHandlesClosure : public ThreadClosure {
4371   void (*_f)(Metadata*);
4372  public:
4373   ThreadHandlesClosure(void f(Metadata*)) : _f(f) {}
4374   virtual void do_thread(Thread* thread) {
4375     thread-&gt;metadata_handles_do(_f);
4376   }
4377 };
4378 
4379 void Threads::metadata_handles_do(void f(Metadata*)) {
4380   // Only walk the Handles in Thread.
4381   ThreadHandlesClosure handles_closure(f);
4382   threads_do(&amp;handles_closure);
4383 }
4384 
4385 void Threads::deoptimized_wrt_marked_nmethods() {
4386   ALL_JAVA_THREADS(p) {
4387     p-&gt;deoptimized_wrt_marked_nmethods();
4388   }
4389 }
4390 
4391 
4392 // Get count Java threads that are waiting to enter the specified monitor.
4393 GrowableArray&lt;JavaThread*&gt;* Threads::get_pending_threads(int count,
4394                                                          address monitor,
4395                                                          bool doLock) {
4396   assert(doLock || SafepointSynchronize::is_at_safepoint(),
4397          "must grab Threads_lock or be at safepoint");
4398   GrowableArray&lt;JavaThread*&gt;* result = new GrowableArray&lt;JavaThread*&gt;(count);
4399 
4400   int i = 0;
4401   {
4402     MutexLockerEx ml(doLock ? Threads_lock : NULL);
4403     ALL_JAVA_THREADS(p) {
4404       if (!p-&gt;can_call_java()) continue;
4405 
4406       address pending = (address)p-&gt;current_pending_monitor();
4407       if (pending == monitor) {             // found a match
4408         if (i &lt; count) result-&gt;append(p);   // save the first count matches
4409         i++;
4410       }
4411     }
4412   }
4413   return result;
4414 }
4415 
4416 
4417 JavaThread *Threads::owning_thread_from_monitor_owner(address owner,
4418                                                       bool doLock) {
4419   assert(doLock ||
4420          Threads_lock-&gt;owned_by_self() ||
4421          SafepointSynchronize::is_at_safepoint(),
4422          "must grab Threads_lock or be at safepoint");
4423 
4424   // NULL owner means not locked so we can skip the search
4425   if (owner == NULL) return NULL;
4426 
4427   {
4428     MutexLockerEx ml(doLock ? Threads_lock : NULL);
4429     ALL_JAVA_THREADS(p) {
4430       // first, see if owner is the address of a Java thread
4431       if (owner == (address)p) return p;
4432     }
4433   }
4434   // Cannot assert on lack of success here since this function may be
4435   // used by code that is trying to report useful problem information
4436   // like deadlock detection.
4437   if (UseHeavyMonitors) return NULL;
4438 
4439   // If we didn't find a matching Java thread and we didn't force use of
4440   // heavyweight monitors, then the owner is the stack address of the
4441   // Lock Word in the owning Java thread's stack.
4442   //
4443   JavaThread* the_owner = NULL;
4444   {
4445     MutexLockerEx ml(doLock ? Threads_lock : NULL);
4446     ALL_JAVA_THREADS(q) {
4447       if (q-&gt;is_lock_owned(owner)) {
4448         the_owner = q;
4449         break;
4450       }
4451     }
4452   }
4453   // cannot assert on lack of success here; see above comment
4454   return the_owner;
4455 }
4456 
4457 // Threads::print_on() is called at safepoint by VM_PrintThreads operation.
4458 void Threads::print_on(outputStream* st, bool print_stacks,
4459                        bool internal_format, bool print_concurrent_locks) {
4460   char buf[32];
4461   st-&gt;print_raw_cr(os::local_time_string(buf, sizeof(buf)));
4462 
4463   st-&gt;print_cr("Full thread dump %s (%s %s):",
4464                Abstract_VM_Version::vm_name(),
4465                Abstract_VM_Version::vm_release(),
4466                Abstract_VM_Version::vm_info_string());
4467   st-&gt;cr();
4468 
4469 #if INCLUDE_SERVICES
4470   // Dump concurrent locks
4471   ConcurrentLocksDump concurrent_locks;
4472   if (print_concurrent_locks) {
4473     concurrent_locks.dump_at_safepoint();
4474   }
4475 #endif // INCLUDE_SERVICES
4476 
4477   ALL_JAVA_THREADS(p) {
4478     ResourceMark rm;
4479     p-&gt;print_on(st);
4480     if (print_stacks) {
4481       if (internal_format) {
4482         p-&gt;trace_stack();
4483       } else {
4484         p-&gt;print_stack_on(st);
4485       }
4486     }
4487     st-&gt;cr();
4488 #if INCLUDE_SERVICES
4489     if (print_concurrent_locks) {
4490       concurrent_locks.print_locks_on(p, st);
4491     }
4492 #endif // INCLUDE_SERVICES
4493   }
4494 
4495   VMThread::vm_thread()-&gt;print_on(st);
4496   st-&gt;cr();
4497   Universe::heap()-&gt;print_gc_threads_on(st);
4498   WatcherThread* wt = WatcherThread::watcher_thread();
4499   if (wt != NULL) {
4500     wt-&gt;print_on(st);
4501     st-&gt;cr();
4502   }
4503   st-&gt;flush();
4504 }
4505 
4506 void Threads::print_on_error(Thread* this_thread, outputStream* st, Thread* current, char* buf,
4507                              int buflen, bool* found_current) {
4508   if (this_thread != NULL) {
4509     bool is_current = (current == this_thread);
4510     *found_current = *found_current || is_current;
4511     st-&gt;print("%s", is_current ? "=&gt;" : "  ");
4512 
4513     st-&gt;print(PTR_FORMAT, p2i(this_thread));
4514     st-&gt;print(" ");
4515     this_thread-&gt;print_on_error(st, buf, buflen);
4516     st-&gt;cr();
4517   }
4518 }
4519 
4520 class PrintOnErrorClosure : public ThreadClosure {
4521   outputStream* _st;
4522   Thread* _current;
4523   char* _buf;
4524   int _buflen;
4525   bool* _found_current;
4526  public:
4527   PrintOnErrorClosure(outputStream* st, Thread* current, char* buf,
4528                       int buflen, bool* found_current) :
4529    _st(st), _current(current), _buf(buf), _buflen(buflen), _found_current(found_current) {}
4530 
4531   virtual void do_thread(Thread* thread) {
4532     Threads::print_on_error(thread, _st, _current, _buf, _buflen, _found_current);
4533   }
4534 };
4535 
4536 // Threads::print_on_error() is called by fatal error handler. It's possible
4537 // that VM is not at safepoint and/or current thread is inside signal handler.
4538 // Don't print stack trace, as the stack may not be walkable. Don't allocate
4539 // memory (even in resource area), it might deadlock the error handler.
4540 void Threads::print_on_error(outputStream* st, Thread* current, char* buf,
4541                              int buflen) {
4542   bool found_current = false;
4543   st-&gt;print_cr("Java Threads: ( =&gt; current thread )");
4544   ALL_JAVA_THREADS(thread) {
4545     print_on_error(thread, st, current, buf, buflen, &amp;found_current);
4546   }
4547   st-&gt;cr();
4548 
4549   st-&gt;print_cr("Other Threads:");
4550   print_on_error(VMThread::vm_thread(), st, current, buf, buflen, &amp;found_current);
4551   print_on_error(WatcherThread::watcher_thread(), st, current, buf, buflen, &amp;found_current);
4552 
4553   PrintOnErrorClosure print_closure(st, current, buf, buflen, &amp;found_current);
4554   Universe::heap()-&gt;gc_threads_do(&amp;print_closure);
4555 
4556   if (!found_current) {
4557     st-&gt;cr();
4558     st-&gt;print("=&gt;" PTR_FORMAT " (exited) ", p2i(current));
4559     current-&gt;print_on_error(st, buf, buflen);
4560     st-&gt;cr();
4561   }
4562   st-&gt;cr();
4563   st-&gt;print_cr("Threads with active compile tasks:");
4564   print_threads_compiling(st, buf, buflen);
4565 }
4566 
4567 void Threads::print_threads_compiling(outputStream* st, char* buf, int buflen) {
4568   ALL_JAVA_THREADS(thread) {
4569     if (thread-&gt;is_Compiler_thread()) {
4570       CompilerThread* ct = (CompilerThread*) thread;
4571       if (ct-&gt;task() != NULL) {
4572         thread-&gt;print_name_on_error(st, buf, buflen);
4573         ct-&gt;task()-&gt;print(st, NULL, true, true);
4574       }
4575     }
4576   }
4577 }
4578 
4579 
4580 // Internal SpinLock and Mutex
4581 // Based on ParkEvent
4582 
4583 // Ad-hoc mutual exclusion primitives: SpinLock and Mux
4584 //
4585 // We employ SpinLocks _only for low-contention, fixed-length
4586 // short-duration critical sections where we're concerned
4587 // about native mutex_t or HotSpot Mutex:: latency.
4588 // The mux construct provides a spin-then-block mutual exclusion
4589 // mechanism.
4590 //
4591 // Testing has shown that contention on the ListLock guarding gFreeList
4592 // is common.  If we implement ListLock as a simple SpinLock it's common
4593 // for the JVM to devolve to yielding with little progress.  This is true
4594 // despite the fact that the critical sections protected by ListLock are
4595 // extremely short.
4596 //
4597 // TODO-FIXME: ListLock should be of type SpinLock.
4598 // We should make this a 1st-class type, integrated into the lock
4599 // hierarchy as leaf-locks.  Critically, the SpinLock structure
4600 // should have sufficient padding to avoid false-sharing and excessive
4601 // cache-coherency traffic.
4602 
4603 
4604 typedef volatile int SpinLockT;
4605 
4606 void Thread::SpinAcquire(volatile int * adr, const char * LockName) {
4607   if (Atomic::cmpxchg (1, adr, 0) == 0) {
4608     return;   // normal fast-path return
4609   }
4610 
4611   // Slow-path : We've encountered contention -- Spin/Yield/Block strategy.
4612   TEVENT(SpinAcquire - ctx);
4613   int ctr = 0;
4614   int Yields = 0;
4615   for (;;) {
4616     while (*adr != 0) {
4617       ++ctr;
4618       if ((ctr &amp; 0xFFF) == 0 || !os::is_MP()) {
4619         if (Yields &gt; 5) {
4620           os::naked_short_sleep(1);
4621         } else {
4622           os::naked_yield();
4623           ++Yields;
4624         }
4625       } else {
4626         SpinPause();
4627       }
4628     }
4629     if (Atomic::cmpxchg(1, adr, 0) == 0) return;
4630   }
4631 }
4632 
4633 void Thread::SpinRelease(volatile int * adr) {
4634   assert(*adr != 0, "invariant");
4635   OrderAccess::fence();      // guarantee at least release consistency.
4636   // Roach-motel semantics.
4637   // It's safe if subsequent LDs and STs float "up" into the critical section,
4638   // but prior LDs and STs within the critical section can't be allowed
4639   // to reorder or float past the ST that releases the lock.
4640   // Loads and stores in the critical section - which appear in program
4641   // order before the store that releases the lock - must also appear
4642   // before the store that releases the lock in memory visibility order.
4643   // Conceptually we need a #loadstore|#storestore "release" MEMBAR before
4644   // the ST of 0 into the lock-word which releases the lock, so fence
4645   // more than covers this on all platforms.
4646   *adr = 0;
4647 }
4648 
4649 // muxAcquire and muxRelease:
4650 //
4651 // *  muxAcquire and muxRelease support a single-word lock-word construct.
4652 //    The LSB of the word is set IFF the lock is held.
4653 //    The remainder of the word points to the head of a singly-linked list
4654 //    of threads blocked on the lock.
4655 //
4656 // *  The current implementation of muxAcquire-muxRelease uses its own
4657 //    dedicated Thread._MuxEvent instance.  If we're interested in
4658 //    minimizing the peak number of extant ParkEvent instances then
4659 //    we could eliminate _MuxEvent and "borrow" _ParkEvent as long
4660 //    as certain invariants were satisfied.  Specifically, care would need
4661 //    to be taken with regards to consuming unpark() "permits".
4662 //    A safe rule of thumb is that a thread would never call muxAcquire()
4663 //    if it's enqueued (cxq, EntryList, WaitList, etc) and will subsequently
4664 //    park().  Otherwise the _ParkEvent park() operation in muxAcquire() could
4665 //    consume an unpark() permit intended for monitorenter, for instance.
4666 //    One way around this would be to widen the restricted-range semaphore
4667 //    implemented in park().  Another alternative would be to provide
4668 //    multiple instances of the PlatformEvent() for each thread.  One
4669 //    instance would be dedicated to muxAcquire-muxRelease, for instance.
4670 //
4671 // *  Usage:
4672 //    -- Only as leaf locks
4673 //    -- for short-term locking only as muxAcquire does not perform
4674 //       thread state transitions.
4675 //
4676 // Alternatives:
4677 // *  We could implement muxAcquire and muxRelease with MCS or CLH locks
4678 //    but with parking or spin-then-park instead of pure spinning.
4679 // *  Use Taura-Oyama-Yonenzawa locks.
4680 // *  It's possible to construct a 1-0 lock if we encode the lockword as
4681 //    (List,LockByte).  Acquire will CAS the full lockword while Release
4682 //    will STB 0 into the LockByte.  The 1-0 scheme admits stranding, so
4683 //    acquiring threads use timers (ParkTimed) to detect and recover from
4684 //    the stranding window.  Thread/Node structures must be aligned on 256-byte
4685 //    boundaries by using placement-new.
4686 // *  Augment MCS with advisory back-link fields maintained with CAS().
4687 //    Pictorially:  LockWord -&gt; T1 &lt;-&gt; T2 &lt;-&gt; T3 &lt;-&gt; ... &lt;-&gt; Tn &lt;-&gt; Owner.
4688 //    The validity of the backlinks must be ratified before we trust the value.
4689 //    If the backlinks are invalid the exiting thread must back-track through the
4690 //    the forward links, which are always trustworthy.
4691 // *  Add a successor indication.  The LockWord is currently encoded as
4692 //    (List, LOCKBIT:1).  We could also add a SUCCBIT or an explicit _succ variable
4693 //    to provide the usual futile-wakeup optimization.
4694 //    See RTStt for details.
4695 // *  Consider schedctl.sc_nopreempt to cover the critical section.
4696 //
4697 
4698 
4699 typedef volatile intptr_t MutexT;      // Mux Lock-word
4700 enum MuxBits { LOCKBIT = 1 };
4701 
4702 void Thread::muxAcquire(volatile intptr_t * Lock, const char * LockName) {
4703   intptr_t w = Atomic::cmpxchg_ptr(LOCKBIT, Lock, 0);
4704   if (w == 0) return;
4705   if ((w &amp; LOCKBIT) == 0 &amp;&amp; Atomic::cmpxchg_ptr (w|LOCKBIT, Lock, w) == w) {
4706     return;
4707   }
4708 
4709   TEVENT(muxAcquire - Contention);
4710   ParkEvent * const Self = Thread::current()-&gt;_MuxEvent;
4711   assert((intptr_t(Self) &amp; LOCKBIT) == 0, "invariant");
4712   for (;;) {
4713     int its = (os::is_MP() ? 100 : 0) + 1;
4714 
4715     // Optional spin phase: spin-then-park strategy
4716     while (--its &gt;= 0) {
4717       w = *Lock;
4718       if ((w &amp; LOCKBIT) == 0 &amp;&amp; Atomic::cmpxchg_ptr (w|LOCKBIT, Lock, w) == w) {
4719         return;
4720       }
4721     }
4722 
4723     Self-&gt;reset();
4724     Self-&gt;OnList = intptr_t(Lock);
4725     // The following fence() isn't _strictly necessary as the subsequent
4726     // CAS() both serializes execution and ratifies the fetched *Lock value.
4727     OrderAccess::fence();
4728     for (;;) {
4729       w = *Lock;
4730       if ((w &amp; LOCKBIT) == 0) {
4731         if (Atomic::cmpxchg_ptr (w|LOCKBIT, Lock, w) == w) {
4732           Self-&gt;OnList = 0;   // hygiene - allows stronger asserts
4733           return;
4734         }
4735         continue;      // Interference -- *Lock changed -- Just retry
4736       }
4737       assert(w &amp; LOCKBIT, "invariant");
4738       Self-&gt;ListNext = (ParkEvent *) (w &amp; ~LOCKBIT);
4739       if (Atomic::cmpxchg_ptr(intptr_t(Self)|LOCKBIT, Lock, w) == w) break;
4740     }
4741 
4742     while (Self-&gt;OnList != 0) {
4743       Self-&gt;park();
4744     }
4745   }
4746 }
4747 
4748 void Thread::muxAcquireW(volatile intptr_t * Lock, ParkEvent * ev) {
4749   intptr_t w = Atomic::cmpxchg_ptr(LOCKBIT, Lock, 0);
4750   if (w == 0) return;
4751   if ((w &amp; LOCKBIT) == 0 &amp;&amp; Atomic::cmpxchg_ptr (w|LOCKBIT, Lock, w) == w) {
4752     return;
4753   }
4754 
4755   TEVENT(muxAcquire - Contention);
4756   ParkEvent * ReleaseAfter = NULL;
4757   if (ev == NULL) {
4758     ev = ReleaseAfter = ParkEvent::Allocate(NULL);
4759   }
4760   assert((intptr_t(ev) &amp; LOCKBIT) == 0, "invariant");
4761   for (;;) {
4762     guarantee(ev-&gt;OnList == 0, "invariant");
4763     int its = (os::is_MP() ? 100 : 0) + 1;
4764 
4765     // Optional spin phase: spin-then-park strategy
4766     while (--its &gt;= 0) {
4767       w = *Lock;
4768       if ((w &amp; LOCKBIT) == 0 &amp;&amp; Atomic::cmpxchg_ptr (w|LOCKBIT, Lock, w) == w) {
4769         if (ReleaseAfter != NULL) {
4770           ParkEvent::Release(ReleaseAfter);
4771         }
4772         return;
4773       }
4774     }
4775 
4776     ev-&gt;reset();
4777     ev-&gt;OnList = intptr_t(Lock);
4778     // The following fence() isn't _strictly necessary as the subsequent
4779     // CAS() both serializes execution and ratifies the fetched *Lock value.
4780     OrderAccess::fence();
4781     for (;;) {
4782       w = *Lock;
4783       if ((w &amp; LOCKBIT) == 0) {
4784         if (Atomic::cmpxchg_ptr (w|LOCKBIT, Lock, w) == w) {
4785           ev-&gt;OnList = 0;
4786           // We call ::Release while holding the outer lock, thus
4787           // artificially lengthening the critical section.
4788           // Consider deferring the ::Release() until the subsequent unlock(),
4789           // after we've dropped the outer lock.
4790           if (ReleaseAfter != NULL) {
4791             ParkEvent::Release(ReleaseAfter);
4792           }
4793           return;
4794         }
4795         continue;      // Interference -- *Lock changed -- Just retry
4796       }
4797       assert(w &amp; LOCKBIT, "invariant");
4798       ev-&gt;ListNext = (ParkEvent *) (w &amp; ~LOCKBIT);
4799       if (Atomic::cmpxchg_ptr(intptr_t(ev)|LOCKBIT, Lock, w) == w) break;
4800     }
4801 
4802     while (ev-&gt;OnList != 0) {
4803       ev-&gt;park();
4804     }
4805   }
4806 }
4807 
4808 // Release() must extract a successor from the list and then wake that thread.
4809 // It can "pop" the front of the list or use a detach-modify-reattach (DMR) scheme
4810 // similar to that used by ParkEvent::Allocate() and ::Release().  DMR-based
4811 // Release() would :
4812 // (A) CAS() or swap() null to *Lock, releasing the lock and detaching the list.
4813 // (B) Extract a successor from the private list "in-hand"
4814 // (C) attempt to CAS() the residual back into *Lock over null.
4815 //     If there were any newly arrived threads and the CAS() would fail.
4816 //     In that case Release() would detach the RATs, re-merge the list in-hand
4817 //     with the RATs and repeat as needed.  Alternately, Release() might
4818 //     detach and extract a successor, but then pass the residual list to the wakee.
4819 //     The wakee would be responsible for reattaching and remerging before it
4820 //     competed for the lock.
4821 //
4822 // Both "pop" and DMR are immune from ABA corruption -- there can be
4823 // multiple concurrent pushers, but only one popper or detacher.
4824 // This implementation pops from the head of the list.  This is unfair,
4825 // but tends to provide excellent throughput as hot threads remain hot.
4826 // (We wake recently run threads first).
4827 //
4828 // All paths through muxRelease() will execute a CAS.
4829 // Release consistency -- We depend on the CAS in muxRelease() to provide full
4830 // bidirectional fence/MEMBAR semantics, ensuring that all prior memory operations
4831 // executed within the critical section are complete and globally visible before the
4832 // store (CAS) to the lock-word that releases the lock becomes globally visible.
4833 void Thread::muxRelease(volatile intptr_t * Lock)  {
4834   for (;;) {
4835     const intptr_t w = Atomic::cmpxchg_ptr(0, Lock, LOCKBIT);
4836     assert(w &amp; LOCKBIT, "invariant");
4837     if (w == LOCKBIT) return;
4838     ParkEvent * const List = (ParkEvent *) (w &amp; ~LOCKBIT);
4839     assert(List != NULL, "invariant");
4840     assert(List-&gt;OnList == intptr_t(Lock), "invariant");
4841     ParkEvent * const nxt = List-&gt;ListNext;
4842     guarantee((intptr_t(nxt) &amp; LOCKBIT) == 0, "invariant");
4843 
4844     // The following CAS() releases the lock and pops the head element.
4845     // The CAS() also ratifies the previously fetched lock-word value.
4846     if (Atomic::cmpxchg_ptr (intptr_t(nxt), Lock, w) != w) {
4847       continue;
4848     }
4849     List-&gt;OnList = 0;
4850     OrderAccess::fence();
4851     List-&gt;unpark();
4852     return;
4853   }
4854 }
4855 
4856 
4857 void Threads::verify() {
4858   ALL_JAVA_THREADS(p) {
4859     p-&gt;verify();
4860   }
4861   VMThread* thread = VMThread::vm_thread();
4862   if (thread != NULL) thread-&gt;verify();
4863 }
</pre></body></html>
