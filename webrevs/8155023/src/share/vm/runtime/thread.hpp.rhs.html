<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta charset="utf-8">
<meta http-equiv="cache-control" content="no-cache" />
<meta http-equiv="Pragma" content="no-cache" />
<meta http-equiv="Expires" content="-1" />
<!--
   Note to customizers: the body of the webrev is IDed as SUNWwebrev
   to allow easy overriding by users of webrev via the userContent.css
   mechanism available in some browsers.

   For example, to have all "removed" information be red instead of
   brown, set a rule in your userContent.css file like:

       body#SUNWwebrev span.removed { color: red ! important; }
-->
<style type="text/css" media="screen">
body {
    background-color: #eeeeee;
}
hr {
    border: none 0;
    border-top: 1px solid #aaa;
    height: 1px;
}
div.summary {
    font-size: .8em;
    border-bottom: 1px solid #aaa;
    padding-left: 1em;
    padding-right: 1em;
}
div.summary h2 {
    margin-bottom: 0.3em;
}
div.summary table th {
    text-align: right;
    vertical-align: top;
    white-space: nowrap;
}
span.lineschanged {
    font-size: 0.7em;
}
span.oldmarker {
    color: red;
    font-size: large;
    font-weight: bold;
}
span.newmarker {
    color: green;
    font-size: large;
    font-weight: bold;
}
span.removed {
    color: brown;
}
span.changed {
    color: blue;
}
span.new {
    color: blue;
    font-weight: bold;
}
a.print { font-size: x-small; }

</style>

<style type="text/css" media="print">
pre { font-size: 0.8em; font-family: courier, monospace; }
span.removed { color: #444; font-style: italic }
span.changed { font-weight: bold; }
span.new { font-weight: bold; }
span.newmarker { font-size: 1.2em; font-weight: bold; }
span.oldmarker { font-size: 1.2em; font-weight: bold; }
a.print {display: none}
hr { border: none 0; border-top: 1px solid #aaa; height: 1px; }
</style>

    <script type="text/javascript" src="../../../../ancnav.js"></script>
    </head>
    <body id="SUNWwebrev" onkeypress="keypress(event);">
    <a name="0"></a>
    <pre></pre><hr></hr>
<pre>
   1 /*
   2  * Copyright (c) 1997, 2016, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #ifndef SHARE_VM_RUNTIME_THREAD_HPP
  26 #define SHARE_VM_RUNTIME_THREAD_HPP
  27 
  28 #include "gc/shared/threadLocalAllocBuffer.hpp"
  29 #include "memory/allocation.hpp"
  30 #include "oops/oop.hpp"
  31 #include "prims/jni.h"
  32 #include "prims/jvmtiExport.hpp"
  33 #include "runtime/frame.hpp"
  34 #include "runtime/javaFrameAnchor.hpp"
  35 #include "runtime/jniHandles.hpp"
  36 #include "runtime/mutexLocker.hpp"
  37 #include "runtime/os.hpp"
  38 #include "runtime/osThread.hpp"
  39 #include "runtime/park.hpp"
  40 #include "runtime/safepoint.hpp"
  41 #include "runtime/stubRoutines.hpp"
  42 #include "runtime/threadLocalStorage.hpp"
  43 #include "runtime/thread_ext.hpp"
  44 #include "runtime/unhandledOops.hpp"
  45 #include "trace/traceBackend.hpp"
  46 #include "trace/traceMacros.hpp"
  47 #include "utilities/exceptions.hpp"
  48 #include "utilities/macros.hpp"
  49 #if INCLUDE_ALL_GCS
  50 #include "gc/g1/dirtyCardQueue.hpp"
  51 #include "gc/g1/satbMarkQueue.hpp"
  52 #endif // INCLUDE_ALL_GCS
  53 #ifdef TARGET_ARCH_zero
  54 # include "stack_zero.hpp"
  55 #endif
  56 
  57 class ThreadSafepointState;
  58 class ThreadProfiler;
  59 
  60 class JvmtiThreadState;
  61 class JvmtiGetLoadedClassesClosure;
  62 class ThreadStatistics;
  63 class ConcurrentLocksDump;
  64 class ParkEvent;
  65 class Parker;
  66 
  67 class ciEnv;
  68 class CompileThread;
  69 class CompileLog;
  70 class CompileTask;
  71 class CompileQueue;
  72 class CompilerCounters;
  73 class vframeArray;
  74 
  75 class DeoptResourceMark;
  76 class jvmtiDeferredLocalVariableSet;
  77 
  78 class GCTaskQueue;
  79 class ThreadClosure;
  80 class IdealGraphPrinter;
  81 
  82 class Metadata;
  83 template &lt;class T, MEMFLAGS F&gt; class ChunkedList;
  84 typedef ChunkedList&lt;Metadata*, mtInternal&gt; MetadataOnStackBuffer;
  85 
  86 DEBUG_ONLY(class ResourceMark;)
  87 
  88 class WorkerThread;
  89 
  90 // Class hierarchy
  91 // - Thread
  92 //   - NamedThread
  93 //     - VMThread
  94 //     - ConcurrentGCThread
  95 //     - WorkerThread
  96 //       - GangWorker
  97 //       - GCTaskThread
  98 //   - JavaThread
  99 //   - WatcherThread
 100 
 101 class Thread: public ThreadShadow {
 102   friend class VMStructs;
 103   friend class JVMCIVMStructs;
 104  private:
 105 
 106 #ifndef USE_LIBRARY_BASED_TLS_ONLY
 107   // Current thread is maintained as a thread-local variable
 108   static THREAD_LOCAL_DECL Thread* _thr_current;
 109 #endif
 110 
 111   // Exception handling
 112   // (Note: _pending_exception and friends are in ThreadShadow)
 113   //oop       _pending_exception;                // pending exception for current thread
 114   // const char* _exception_file;                   // file information for exception (debugging only)
 115   // int         _exception_line;                   // line information for exception (debugging only)
 116  protected:
 117   // Support for forcing alignment of thread objects for biased locking
 118   void*       _real_malloc_address;
 119  public:
 120   void* operator new(size_t size) throw() { return allocate(size, true); }
 121   void* operator new(size_t size, const std::nothrow_t&amp; nothrow_constant) throw() {
 122     return allocate(size, false); }
 123   void  operator delete(void* p);
 124 
 125  protected:
 126   static void* allocate(size_t size, bool throw_excpt, MEMFLAGS flags = mtThread);
 127  private:
 128 
 129   // ***************************************************************
 130   // Suspend and resume support
 131   // ***************************************************************
 132   //
 133   // VM suspend/resume no longer exists - it was once used for various
 134   // things including safepoints but was deprecated and finally removed
 135   // in Java 7. Because VM suspension was considered "internal" Java-level
 136   // suspension was considered "external", and this legacy naming scheme
 137   // remains.
 138   //
 139   // External suspend/resume requests come from JVM_SuspendThread,
 140   // JVM_ResumeThread, JVMTI SuspendThread, and finally JVMTI
 141   // ResumeThread. External
 142   // suspend requests cause _external_suspend to be set and external
 143   // resume requests cause _external_suspend to be cleared.
 144   // External suspend requests do not nest on top of other external
 145   // suspend requests. The higher level APIs reject suspend requests
 146   // for already suspended threads.
 147   //
 148   // The external_suspend
 149   // flag is checked by has_special_runtime_exit_condition() and java thread
 150   // will self-suspend when handle_special_runtime_exit_condition() is
 151   // called. Most uses of the _thread_blocked state in JavaThreads are
 152   // considered the same as being externally suspended; if the blocking
 153   // condition lifts, the JavaThread will self-suspend. Other places
 154   // where VM checks for external_suspend include:
 155   //   + mutex granting (do not enter monitors when thread is suspended)
 156   //   + state transitions from _thread_in_native
 157   //
 158   // In general, java_suspend() does not wait for an external suspend
 159   // request to complete. When it returns, the only guarantee is that
 160   // the _external_suspend field is true.
 161   //
 162   // wait_for_ext_suspend_completion() is used to wait for an external
 163   // suspend request to complete. External suspend requests are usually
 164   // followed by some other interface call that requires the thread to
 165   // be quiescent, e.g., GetCallTrace(). By moving the "wait time" into
 166   // the interface that requires quiescence, we give the JavaThread a
 167   // chance to self-suspend before we need it to be quiescent. This
 168   // improves overall suspend/query performance.
 169   //
 170   // _suspend_flags controls the behavior of java_ suspend/resume.
 171   // It must be set under the protection of SR_lock. Read from the flag is
 172   // OK without SR_lock as long as the value is only used as a hint.
 173   // (e.g., check _external_suspend first without lock and then recheck
 174   // inside SR_lock and finish the suspension)
 175   //
 176   // _suspend_flags is also overloaded for other "special conditions" so
 177   // that a single check indicates whether any special action is needed
 178   // eg. for async exceptions.
 179   // -------------------------------------------------------------------
 180   // Notes:
 181   // 1. The suspend/resume logic no longer uses ThreadState in OSThread
 182   // but we still update its value to keep other part of the system (mainly
 183   // JVMTI) happy. ThreadState is legacy code (see notes in
 184   // osThread.hpp).
 185   //
 186   // 2. It would be more natural if set_external_suspend() is private and
 187   // part of java_suspend(), but that probably would affect the suspend/query
 188   // performance. Need more investigation on this.
 189 
 190   // suspend/resume lock: used for self-suspend
 191   Monitor* _SR_lock;
 192 
 193  protected:
 194   enum SuspendFlags {
 195     // NOTE: avoid using the sign-bit as cc generates different test code
 196     //       when the sign-bit is used, and sometimes incorrectly - see CR 6398077
 197 
 198     _external_suspend       = 0x20000000U, // thread is asked to self suspend
 199     _ext_suspended          = 0x40000000U, // thread has self-suspended
 200     _deopt_suspend          = 0x10000000U, // thread needs to self suspend for deopt
 201 
 202     _has_async_exception    = 0x00000001U, // there is a pending async exception
 203     _critical_native_unlock = 0x00000002U  // Must call back to unlock JNI critical lock
 204   };
 205 
 206   // various suspension related flags - atomically updated
 207   // overloaded for async exception checking in check_special_condition_for_native_trans.
 208   volatile uint32_t _suspend_flags;
 209 
 210  private:
 211   int _num_nested_signal;
 212 
 213   DEBUG_ONLY(bool _suspendible_thread;)
 214 
 215  public:
 216   void enter_signal_handler() { _num_nested_signal++; }
 217   void leave_signal_handler() { _num_nested_signal--; }
 218   bool is_inside_signal_handler() const { return _num_nested_signal &gt; 0; }
 219 
 220 #ifdef ASSERT
 221   void set_suspendible_thread() {
 222     _suspendible_thread = true;
 223   }
 224 
 225   void clear_suspendible_thread() {
 226     _suspendible_thread = false;
 227   }
 228 
 229   bool is_suspendible_thread() { return _suspendible_thread; }
 230 #endif
 231 
 232  private:
 233   // Active_handles points to a block of handles
 234   JNIHandleBlock* _active_handles;
 235 
 236   // One-element thread local free list
 237   JNIHandleBlock* _free_handle_block;
 238 
 239   // Point to the last handle mark
 240   HandleMark* _last_handle_mark;
 241 
 242   // The parity of the last strong_roots iteration in which this thread was
 243   // claimed as a task.
 244   jint _oops_do_parity;
 245 
 246  public:
 247   void set_last_handle_mark(HandleMark* mark)   { _last_handle_mark = mark; }
 248   HandleMark* last_handle_mark() const          { return _last_handle_mark; }
 249  private:
 250 
 251   // debug support for checking if code does allow safepoints or not
 252   // GC points in the VM can happen because of allocation, invoking a VM operation, or blocking on
 253   // mutex, or blocking on an object synchronizer (Java locking).
 254   // If !allow_safepoint(), then an assertion failure will happen in any of the above cases
 255   // If !allow_allocation(), then an assertion failure will happen during allocation
 256   // (Hence, !allow_safepoint() =&gt; !allow_allocation()).
 257   //
 258   // The two classes NoSafepointVerifier and No_Allocation_Verifier are used to set these counters.
 259   //
 260   NOT_PRODUCT(int _allow_safepoint_count;)      // If 0, thread allow a safepoint to happen
 261   debug_only(int _allow_allocation_count;)     // If 0, the thread is allowed to allocate oops.
 262 
 263   // Used by SkipGCALot class.
 264   NOT_PRODUCT(bool _skip_gcalot;)               // Should we elide gc-a-lot?
 265 
 266   friend class NoAllocVerifier;
 267   friend class NoSafepointVerifier;
 268   friend class PauseNoSafepointVerifier;
 269   friend class GCLocker;
 270 
 271   ThreadLocalAllocBuffer _tlab;                 // Thread-local eden
 272   jlong _allocated_bytes;                       // Cumulative number of bytes allocated on
 273                                                 // the Java heap
 274 
 275   mutable TRACE_DATA _trace_data;               // Thread-local data for tracing
 276 
 277   ThreadExt _ext;
 278 
 279   int   _vm_operation_started_count;            // VM_Operation support
 280   int   _vm_operation_completed_count;          // VM_Operation support
 281 
 282   ObjectMonitor* _current_pending_monitor;      // ObjectMonitor this thread
 283                                                 // is waiting to lock
 284   bool _current_pending_monitor_is_from_java;   // locking is from Java code
 285 
 286   // ObjectMonitor on which this thread called Object.wait()
 287   ObjectMonitor* _current_waiting_monitor;
 288 
 289   // Private thread-local objectmonitor list - a simple cache organized as a SLL.
 290  public:
 291   ObjectMonitor* omFreeList;
 292   int omFreeCount;                              // length of omFreeList
 293   int omFreeProvision;                          // reload chunk size
 294   ObjectMonitor* omInUseList;                   // SLL to track monitors in circulation
 295   int omInUseCount;                             // length of omInUseList
 296 
 297 #ifdef ASSERT
 298  private:
 299   bool _visited_for_critical_count;
 300 
 301  public:
 302   void set_visited_for_critical_count(bool z) { _visited_for_critical_count = z; }
 303   bool was_visited_for_critical_count() const   { return _visited_for_critical_count; }
 304 #endif
 305 
 306  public:
 307   enum {
 308     is_definitely_current_thread = true
 309   };
 310 
 311   // Constructor
 312   Thread();
 313   virtual ~Thread();
 314 
 315   // Manage Thread::current()
 316   void initialize_thread_current();
 317   private:
 318   void clear_thread_current(); // needed for detaching JNI threads
 319 
 320   public:
 321   // thread entry point
 322   virtual void run();
 323 
 324   // Testers
 325   virtual bool is_VM_thread()       const            { return false; }
 326   virtual bool is_Java_thread()     const            { return false; }
 327   virtual bool is_Compiler_thread() const            { return false; }
 328   virtual bool is_Code_cache_sweeper_thread() const  { return false; }
 329   virtual bool is_hidden_from_external_view() const  { return false; }
 330   virtual bool is_jvmti_agent_thread() const         { return false; }
 331   // True iff the thread can perform GC operations at a safepoint.
 332   // Generally will be true only of VM thread and parallel GC WorkGang
 333   // threads.
 334   virtual bool is_GC_task_thread() const             { return false; }
 335   virtual bool is_Watcher_thread() const             { return false; }
 336   virtual bool is_ConcurrentGC_thread() const        { return false; }
 337   virtual bool is_Named_thread() const               { return false; }
 338   virtual bool is_Worker_thread() const              { return false; }
 339 
 340   // Can this thread make Java upcalls
 341   virtual bool can_call_java() const                 { return false; }
 342 
 343   // Casts
 344   virtual WorkerThread* as_Worker_thread() const     { return NULL; }
 345 
 346   virtual char* name() const { return (char*)"Unknown thread"; }
 347 
 348   // Returns the current thread (ASSERTS if NULL)
 349   static inline Thread* current();
 350   // Returns the current thread, or NULL if not attached
 351   static inline Thread* current_or_null();
 352   // Returns the current thread, or NULL if not attached, and is
 353   // safe for use from signal-handlers
 354   static inline Thread* current_or_null_safe();
 355 
 356   // Common thread operations
 357   static void set_priority(Thread* thread, ThreadPriority priority);
 358   static ThreadPriority get_priority(const Thread* const thread);
 359   static void start(Thread* thread);
 360   static void interrupt(Thread* thr);
 361   static bool is_interrupted(Thread* thr, bool clear_interrupted);
 362 
 363   void set_native_thread_name(const char *name) {
 364     assert(Thread::current() == this, "set_native_thread_name can only be called on the current thread");
 365     os::set_native_thread_name(name);
 366   }
 367 
 368   ObjectMonitor** omInUseList_addr()             { return (ObjectMonitor **)&amp;omInUseList; }
 369   Monitor* SR_lock() const                       { return _SR_lock; }
 370 
 371   bool has_async_exception() const { return (_suspend_flags &amp; _has_async_exception) != 0; }
 372 
 373   inline void set_suspend_flag(SuspendFlags f);
 374   inline void clear_suspend_flag(SuspendFlags f);
 375 
 376   inline void set_has_async_exception();
 377   inline void clear_has_async_exception();
 378 
 379   bool do_critical_native_unlock() const { return (_suspend_flags &amp; _critical_native_unlock) != 0; }
 380 
 381   inline void set_critical_native_unlock();
 382   inline void clear_critical_native_unlock();
 383 
 384   // Support for Unhandled Oop detection
 385   // Add the field for both, fastdebug and debug, builds to keep
 386   // Thread's fields layout the same.
 387   // Note: CHECK_UNHANDLED_OOPS is defined only for fastdebug build.
 388 #ifdef CHECK_UNHANDLED_OOPS
 389  private:
 390   UnhandledOops* _unhandled_oops;
 391 #elif defined(ASSERT)
 392  private:
 393   void* _unhandled_oops;
 394 #endif
 395 #ifdef CHECK_UNHANDLED_OOPS
 396  public:
 397   UnhandledOops* unhandled_oops() { return _unhandled_oops; }
 398   // Mark oop safe for gc.  It may be stack allocated but won't move.
 399   void allow_unhandled_oop(oop *op) {
 400     if (CheckUnhandledOops) unhandled_oops()-&gt;allow_unhandled_oop(op);
 401   }
 402   // Clear oops at safepoint so crashes point to unhandled oop violator
 403   void clear_unhandled_oops() {
 404     if (CheckUnhandledOops) unhandled_oops()-&gt;clear_unhandled_oops();
 405   }
 406 #endif // CHECK_UNHANDLED_OOPS
 407 
 408  public:
 409 #ifndef PRODUCT
 410   bool skip_gcalot()           { return _skip_gcalot; }
 411   void set_skip_gcalot(bool v) { _skip_gcalot = v;    }
 412 #endif
 413 
 414   // Installs a pending exception to be inserted later
 415   static void send_async_exception(oop thread_oop, oop java_throwable);
 416 
 417   // Resource area
 418   ResourceArea* resource_area() const            { return _resource_area; }
 419   void set_resource_area(ResourceArea* area)     { _resource_area = area; }
 420 
 421   OSThread* osthread() const                     { return _osthread;   }
 422   void set_osthread(OSThread* thread)            { _osthread = thread; }
 423 
 424   // JNI handle support
 425   JNIHandleBlock* active_handles() const         { return _active_handles; }
 426   void set_active_handles(JNIHandleBlock* block) { _active_handles = block; }
 427   JNIHandleBlock* free_handle_block() const      { return _free_handle_block; }
 428   void set_free_handle_block(JNIHandleBlock* block) { _free_handle_block = block; }
 429 
 430   // Internal handle support
 431   HandleArea* handle_area() const                { return _handle_area; }
 432   void set_handle_area(HandleArea* area)         { _handle_area = area; }
 433 
 434   GrowableArray&lt;Metadata*&gt;* metadata_handles() const          { return _metadata_handles; }
 435   void set_metadata_handles(GrowableArray&lt;Metadata*&gt;* handles){ _metadata_handles = handles; }
 436 
 437   // Thread-Local Allocation Buffer (TLAB) support
 438   ThreadLocalAllocBuffer&amp; tlab()                 { return _tlab; }
 439   void initialize_tlab() {
 440     if (UseTLAB) {
 441       tlab().initialize();
 442     }
 443   }
 444 
 445   jlong allocated_bytes()               { return _allocated_bytes; }
 446   void set_allocated_bytes(jlong value) { _allocated_bytes = value; }
 447   void incr_allocated_bytes(jlong size) { _allocated_bytes += size; }
 448   inline jlong cooked_allocated_bytes();
 449 
 450   TRACE_DEFINE_THREAD_TRACE_DATA_OFFSET;
 451   TRACE_DATA* trace_data() const        { return &amp;_trace_data; }
 452 
 453   const ThreadExt&amp; ext() const          { return _ext; }
 454   ThreadExt&amp; ext()                      { return _ext; }
 455 
 456   // VM operation support
 457   int vm_operation_ticket()                      { return ++_vm_operation_started_count; }
 458   int vm_operation_completed_count()             { return _vm_operation_completed_count; }
 459   void increment_vm_operation_completed_count()  { _vm_operation_completed_count++; }
 460 
 461   // For tracking the heavyweight monitor the thread is pending on.
 462   ObjectMonitor* current_pending_monitor() {
 463     return _current_pending_monitor;
 464   }
 465   void set_current_pending_monitor(ObjectMonitor* monitor) {
 466     _current_pending_monitor = monitor;
 467   }
 468   void set_current_pending_monitor_is_from_java(bool from_java) {
 469     _current_pending_monitor_is_from_java = from_java;
 470   }
 471   bool current_pending_monitor_is_from_java() {
 472     return _current_pending_monitor_is_from_java;
 473   }
 474 
 475   // For tracking the ObjectMonitor on which this thread called Object.wait()
 476   ObjectMonitor* current_waiting_monitor() {
 477     return _current_waiting_monitor;
 478   }
 479   void set_current_waiting_monitor(ObjectMonitor* monitor) {
 480     _current_waiting_monitor = monitor;
 481   }
 482 
 483   // GC support
 484   // Apply "f-&gt;do_oop" to all root oops in "this".
 485   //   Used by JavaThread::oops_do.
 486   // Apply "cf-&gt;do_code_blob" (if !NULL) to all code blobs active in frames
 487   virtual void oops_do(OopClosure* f, CodeBlobClosure* cf);
 488 
 489   // Handles the parallel case for the method below.
 490  private:
 491   bool claim_oops_do_par_case(int collection_parity);
 492  public:
 493   // Requires that "collection_parity" is that of the current roots
 494   // iteration.  If "is_par" is false, sets the parity of "this" to
 495   // "collection_parity", and returns "true".  If "is_par" is true,
 496   // uses an atomic instruction to set the current threads parity to
 497   // "collection_parity", if it is not already.  Returns "true" iff the
 498   // calling thread does the update, this indicates that the calling thread
 499   // has claimed the thread's stack as a root groop in the current
 500   // collection.
 501   bool claim_oops_do(bool is_par, int collection_parity) {
 502     if (!is_par) {
 503       _oops_do_parity = collection_parity;
 504       return true;
 505     } else {
 506       return claim_oops_do_par_case(collection_parity);
 507     }
 508   }
 509 
 510   // jvmtiRedefineClasses support
 511   void metadata_handles_do(void f(Metadata*));
 512 
 513   // Used by fast lock support
 514   virtual bool is_lock_owned(address adr) const;
 515 
 516   // Check if address is in the stack of the thread (not just for locks).
 517   // Warning: the method can only be used on the running thread
 518   bool is_in_stack(address adr) const;
 519   // Check if address is in the usable part of the stack (excludes protected
 520   // guard pages)
 521   bool is_in_usable_stack(address adr) const;
 522 
 523   // Sets this thread as starting thread. Returns failure if thread
 524   // creation fails due to lack of memory, too many threads etc.
 525   bool set_as_starting_thread();
 526 
 527 protected:
 528   // OS data associated with the thread
 529   OSThread* _osthread;  // Platform-specific thread information
 530 
 531   // Thread local resource area for temporary allocation within the VM
 532   ResourceArea* _resource_area;
 533 
 534   DEBUG_ONLY(ResourceMark* _current_resource_mark;)
 535 
 536   // Thread local handle area for allocation of handles within the VM
 537   HandleArea* _handle_area;
 538   GrowableArray&lt;Metadata*&gt;* _metadata_handles;
 539 
 540   // Support for stack overflow handling, get_thread, etc.
 541   address          _stack_base;
 542   size_t           _stack_size;
 543   uintptr_t        _self_raw_id;      // used by get_thread (mutable)
 544   int              _lgrp_id;
 545 
 546  public:
 547   // Stack overflow support
 548   address stack_base() const           { assert(_stack_base != NULL,"Sanity check"); return _stack_base; }
 549   void    set_stack_base(address base) { _stack_base = base; }
 550   size_t  stack_size() const           { return _stack_size; }
 551   void    set_stack_size(size_t size)  { _stack_size = size; }
 552   address stack_end()  const           { return stack_base() - stack_size(); }
 553   void    record_stack_base_and_size();
 554 
 555   bool    on_local_stack(address adr) const {
 556     // QQQ this has knowledge of direction, ought to be a stack method
 557     return (_stack_base &gt;= adr &amp;&amp; adr &gt;= stack_end());
 558   }
 559 
 560   uintptr_t self_raw_id()                    { return _self_raw_id; }
 561   void      set_self_raw_id(uintptr_t value) { _self_raw_id = value; }
 562 
 563   int     lgrp_id() const        { return _lgrp_id; }
 564   void    set_lgrp_id(int value) { _lgrp_id = value; }
 565 
 566   // Printing
 567   virtual void print_on(outputStream* st) const;
 568   void print() const { print_on(tty); }
 569   virtual void print_on_error(outputStream* st, char* buf, int buflen) const;
 570 
 571   // Debug-only code
 572 #ifdef ASSERT
 573  private:
 574   // Deadlock detection support for Mutex locks. List of locks own by thread.
 575   Monitor* _owned_locks;
 576   // Mutex::set_owner_implementation is the only place where _owned_locks is modified,
 577   // thus the friendship
 578   friend class Mutex;
 579   friend class Monitor;
 580 
 581  public:
 582   void print_owned_locks_on(outputStream* st) const;
 583   void print_owned_locks() const                 { print_owned_locks_on(tty);    }
 584   Monitor* owned_locks() const                   { return _owned_locks;          }
 585   bool owns_locks() const                        { return owned_locks() != NULL; }
 586   bool owns_locks_but_compiled_lock() const;
 587   int oops_do_parity() const                     { return _oops_do_parity; }
 588 
 589   // Deadlock detection
 590   bool allow_allocation()                        { return _allow_allocation_count == 0; }
 591   ResourceMark* current_resource_mark()          { return _current_resource_mark; }
 592   void set_current_resource_mark(ResourceMark* rm) { _current_resource_mark = rm; }
 593 #endif
 594 
 595   void check_for_valid_safepoint_state(bool potential_vm_operation) PRODUCT_RETURN;
 596 
 597  private:
 598   volatile int _jvmti_env_iteration_count;
 599 
 600  public:
 601   void entering_jvmti_env_iteration()            { ++_jvmti_env_iteration_count; }
 602   void leaving_jvmti_env_iteration()             { --_jvmti_env_iteration_count; }
 603   bool is_inside_jvmti_env_iteration()           { return _jvmti_env_iteration_count &gt; 0; }
 604 
 605   // Code generation
 606   static ByteSize exception_file_offset()        { return byte_offset_of(Thread, _exception_file); }
 607   static ByteSize exception_line_offset()        { return byte_offset_of(Thread, _exception_line); }
 608   static ByteSize active_handles_offset()        { return byte_offset_of(Thread, _active_handles); }
 609 
 610   static ByteSize stack_base_offset()            { return byte_offset_of(Thread, _stack_base); }
 611   static ByteSize stack_size_offset()            { return byte_offset_of(Thread, _stack_size); }
 612 
 613 #define TLAB_FIELD_OFFSET(name) \
 614   static ByteSize tlab_##name##_offset()         { return byte_offset_of(Thread, _tlab) + ThreadLocalAllocBuffer::name##_offset(); }
 615 
 616   TLAB_FIELD_OFFSET(start)
 617   TLAB_FIELD_OFFSET(end)
 618   TLAB_FIELD_OFFSET(top)
 619   TLAB_FIELD_OFFSET(pf_top)
 620   TLAB_FIELD_OFFSET(size)                   // desired_size
 621   TLAB_FIELD_OFFSET(refill_waste_limit)
 622   TLAB_FIELD_OFFSET(number_of_refills)
 623   TLAB_FIELD_OFFSET(fast_refill_waste)
 624   TLAB_FIELD_OFFSET(slow_allocations)
 625 
 626 #undef TLAB_FIELD_OFFSET
 627 
 628   static ByteSize allocated_bytes_offset()       { return byte_offset_of(Thread, _allocated_bytes); }
 629 
 630  public:
 631   volatile intptr_t _Stalled;
 632   volatile int _TypeTag;
 633   ParkEvent * _ParkEvent;                     // for synchronized()
 634   ParkEvent * _SleepEvent;                    // for Thread.sleep
 635   ParkEvent * _MutexEvent;                    // for native internal Mutex/Monitor
 636   ParkEvent * _MuxEvent;                      // for low-level muxAcquire-muxRelease
 637   int NativeSyncRecursion;                    // diagnostic
 638 
 639   volatile int _OnTrap;                       // Resume-at IP delta
 640   jint _hashStateW;                           // Marsaglia Shift-XOR thread-local RNG
 641   jint _hashStateX;                           // thread-specific hashCode generator state
 642   jint _hashStateY;
 643   jint _hashStateZ;
 644   void * _schedctl;
 645 
 646 
 647   volatile jint rng[4];                      // RNG for spin loop
 648 
 649   // Low-level leaf-lock primitives used to implement synchronization
 650   // and native monitor-mutex infrastructure.
 651   // Not for general synchronization use.
 652   static void SpinAcquire(volatile int * Lock, const char * Name);
 653   static void SpinRelease(volatile int * Lock);
 654   static void muxAcquire(volatile intptr_t * Lock, const char * Name);
 655   static void muxAcquireW(volatile intptr_t * Lock, ParkEvent * ev);
 656   static void muxRelease(volatile intptr_t * Lock);
 657 };
 658 
 659 // Inline implementation of Thread::current()
 660 inline Thread* Thread::current() {
 661   Thread* current = current_or_null();
 662   assert(current != NULL, "Thread::current() called on detached thread");
 663   return current;
 664 }
 665 
 666 inline Thread* Thread::current_or_null() {
 667 #ifndef USE_LIBRARY_BASED_TLS_ONLY
 668   return _thr_current;
 669 #else
 670   return ThreadLocalStorage::thread();
 671 #endif
 672 }
 673 
 674 inline Thread* Thread::current_or_null_safe() {
 675   return ThreadLocalStorage::thread();
 676 }
 677 
 678 // Name support for threads.  non-JavaThread subclasses with multiple
 679 // uniquely named instances should derive from this.
 680 class NamedThread: public Thread {
 681   friend class VMStructs;
 682   enum {
 683     max_name_len = 64
 684   };
 685  private:
 686   char* _name;
 687   // log JavaThread being processed by oops_do
 688   JavaThread* _processed_thread;
 689   uint _gc_id; // The current GC id when a thread takes part in GC
 690 
 691  public:
 692   NamedThread();
 693   ~NamedThread();
 694   // May only be called once per thread.
 695   void set_name(const char* format, ...)  ATTRIBUTE_PRINTF(2, 3);
 696   void initialize_named_thread();
 697   virtual bool is_Named_thread() const { return true; }
 698   virtual char* name() const { return _name == NULL ? (char*)"Unknown Thread" : _name; }
 699   JavaThread *processed_thread() { return _processed_thread; }
 700   void set_processed_thread(JavaThread *thread) { _processed_thread = thread; }
 701   virtual void print_on(outputStream* st) const;
 702 
 703   void set_gc_id(uint gc_id) { _gc_id = gc_id; }
 704   uint gc_id() { return _gc_id; }
 705 };
 706 
 707 // Worker threads are named and have an id of an assigned work.
 708 class WorkerThread: public NamedThread {
 709  private:
 710   uint _id;
 711  public:
 712   WorkerThread() : _id(0)               { }
 713   virtual bool is_Worker_thread() const { return true; }
 714 
 715   virtual WorkerThread* as_Worker_thread() const {
 716     assert(is_Worker_thread(), "Dubious cast to WorkerThread*?");
 717     return (WorkerThread*) this;
 718   }
 719 
 720   void set_id(uint work_id)             { _id = work_id; }
 721   uint id() const                       { return _id; }
 722 };
 723 
 724 // A single WatcherThread is used for simulating timer interrupts.
 725 class WatcherThread: public Thread {
 726   friend class VMStructs;
 727  public:
 728   virtual void run();
 729 
 730  private:
 731   static WatcherThread* _watcher_thread;
 732 
 733   static bool _startable;
 734   // volatile due to at least one lock-free read
 735   volatile static bool _should_terminate;
 736 
 737   os::WatcherThreadCrashProtection* _crash_protection;
 738  public:
 739   enum SomeConstants {
 740     delay_interval = 10                          // interrupt delay in milliseconds
 741   };
 742 
 743   // Constructor
 744   WatcherThread();
 745 
 746   // Tester
 747   bool is_Watcher_thread() const                 { return true; }
 748 
 749   // Printing
 750   char* name() const { return (char*)"VM Periodic Task Thread"; }
 751   void print_on(outputStream* st) const;
 752   void unpark();
 753 
 754   // Returns the single instance of WatcherThread
 755   static WatcherThread* watcher_thread()         { return _watcher_thread; }
 756 
 757   // Create and start the single instance of WatcherThread, or stop it on shutdown
 758   static void start();
 759   static void stop();
 760   // Only allow start once the VM is sufficiently initialized
 761   // Otherwise the first task to enroll will trigger the start
 762   static void make_startable();
 763 
 764   void set_crash_protection(os::WatcherThreadCrashProtection* crash_protection) {
 765     assert(Thread::current()-&gt;is_Watcher_thread(), "Can only be set by WatcherThread");
 766     _crash_protection = crash_protection;
 767   }
 768 
 769   bool has_crash_protection() const { return _crash_protection != NULL; }
 770   os::WatcherThreadCrashProtection* crash_protection() const { return _crash_protection; }
 771 
 772  private:
 773   int sleep() const;
 774 };
 775 
 776 
 777 class CompilerThread;
 778 
 779 typedef void (*ThreadFunction)(JavaThread*, TRAPS);
 780 
 781 class JavaThread: public Thread {
 782   friend class VMStructs;
 783   friend class JVMCIVMStructs;
 784   friend class WhiteBox;
 785  private:
 786   JavaThread*    _next;                          // The next thread in the Threads list
 787   oop            _threadObj;                     // The Java level thread object
 788 
 789 #ifdef ASSERT
 790  private:
 791   int _java_call_counter;
 792 
 793  public:
 794   int  java_call_counter()                       { return _java_call_counter; }
 795   void inc_java_call_counter()                   { _java_call_counter++; }
 796   void dec_java_call_counter() {
 797     assert(_java_call_counter &gt; 0, "Invalid nesting of JavaCallWrapper");
 798     _java_call_counter--;
 799   }
 800  private:  // restore original namespace restriction
 801 #endif  // ifdef ASSERT
 802 
 803 #ifndef PRODUCT
 804  public:
 805   enum {
 806     jump_ring_buffer_size = 16
 807   };
 808  private:  // restore original namespace restriction
 809 #endif
 810 
 811   JavaFrameAnchor _anchor;                       // Encapsulation of current java frame and it state
 812 
 813   ThreadFunction _entry_point;
 814 
 815   JNIEnv        _jni_environment;
 816 
 817   // Deopt support
 818   DeoptResourceMark*  _deopt_mark;               // Holds special ResourceMark for deoptimization
 819 
 820   intptr_t*      _must_deopt_id;                 // id of frame that needs to be deopted once we
 821                                                  // transition out of native
 822   CompiledMethod*       _deopt_nmethod;         // CompiledMethod that is currently being deoptimized
 823   vframeArray*  _vframe_array_head;              // Holds the heap of the active vframeArrays
 824   vframeArray*  _vframe_array_last;              // Holds last vFrameArray we popped
 825   // Because deoptimization is lazy we must save jvmti requests to set locals
 826   // in compiled frames until we deoptimize and we have an interpreter frame.
 827   // This holds the pointer to array (yeah like there might be more than one) of
 828   // description of compiled vframes that have locals that need to be updated.
 829   GrowableArray&lt;jvmtiDeferredLocalVariableSet*&gt;* _deferred_locals_updates;
 830 
 831   // Handshake value for fixing 6243940. We need a place for the i2c
 832   // adapter to store the callee Method*. This value is NEVER live
 833   // across a gc point so it does NOT have to be gc'd
 834   // The handshake is open ended since we can't be certain that it will
 835   // be NULLed. This is because we rarely ever see the race and end up
 836   // in handle_wrong_method which is the backend of the handshake. See
 837   // code in i2c adapters and handle_wrong_method.
 838 
 839   Method*       _callee_target;
 840 
 841   // Used to pass back results to the interpreter or generated code running Java code.
 842   oop           _vm_result;    // oop result is GC-preserved
 843   Metadata*     _vm_result_2;  // non-oop result
 844 
 845   // See ReduceInitialCardMarks: this holds the precise space interval of
 846   // the most recent slow path allocation for which compiled code has
 847   // elided card-marks for performance along the fast-path.
 848   MemRegion     _deferred_card_mark;
 849 
 850   MonitorChunk* _monitor_chunks;                 // Contains the off stack monitors
 851                                                  // allocated during deoptimization
 852                                                  // and by JNI_MonitorEnter/Exit
 853 
 854   // Async. requests support
 855   enum AsyncRequests {
 856     _no_async_condition = 0,
 857     _async_exception,
 858     _async_unsafe_access_error
 859   };
 860   AsyncRequests _special_runtime_exit_condition; // Enum indicating pending async. request
 861   oop           _pending_async_exception;
 862 
 863   // Safepoint support
 864  public:                                         // Expose _thread_state for SafeFetchInt()
 865   volatile JavaThreadState _thread_state;
 866  private:
 867   ThreadSafepointState *_safepoint_state;        // Holds information about a thread during a safepoint
 868   address               _saved_exception_pc;     // Saved pc of instruction where last implicit exception happened
 869 
 870   // JavaThread termination support
 871   enum TerminatedTypes {
 872     _not_terminated = 0xDEAD - 2,
 873     _thread_exiting,                             // JavaThread::exit() has been called for this thread
 874     _thread_terminated,                          // JavaThread is removed from thread list
 875     _vm_exited                                   // JavaThread is still executing native code, but VM is terminated
 876                                                  // only VM_Exit can set _vm_exited
 877   };
 878 
 879   // In general a JavaThread's _terminated field transitions as follows:
 880   //
 881   //   _not_terminated =&gt; _thread_exiting =&gt; _thread_terminated
 882   //
 883   // _vm_exited is a special value to cover the case of a JavaThread
 884   // executing native code after the VM itself is terminated.
 885   volatile TerminatedTypes _terminated;
 886   // suspend/resume support
 887   volatile bool         _suspend_equivalent;     // Suspend equivalent condition
 888   jint                  _in_deopt_handler;       // count of deoptimization
 889                                                  // handlers thread is in
 890   volatile bool         _doing_unsafe_access;    // Thread may fault due to unsafe access
 891   bool                  _do_not_unlock_if_synchronized;  // Do not unlock the receiver of a synchronized method (since it was
 892                                                          // never locked) when throwing an exception. Used by interpreter only.
 893 
 894   // JNI attach states:
 895   enum JNIAttachStates {
 896     _not_attaching_via_jni = 1,  // thread is not attaching via JNI
 897     _attaching_via_jni,          // thread is attaching via JNI
 898     _attached_via_jni            // thread has attached via JNI
 899   };
 900 
 901   // A regular JavaThread's _jni_attach_state is _not_attaching_via_jni.
 902   // A native thread that is attaching via JNI starts with a value
 903   // of _attaching_via_jni and transitions to _attached_via_jni.
 904   volatile JNIAttachStates _jni_attach_state;
 905 
 906  public:
 907   // State of the stack guard pages for this thread.
 908   enum StackGuardState {
 909     stack_guard_unused,         // not needed
 910     stack_guard_reserved_disabled,
 911     stack_guard_yellow_reserved_disabled,// disabled (temporarily) after stack overflow
 912     stack_guard_enabled         // enabled
 913   };
 914 
 915  private:
 916 
 917 #if INCLUDE_JVMCI
 918   // The _pending_* fields below are used to communicate extra information
 919   // from an uncommon trap in JVMCI compiled code to the uncommon trap handler.
 920 
 921   // Communicates the DeoptReason and DeoptAction of the uncommon trap
 922   int       _pending_deoptimization;
 923 
 924   // Specifies whether the uncommon trap is to bci 0 of a synchronized method
 925   // before the monitor has been acquired.
 926   bool      _pending_monitorenter;
 927 
 928   // Specifies if the DeoptReason for the last uncommon trap was Reason_transfer_to_interpreter
 929   bool      _pending_transfer_to_interpreter;
 930 
<a name="1" id="anc1"></a><span class="new"> 931   // Guard for re-entrant call to JVMCIRuntime::adjust_comp_level</span>
<span class="new"> 932   bool      _adjusting_comp_level;</span>
<span class="new"> 933 </span>
 934   // An object that JVMCI compiled code can use to further describe and
 935   // uniquely identify the  speculative optimization guarded by the uncommon trap
 936   oop       _pending_failed_speculation;
 937 
 938   // These fields are mutually exclusive in terms of live ranges.
 939   union {
 940     // Communicates the pc at which the most recent implicit exception occurred
 941     // from the signal handler to a deoptimization stub.
 942     address   _implicit_exception_pc;
 943 
 944     // Communicates an alternative call target to an i2c stub from a JavaCall .
 945     address   _alternate_call_target;
 946   } _jvmci;
 947 
 948   // Support for high precision, thread sensitive counters in JVMCI compiled code.
 949   jlong*    _jvmci_counters;
 950 
 951  public:
 952   static jlong* _jvmci_old_thread_counters;
 953   static void collect_counters(typeArrayOop array);
 954  private:
 955 #endif // INCLUDE_JVMCI
 956 
 957   StackGuardState  _stack_guard_state;
 958 
 959   // Precompute the limit of the stack as used in stack overflow checks.
 960   // We load it from here to simplify the stack overflow check in assembly.
 961   address          _stack_overflow_limit;
 962   address          _reserved_stack_activation;
 963 
 964   // Compiler exception handling (NOTE: The _exception_oop is *NOT* the same as _pending_exception. It is
 965   // used to temp. parsing values into and out of the runtime system during exception handling for compiled
 966   // code)
 967   volatile oop     _exception_oop;               // Exception thrown in compiled code
 968   volatile address _exception_pc;                // PC where exception happened
 969   volatile address _exception_handler_pc;        // PC for handler of exception
 970   volatile int     _is_method_handle_return;     // true (== 1) if the current exception PC is a MethodHandle call site.
 971 
 972  private:
 973   // support for JNI critical regions
 974   jint    _jni_active_critical;                  // count of entries into JNI critical region
 975 
 976   // Checked JNI: function name requires exception check
 977   char* _pending_jni_exception_check_fn;
 978 
 979   // For deadlock detection.
 980   int _depth_first_number;
 981 
 982   // JVMTI PopFrame support
 983   // This is set to popframe_pending to signal that top Java frame should be popped immediately
 984   int _popframe_condition;
 985 
 986   // If reallocation of scalar replaced objects fails, we throw OOM
 987   // and during exception propagation, pop the top
 988   // _frames_to_pop_failed_realloc frames, the ones that reference
 989   // failed reallocations.
 990   int _frames_to_pop_failed_realloc;
 991 
 992 #ifndef PRODUCT
 993   int _jmp_ring_index;
 994   struct {
 995     // We use intptr_t instead of address so debugger doesn't try and display strings
 996     intptr_t _target;
 997     intptr_t _instruction;
 998     const char*  _file;
 999     int _line;
1000   }   _jmp_ring[jump_ring_buffer_size];
1001 #endif // PRODUCT
1002 
1003 #if INCLUDE_ALL_GCS
1004   // Support for G1 barriers
1005 
1006   SATBMarkQueue _satb_mark_queue;        // Thread-local log for SATB barrier.
1007   // Set of all such queues.
1008   static SATBMarkQueueSet _satb_mark_queue_set;
1009 
1010   DirtyCardQueue _dirty_card_queue;      // Thread-local log for dirty cards.
1011   // Set of all such queues.
1012   static DirtyCardQueueSet _dirty_card_queue_set;
1013 
1014   void flush_barrier_queues();
1015 #endif // INCLUDE_ALL_GCS
1016 
1017   friend class VMThread;
1018   friend class ThreadWaitTransition;
1019   friend class VM_Exit;
1020 
1021   void initialize();                             // Initialized the instance variables
1022 
1023  public:
1024   // Constructor
1025   JavaThread(bool is_attaching_via_jni = false); // for main thread and JNI attached threads
1026   JavaThread(ThreadFunction entry_point, size_t stack_size = 0);
1027   ~JavaThread();
1028 
1029 #ifdef ASSERT
1030   // verify this JavaThread hasn't be published in the Threads::list yet
1031   void verify_not_published();
1032 #endif
1033 
1034   //JNI functiontable getter/setter for JVMTI jni function table interception API.
1035   void set_jni_functions(struct JNINativeInterface_* functionTable) {
1036     _jni_environment.functions = functionTable;
1037   }
1038   struct JNINativeInterface_* get_jni_functions() {
1039     return (struct JNINativeInterface_ *)_jni_environment.functions;
1040   }
1041 
1042   // This function is called at thread creation to allow
1043   // platform specific thread variables to be initialized.
1044   void cache_global_variables();
1045 
1046   // Executes Shutdown.shutdown()
1047   void invoke_shutdown_hooks();
1048 
1049   // Cleanup on thread exit
1050   enum ExitType {
1051     normal_exit,
1052     jni_detach
1053   };
1054   void exit(bool destroy_vm, ExitType exit_type = normal_exit);
1055 
1056   void cleanup_failed_attach_current_thread();
1057 
1058   // Testers
1059   virtual bool is_Java_thread() const            { return true;  }
1060   virtual bool can_call_java() const             { return true; }
1061 
1062   // Thread chain operations
1063   JavaThread* next() const                       { return _next; }
1064   void set_next(JavaThread* p)                   { _next = p; }
1065 
1066   // Thread oop. threadObj() can be NULL for initial JavaThread
1067   // (or for threads attached via JNI)
1068   oop threadObj() const                          { return _threadObj; }
1069   void set_threadObj(oop p)                      { _threadObj = p; }
1070 
1071   ThreadPriority java_priority() const;          // Read from threadObj()
1072 
1073   // Prepare thread and add to priority queue.  If a priority is
1074   // not specified, use the priority of the thread object. Threads_lock
1075   // must be held while this function is called.
1076   void prepare(jobject jni_thread, ThreadPriority prio=NoPriority);
1077   void prepare_ext();
1078 
1079   void set_saved_exception_pc(address pc)        { _saved_exception_pc = pc; }
1080   address saved_exception_pc()                   { return _saved_exception_pc; }
1081 
1082 
1083   ThreadFunction entry_point() const             { return _entry_point; }
1084 
1085   // Allocates a new Java level thread object for this thread. thread_name may be NULL.
1086   void allocate_threadObj(Handle thread_group, const char* thread_name, bool daemon, TRAPS);
1087 
1088   // Last frame anchor routines
1089 
1090   JavaFrameAnchor* frame_anchor(void)            { return &amp;_anchor; }
1091 
1092   // last_Java_sp
1093   bool has_last_Java_frame() const               { return _anchor.has_last_Java_frame(); }
1094   intptr_t* last_Java_sp() const                 { return _anchor.last_Java_sp(); }
1095 
1096   // last_Java_pc
1097 
1098   address last_Java_pc(void)                     { return _anchor.last_Java_pc(); }
1099 
1100   // Safepoint support
1101 #if !(defined(PPC64) || defined(AARCH64))
1102   JavaThreadState thread_state() const           { return _thread_state; }
1103   void set_thread_state(JavaThreadState s)       { _thread_state = s;    }
1104 #else
1105   // Use membars when accessing volatile _thread_state. See
1106   // Threads::create_vm() for size checks.
1107   inline JavaThreadState thread_state() const;
1108   inline void set_thread_state(JavaThreadState s);
1109 #endif
1110   ThreadSafepointState *safepoint_state() const  { return _safepoint_state; }
1111   void set_safepoint_state(ThreadSafepointState *state) { _safepoint_state = state; }
1112   bool is_at_poll_safepoint()                    { return _safepoint_state-&gt;is_at_poll_safepoint(); }
1113 
1114   // thread has called JavaThread::exit() or is terminated
1115   bool is_exiting()                              { return _terminated == _thread_exiting || is_terminated(); }
1116   // thread is terminated (no longer on the threads list); we compare
1117   // against the two non-terminated values so that a freed JavaThread
1118   // will also be considered terminated.
1119   bool is_terminated()                           { return _terminated != _not_terminated &amp;&amp; _terminated != _thread_exiting; }
1120   void set_terminated(TerminatedTypes t)         { _terminated = t; }
1121   // special for Threads::remove() which is static:
1122   void set_terminated_value()                    { _terminated = _thread_terminated; }
1123   void block_if_vm_exited();
1124 
1125   bool doing_unsafe_access()                     { return _doing_unsafe_access; }
1126   void set_doing_unsafe_access(bool val)         { _doing_unsafe_access = val; }
1127 
1128   bool do_not_unlock_if_synchronized()             { return _do_not_unlock_if_synchronized; }
1129   void set_do_not_unlock_if_synchronized(bool val) { _do_not_unlock_if_synchronized = val; }
1130 
1131   // Suspend/resume support for JavaThread
1132  private:
1133   inline void set_ext_suspended();
1134   inline void clear_ext_suspended();
1135 
1136  public:
1137   void java_suspend();
1138   void java_resume();
1139   int  java_suspend_self();
1140 
1141   void check_and_wait_while_suspended() {
1142     assert(JavaThread::current() == this, "sanity check");
1143 
1144     bool do_self_suspend;
1145     do {
1146       // were we externally suspended while we were waiting?
1147       do_self_suspend = handle_special_suspend_equivalent_condition();
1148       if (do_self_suspend) {
1149         // don't surprise the thread that suspended us by returning
1150         java_suspend_self();
1151         set_suspend_equivalent();
1152       }
1153     } while (do_self_suspend);
1154   }
1155   static void check_safepoint_and_suspend_for_native_trans(JavaThread *thread);
1156   // Check for async exception in addition to safepoint and suspend request.
1157   static void check_special_condition_for_native_trans(JavaThread *thread);
1158 
1159   // Same as check_special_condition_for_native_trans but finishes the
1160   // transition into thread_in_Java mode so that it can potentially
1161   // block.
1162   static void check_special_condition_for_native_trans_and_transition(JavaThread *thread);
1163 
1164   bool is_ext_suspend_completed(bool called_by_wait, int delay, uint32_t *bits);
1165   bool is_ext_suspend_completed_with_lock(uint32_t *bits) {
1166     MutexLockerEx ml(SR_lock(), Mutex::_no_safepoint_check_flag);
1167     // Warning: is_ext_suspend_completed() may temporarily drop the
1168     // SR_lock to allow the thread to reach a stable thread state if
1169     // it is currently in a transient thread state.
1170     return is_ext_suspend_completed(false /* !called_by_wait */,
1171                                     SuspendRetryDelay, bits);
1172   }
1173 
1174   // We cannot allow wait_for_ext_suspend_completion() to run forever or
1175   // we could hang. SuspendRetryCount and SuspendRetryDelay are normally
1176   // passed as the count and delay parameters. Experiments with specific
1177   // calls to wait_for_ext_suspend_completion() can be done by passing
1178   // other values in the code. Experiments with all calls can be done
1179   // via the appropriate -XX options.
1180   bool wait_for_ext_suspend_completion(int count, int delay, uint32_t *bits);
1181 
1182   inline void set_external_suspend();
1183   inline void clear_external_suspend();
1184 
1185   inline void set_deopt_suspend();
1186   inline void clear_deopt_suspend();
1187   bool is_deopt_suspend()         { return (_suspend_flags &amp; _deopt_suspend) != 0; }
1188 
1189   bool is_external_suspend() const {
1190     return (_suspend_flags &amp; _external_suspend) != 0;
1191   }
1192   // Whenever a thread transitions from native to vm/java it must suspend
1193   // if external|deopt suspend is present.
1194   bool is_suspend_after_native() const {
1195     return (_suspend_flags &amp; (_external_suspend | _deopt_suspend)) != 0;
1196   }
1197 
1198   // external suspend request is completed
1199   bool is_ext_suspended() const {
1200     return (_suspend_flags &amp; _ext_suspended) != 0;
1201   }
1202 
1203   bool is_external_suspend_with_lock() const {
1204     MutexLockerEx ml(SR_lock(), Mutex::_no_safepoint_check_flag);
1205     return is_external_suspend();
1206   }
1207 
1208   // Special method to handle a pending external suspend request
1209   // when a suspend equivalent condition lifts.
1210   bool handle_special_suspend_equivalent_condition() {
1211     assert(is_suspend_equivalent(),
1212            "should only be called in a suspend equivalence condition");
1213     MutexLockerEx ml(SR_lock(), Mutex::_no_safepoint_check_flag);
1214     bool ret = is_external_suspend();
1215     if (!ret) {
1216       // not about to self-suspend so clear suspend equivalence
1217       clear_suspend_equivalent();
1218     }
1219     // implied else:
1220     // We have a pending external suspend request so we leave the
1221     // suspend_equivalent flag set until java_suspend_self() sets
1222     // the ext_suspended flag and clears the suspend_equivalent
1223     // flag. This insures that wait_for_ext_suspend_completion()
1224     // will return consistent values.
1225     return ret;
1226   }
1227 
1228   // utility methods to see if we are doing some kind of suspension
1229   bool is_being_ext_suspended() const            {
1230     MutexLockerEx ml(SR_lock(), Mutex::_no_safepoint_check_flag);
1231     return is_ext_suspended() || is_external_suspend();
1232   }
1233 
1234   bool is_suspend_equivalent() const             { return _suspend_equivalent; }
1235 
1236   void set_suspend_equivalent()                  { _suspend_equivalent = true; }
1237   void clear_suspend_equivalent()                { _suspend_equivalent = false; }
1238 
1239   // Thread.stop support
1240   void send_thread_stop(oop throwable);
1241   AsyncRequests clear_special_runtime_exit_condition() {
1242     AsyncRequests x = _special_runtime_exit_condition;
1243     _special_runtime_exit_condition = _no_async_condition;
1244     return x;
1245   }
1246 
1247   // Are any async conditions present?
1248   bool has_async_condition() { return (_special_runtime_exit_condition != _no_async_condition); }
1249 
1250   void check_and_handle_async_exceptions(bool check_unsafe_error = true);
1251 
1252   // these next two are also used for self-suspension and async exception support
1253   void handle_special_runtime_exit_condition(bool check_asyncs = true);
1254 
1255   // Return true if JavaThread has an asynchronous condition or
1256   // if external suspension is requested.
1257   bool has_special_runtime_exit_condition() {
1258     // We call is_external_suspend() last since external suspend should
1259     // be less common. Because we don't use is_external_suspend_with_lock
1260     // it is possible that we won't see an asynchronous external suspend
1261     // request that has just gotten started, i.e., SR_lock grabbed but
1262     // _external_suspend field change either not made yet or not visible
1263     // yet. However, this is okay because the request is asynchronous and
1264     // we will see the new flag value the next time through. It's also
1265     // possible that the external suspend request is dropped after
1266     // we have checked is_external_suspend(), we will recheck its value
1267     // under SR_lock in java_suspend_self().
1268     return (_special_runtime_exit_condition != _no_async_condition) ||
1269             is_external_suspend() || is_deopt_suspend();
1270   }
1271 
1272   void set_pending_unsafe_access_error()          { _special_runtime_exit_condition = _async_unsafe_access_error; }
1273 
1274   inline void set_pending_async_exception(oop e);
1275 
1276   // Fast-locking support
1277   bool is_lock_owned(address adr) const;
1278 
1279   // Accessors for vframe array top
1280   // The linked list of vframe arrays are sorted on sp. This means when we
1281   // unpack the head must contain the vframe array to unpack.
1282   void set_vframe_array_head(vframeArray* value) { _vframe_array_head = value; }
1283   vframeArray* vframe_array_head() const         { return _vframe_array_head;  }
1284 
1285   // Side structure for deferring update of java frame locals until deopt occurs
1286   GrowableArray&lt;jvmtiDeferredLocalVariableSet*&gt;* deferred_locals() const { return _deferred_locals_updates; }
1287   void set_deferred_locals(GrowableArray&lt;jvmtiDeferredLocalVariableSet *&gt;* vf) { _deferred_locals_updates = vf; }
1288 
1289   // These only really exist to make debugging deopt problems simpler
1290 
1291   void set_vframe_array_last(vframeArray* value) { _vframe_array_last = value; }
1292   vframeArray* vframe_array_last() const         { return _vframe_array_last;  }
1293 
1294   // The special resourceMark used during deoptimization
1295 
1296   void set_deopt_mark(DeoptResourceMark* value)  { _deopt_mark = value; }
1297   DeoptResourceMark* deopt_mark(void)            { return _deopt_mark; }
1298 
1299   intptr_t* must_deopt_id()                      { return _must_deopt_id; }
1300   void     set_must_deopt_id(intptr_t* id)       { _must_deopt_id = id; }
1301   void     clear_must_deopt_id()                 { _must_deopt_id = NULL; }
1302 
1303   void set_deopt_compiled_method(CompiledMethod* nm)  { _deopt_nmethod = nm; }
1304   CompiledMethod* deopt_compiled_method()        { return _deopt_nmethod; }
1305 
1306   Method*    callee_target() const               { return _callee_target; }
1307   void set_callee_target  (Method* x)          { _callee_target   = x; }
1308 
1309   // Oop results of vm runtime calls
1310   oop  vm_result() const                         { return _vm_result; }
1311   void set_vm_result  (oop x)                    { _vm_result   = x; }
1312 
1313   Metadata*    vm_result_2() const               { return _vm_result_2; }
1314   void set_vm_result_2  (Metadata* x)          { _vm_result_2   = x; }
1315 
1316   MemRegion deferred_card_mark() const           { return _deferred_card_mark; }
1317   void set_deferred_card_mark(MemRegion mr)      { _deferred_card_mark = mr;   }
1318 
1319 #if INCLUDE_JVMCI
1320   int  pending_deoptimization() const             { return _pending_deoptimization; }
1321   oop  pending_failed_speculation() const         { return _pending_failed_speculation; }
<a name="2" id="anc2"></a><span class="new">1322   bool adjusting_comp_level() const               { return _adjusting_comp_level; }</span>
<span class="new">1323   void set_adjusting_comp_level(bool b)           { _adjusting_comp_level = b; }</span>
1324   bool has_pending_monitorenter() const           { return _pending_monitorenter; }
1325   void set_pending_monitorenter(bool b)           { _pending_monitorenter = b; }
1326   void set_pending_deoptimization(int reason)     { _pending_deoptimization = reason; }
1327   void set_pending_failed_speculation(oop failed_speculation) { _pending_failed_speculation = failed_speculation; }
1328   void set_pending_transfer_to_interpreter(bool b) { _pending_transfer_to_interpreter = b; }
1329   void set_jvmci_alternate_call_target(address a) { assert(_jvmci._alternate_call_target == NULL, "must be"); _jvmci._alternate_call_target = a; }
1330   void set_jvmci_implicit_exception_pc(address a) { assert(_jvmci._implicit_exception_pc == NULL, "must be"); _jvmci._implicit_exception_pc = a; }
1331 #endif // INCLUDE_JVMCI
1332 
1333   // Exception handling for compiled methods
1334   oop      exception_oop() const                 { return _exception_oop; }
1335   address  exception_pc() const                  { return _exception_pc; }
1336   address  exception_handler_pc() const          { return _exception_handler_pc; }
1337   bool     is_method_handle_return() const       { return _is_method_handle_return == 1; }
1338 
1339   void set_exception_oop(oop o)                  { (void)const_cast&lt;oop&amp;&gt;(_exception_oop = o); }
1340   void set_exception_pc(address a)               { _exception_pc = a; }
1341   void set_exception_handler_pc(address a)       { _exception_handler_pc = a; }
1342   void set_is_method_handle_return(bool value)   { _is_method_handle_return = value ? 1 : 0; }
1343 
1344   void clear_exception_oop_and_pc() {
1345     set_exception_oop(NULL);
1346     set_exception_pc(NULL);
1347   }
1348 
1349   // Stack overflow support
1350   //
1351   //  (small addresses)
1352   //
1353   //  --  &lt;-- stack_end()                   ---
1354   //  |                                      |
1355   //  |  red pages                           |
1356   //  |                                      |
1357   //  --  &lt;-- stack_red_zone_base()          |
1358   //  |                                      |
1359   //  |                                     guard
1360   //  |  yellow pages                       zone
1361   //  |                                      |
1362   //  |                                      |
1363   //  --  &lt;-- stack_yellow_zone_base()       |
1364   //  |                                      |
1365   //  |                                      |
1366   //  |  reserved pages                      |
1367   //  |                                      |
1368   //  --  &lt;-- stack_reserved_zone_base()    ---      ---
1369   //                                                 /|\  shadow
1370   //                                                  |   zone
1371   //                                                 \|/  size
1372   //  some untouched memory                          ---         &lt;--  stack_overflow_limit()
1373   //
1374   //
1375   //  --
1376   //  |
1377   //  |  shadow zone
1378   //  |
1379   //  --
1380   //  x    frame n
1381   //  --
1382   //  x    frame n-1
1383   //  x
1384   //  --
1385   //  ...
1386   //
1387   //  --
1388   //  x    frame 0
1389   //  --  &lt;-- stack_base()
1390   //
1391   //  (large addresses)
1392   //
1393 
1394  private:
1395   // These values are derived from flags StackRedPages, StackYellowPages,
1396   // StackReservedPages and StackShadowPages. The zone size is determined
1397   // ergonomically if page_size &gt; 4K.
1398   static size_t _stack_red_zone_size;
1399   static size_t _stack_yellow_zone_size;
1400   static size_t _stack_reserved_zone_size;
1401   static size_t _stack_shadow_zone_size;
1402  public:
1403   inline size_t stack_available(address cur_sp);
1404 
1405   static size_t stack_red_zone_size() {
1406     assert(_stack_red_zone_size &gt; 0, "Don't call this before the field is initialized.");
1407     return _stack_red_zone_size;
1408   }
1409   static void set_stack_red_zone_size(size_t s) {
1410     assert(is_size_aligned(s, os::vm_page_size()),
1411            "We can not protect if the red zone size is not page aligned.");
1412     assert(_stack_red_zone_size == 0, "This should be called only once.");
1413     _stack_red_zone_size = s;
1414   }
1415   address stack_red_zone_base() {
1416     return (address)(stack_end() + stack_red_zone_size());
1417   }
1418   bool in_stack_red_zone(address a) {
1419     return a &lt;= stack_red_zone_base() &amp;&amp; a &gt;= stack_end();
1420   }
1421 
1422   static size_t stack_yellow_zone_size() {
1423     assert(_stack_yellow_zone_size &gt; 0, "Don't call this before the field is initialized.");
1424     return _stack_yellow_zone_size;
1425   }
1426   static void set_stack_yellow_zone_size(size_t s) {
1427     assert(is_size_aligned(s, os::vm_page_size()),
1428            "We can not protect if the yellow zone size is not page aligned.");
1429     assert(_stack_yellow_zone_size == 0, "This should be called only once.");
1430     _stack_yellow_zone_size = s;
1431   }
1432 
1433   static size_t stack_reserved_zone_size() {
1434     // _stack_reserved_zone_size may be 0. This indicates the feature is off.
1435     return _stack_reserved_zone_size;
1436   }
1437   static void set_stack_reserved_zone_size(size_t s) {
1438     assert(is_size_aligned(s, os::vm_page_size()),
1439            "We can not protect if the reserved zone size is not page aligned.");
1440     assert(_stack_reserved_zone_size == 0, "This should be called only once.");
1441     _stack_reserved_zone_size = s;
1442   }
1443   address stack_reserved_zone_base() {
1444     return (address)(stack_end() +
1445                      (stack_red_zone_size() + stack_yellow_zone_size() + stack_reserved_zone_size()));
1446   }
1447   bool in_stack_reserved_zone(address a) {
1448     return (a &lt;= stack_reserved_zone_base()) &amp;&amp;
1449            (a &gt;= (address)((intptr_t)stack_reserved_zone_base() - stack_reserved_zone_size()));
1450   }
1451 
1452   static size_t stack_yellow_reserved_zone_size() {
1453     return _stack_yellow_zone_size + _stack_reserved_zone_size;
1454   }
1455   bool in_stack_yellow_reserved_zone(address a) {
1456     return (a &lt;= stack_reserved_zone_base()) &amp;&amp; (a &gt;= stack_red_zone_base());
1457   }
1458 
1459   // Size of red + yellow + reserved zones.
1460   static size_t stack_guard_zone_size() {
1461     return stack_red_zone_size() + stack_yellow_reserved_zone_size();
1462   }
1463 
1464   static size_t stack_shadow_zone_size() {
1465     assert(_stack_shadow_zone_size &gt; 0, "Don't call this before the field is initialized.");
1466     return _stack_shadow_zone_size;
1467   }
1468   static void set_stack_shadow_zone_size(size_t s) {
1469     // The shadow area is not allocated or protected, so
1470     // it needs not be page aligned.
1471     // But the stack bang currently assumes that it is a
1472     // multiple of page size. This guarantees that the bang
1473     // loop touches all pages in the shadow zone.
1474     // This can be guaranteed differently, as well.  E.g., if
1475     // the page size is a multiple of 4K, banging in 4K steps
1476     // suffices to touch all pages. (Some pages are banged
1477     // several times, though.)
1478     assert(is_size_aligned(s, os::vm_page_size()),
1479            "Stack bang assumes multiple of page size.");
1480     assert(_stack_shadow_zone_size == 0, "This should be called only once.");
1481     _stack_shadow_zone_size = s;
1482   }
1483 
1484   void create_stack_guard_pages();
1485   void remove_stack_guard_pages();
1486 
1487   void enable_stack_reserved_zone();
1488   void disable_stack_reserved_zone();
1489   void enable_stack_yellow_reserved_zone();
1490   void disable_stack_yellow_reserved_zone();
1491   void enable_stack_red_zone();
1492   void disable_stack_red_zone();
1493 
1494   inline bool stack_guard_zone_unused();
1495   inline bool stack_yellow_reserved_zone_disabled();
1496   inline bool stack_reserved_zone_disabled();
1497   inline bool stack_guards_enabled();
1498 
1499   address reserved_stack_activation() const { return _reserved_stack_activation; }
1500   void set_reserved_stack_activation(address addr) {
1501     assert(_reserved_stack_activation == stack_base()
1502             || _reserved_stack_activation == NULL
1503             || addr == stack_base(), "Must not be set twice");
1504     _reserved_stack_activation = addr;
1505   }
1506 
1507   // Attempt to reguard the stack after a stack overflow may have occurred.
1508   // Returns true if (a) guard pages are not needed on this thread, (b) the
1509   // pages are already guarded, or (c) the pages were successfully reguarded.
1510   // Returns false if there is not enough stack space to reguard the pages, in
1511   // which case the caller should unwind a frame and try again.  The argument
1512   // should be the caller's (approximate) sp.
1513   bool reguard_stack(address cur_sp);
1514   // Similar to above but see if current stackpoint is out of the guard area
1515   // and reguard if possible.
1516   bool reguard_stack(void);
1517 
1518   address stack_overflow_limit() { return _stack_overflow_limit; }
1519   void set_stack_overflow_limit() {
1520     _stack_overflow_limit = stack_end() +
1521                             (JavaThread::stack_guard_zone_size() +
1522                              JavaThread::stack_shadow_zone_size());
1523   }
1524 
1525   // Misc. accessors/mutators
1526   void set_do_not_unlock(void)                   { _do_not_unlock_if_synchronized = true; }
1527   void clr_do_not_unlock(void)                   { _do_not_unlock_if_synchronized = false; }
1528   bool do_not_unlock(void)                       { return _do_not_unlock_if_synchronized; }
1529 
1530 #ifndef PRODUCT
1531   void record_jump(address target, address instr, const char* file, int line);
1532 #endif // PRODUCT
1533 
1534   // For assembly stub generation
1535   static ByteSize threadObj_offset()             { return byte_offset_of(JavaThread, _threadObj); }
1536 #ifndef PRODUCT
1537   static ByteSize jmp_ring_index_offset()        { return byte_offset_of(JavaThread, _jmp_ring_index); }
1538   static ByteSize jmp_ring_offset()              { return byte_offset_of(JavaThread, _jmp_ring); }
1539 #endif // PRODUCT
1540   static ByteSize jni_environment_offset()       { return byte_offset_of(JavaThread, _jni_environment); }
1541   static ByteSize last_Java_sp_offset() {
1542     return byte_offset_of(JavaThread, _anchor) + JavaFrameAnchor::last_Java_sp_offset();
1543   }
1544   static ByteSize last_Java_pc_offset() {
1545     return byte_offset_of(JavaThread, _anchor) + JavaFrameAnchor::last_Java_pc_offset();
1546   }
1547   static ByteSize frame_anchor_offset() {
1548     return byte_offset_of(JavaThread, _anchor);
1549   }
1550   static ByteSize callee_target_offset()         { return byte_offset_of(JavaThread, _callee_target); }
1551   static ByteSize vm_result_offset()             { return byte_offset_of(JavaThread, _vm_result); }
1552   static ByteSize vm_result_2_offset()           { return byte_offset_of(JavaThread, _vm_result_2); }
1553   static ByteSize thread_state_offset()          { return byte_offset_of(JavaThread, _thread_state); }
1554   static ByteSize saved_exception_pc_offset()    { return byte_offset_of(JavaThread, _saved_exception_pc); }
1555   static ByteSize osthread_offset()              { return byte_offset_of(JavaThread, _osthread); }
1556 #if INCLUDE_JVMCI
1557   static ByteSize pending_deoptimization_offset() { return byte_offset_of(JavaThread, _pending_deoptimization); }
1558   static ByteSize pending_monitorenter_offset()  { return byte_offset_of(JavaThread, _pending_monitorenter); }
1559   static ByteSize pending_failed_speculation_offset() { return byte_offset_of(JavaThread, _pending_failed_speculation); }
1560   static ByteSize jvmci_alternate_call_target_offset() { return byte_offset_of(JavaThread, _jvmci._alternate_call_target); }
1561   static ByteSize jvmci_implicit_exception_pc_offset() { return byte_offset_of(JavaThread, _jvmci._implicit_exception_pc); }
1562   static ByteSize jvmci_counters_offset()        { return byte_offset_of(JavaThread, _jvmci_counters); }
1563 #endif // INCLUDE_JVMCI
1564   static ByteSize exception_oop_offset()         { return byte_offset_of(JavaThread, _exception_oop); }
1565   static ByteSize exception_pc_offset()          { return byte_offset_of(JavaThread, _exception_pc); }
1566   static ByteSize exception_handler_pc_offset()  { return byte_offset_of(JavaThread, _exception_handler_pc); }
1567   static ByteSize stack_overflow_limit_offset()  { return byte_offset_of(JavaThread, _stack_overflow_limit); }
1568   static ByteSize is_method_handle_return_offset() { return byte_offset_of(JavaThread, _is_method_handle_return); }
1569   static ByteSize stack_guard_state_offset()     { return byte_offset_of(JavaThread, _stack_guard_state); }
1570   static ByteSize reserved_stack_activation_offset() { return byte_offset_of(JavaThread, _reserved_stack_activation); }
1571   static ByteSize suspend_flags_offset()         { return byte_offset_of(JavaThread, _suspend_flags); }
1572 
1573   static ByteSize do_not_unlock_if_synchronized_offset() { return byte_offset_of(JavaThread, _do_not_unlock_if_synchronized); }
1574   static ByteSize should_post_on_exceptions_flag_offset() {
1575     return byte_offset_of(JavaThread, _should_post_on_exceptions_flag);
1576   }
1577 
1578 #if INCLUDE_ALL_GCS
1579   static ByteSize satb_mark_queue_offset()       { return byte_offset_of(JavaThread, _satb_mark_queue); }
1580   static ByteSize dirty_card_queue_offset()      { return byte_offset_of(JavaThread, _dirty_card_queue); }
1581 #endif // INCLUDE_ALL_GCS
1582 
1583   // Returns the jni environment for this thread
1584   JNIEnv* jni_environment()                      { return &amp;_jni_environment; }
1585 
1586   static JavaThread* thread_from_jni_environment(JNIEnv* env) {
1587     JavaThread *thread_from_jni_env = (JavaThread*)((intptr_t)env - in_bytes(jni_environment_offset()));
1588     // Only return NULL if thread is off the thread list; starting to
1589     // exit should not return NULL.
1590     if (thread_from_jni_env-&gt;is_terminated()) {
1591       thread_from_jni_env-&gt;block_if_vm_exited();
1592       return NULL;
1593     } else {
1594       return thread_from_jni_env;
1595     }
1596   }
1597 
1598   // JNI critical regions. These can nest.
1599   bool in_critical()    { return _jni_active_critical &gt; 0; }
1600   bool in_last_critical()  { return _jni_active_critical == 1; }
1601   void enter_critical() {
1602     assert(Thread::current() == this ||
1603            (Thread::current()-&gt;is_VM_thread() &amp;&amp;
1604            SafepointSynchronize::is_synchronizing()),
1605            "this must be current thread or synchronizing");
1606     _jni_active_critical++;
1607   }
1608   void exit_critical() {
1609     assert(Thread::current() == this, "this must be current thread");
1610     _jni_active_critical--;
1611     assert(_jni_active_critical &gt;= 0, "JNI critical nesting problem?");
1612   }
1613 
1614   // Checked JNI, is the programmer required to check for exceptions, specify which function name
1615   bool is_pending_jni_exception_check() const { return _pending_jni_exception_check_fn != NULL; }
1616   void clear_pending_jni_exception_check() { _pending_jni_exception_check_fn = NULL; }
1617   const char* get_pending_jni_exception_check() const { return _pending_jni_exception_check_fn; }
1618   void set_pending_jni_exception_check(const char* fn_name) { _pending_jni_exception_check_fn = (char*) fn_name; }
1619 
1620   // For deadlock detection
1621   int depth_first_number() { return _depth_first_number; }
1622   void set_depth_first_number(int dfn) { _depth_first_number = dfn; }
1623 
1624  private:
1625   void set_monitor_chunks(MonitorChunk* monitor_chunks) { _monitor_chunks = monitor_chunks; }
1626 
1627  public:
1628   MonitorChunk* monitor_chunks() const           { return _monitor_chunks; }
1629   void add_monitor_chunk(MonitorChunk* chunk);
1630   void remove_monitor_chunk(MonitorChunk* chunk);
1631   bool in_deopt_handler() const                  { return _in_deopt_handler &gt; 0; }
1632   void inc_in_deopt_handler()                    { _in_deopt_handler++; }
1633   void dec_in_deopt_handler() {
1634     assert(_in_deopt_handler &gt; 0, "mismatched deopt nesting");
1635     if (_in_deopt_handler &gt; 0) { // robustness
1636       _in_deopt_handler--;
1637     }
1638   }
1639 
1640  private:
1641   void set_entry_point(ThreadFunction entry_point) { _entry_point = entry_point; }
1642 
1643  public:
1644 
1645   // Frame iteration; calls the function f for all frames on the stack
1646   void frames_do(void f(frame*, const RegisterMap*));
1647 
1648   // Memory operations
1649   void oops_do(OopClosure* f, CodeBlobClosure* cf);
1650 
1651   // Sweeper operations
1652   virtual void nmethods_do(CodeBlobClosure* cf);
1653 
1654   // RedefineClasses Support
1655   void metadata_do(void f(Metadata*));
1656 
1657   // Misc. operations
1658   char* name() const { return (char*)get_thread_name(); }
1659   void print_on(outputStream* st) const;
1660   void print_value();
1661   void print_thread_state_on(outputStream*) const      PRODUCT_RETURN;
1662   void print_thread_state() const                      PRODUCT_RETURN;
1663   void print_on_error(outputStream* st, char* buf, int buflen) const;
1664   void print_name_on_error(outputStream* st, char* buf, int buflen) const;
1665   void verify();
1666   const char* get_thread_name() const;
1667  private:
1668   // factor out low-level mechanics for use in both normal and error cases
1669   const char* get_thread_name_string(char* buf = NULL, int buflen = 0) const;
1670  public:
1671   const char* get_threadgroup_name() const;
1672   const char* get_parent_name() const;
1673 
1674   // Accessing frames
1675   frame last_frame() {
1676     _anchor.make_walkable(this);
1677     return pd_last_frame();
1678   }
1679   javaVFrame* last_java_vframe(RegisterMap* reg_map);
1680 
1681   // Returns method at 'depth' java or native frames down the stack
1682   // Used for security checks
1683   Klass* security_get_caller_class(int depth);
1684 
1685   // Print stack trace in external format
1686   void print_stack_on(outputStream* st);
1687   void print_stack() { print_stack_on(tty); }
1688 
1689   // Print stack traces in various internal formats
1690   void trace_stack()                             PRODUCT_RETURN;
1691   void trace_stack_from(vframe* start_vf)        PRODUCT_RETURN;
1692   void trace_frames()                            PRODUCT_RETURN;
1693   void trace_oops()                              PRODUCT_RETURN;
1694 
1695   // Print an annotated view of the stack frames
1696   void print_frame_layout(int depth = 0, bool validate_only = false) NOT_DEBUG_RETURN;
1697   void validate_frame_layout() {
1698     print_frame_layout(0, true);
1699   }
1700 
1701   // Returns the number of stack frames on the stack
1702   int depth() const;
1703 
1704   // Function for testing deoptimization
1705   void deoptimize();
1706   void make_zombies();
1707 
1708   void deoptimized_wrt_marked_nmethods();
1709 
1710   // Profiling operation (see fprofile.cpp)
1711  public:
1712   bool profile_last_Java_frame(frame* fr);
1713 
1714  private:
1715   ThreadProfiler* _thread_profiler;
1716  private:
1717   friend class FlatProfiler;                    // uses both [gs]et_thread_profiler.
1718   friend class FlatProfilerTask;                // uses get_thread_profiler.
1719   friend class ThreadProfilerMark;              // uses get_thread_profiler.
1720   ThreadProfiler* get_thread_profiler()         { return _thread_profiler; }
1721   ThreadProfiler* set_thread_profiler(ThreadProfiler* tp) {
1722     ThreadProfiler* result = _thread_profiler;
1723     _thread_profiler = tp;
1724     return result;
1725   }
1726 
1727  public:
1728   // Returns the running thread as a JavaThread
1729   static inline JavaThread* current();
1730 
1731   // Returns the active Java thread.  Do not use this if you know you are calling
1732   // from a JavaThread, as it's slower than JavaThread::current.  If called from
1733   // the VMThread, it also returns the JavaThread that instigated the VMThread's
1734   // operation.  You may not want that either.
1735   static JavaThread* active();
1736 
1737   inline CompilerThread* as_CompilerThread();
1738 
1739  public:
1740   virtual void run();
1741   void thread_main_inner();
1742 
1743  private:
1744   // PRIVILEGED STACK
1745   PrivilegedElement*  _privileged_stack_top;
1746   GrowableArray&lt;oop&gt;* _array_for_gc;
1747  public:
1748 
1749   // Returns the privileged_stack information.
1750   PrivilegedElement* privileged_stack_top() const       { return _privileged_stack_top; }
1751   void set_privileged_stack_top(PrivilegedElement *e)   { _privileged_stack_top = e; }
1752   void register_array_for_gc(GrowableArray&lt;oop&gt;* array) { _array_for_gc = array; }
1753 
1754  public:
1755   // Thread local information maintained by JVMTI.
1756   void set_jvmti_thread_state(JvmtiThreadState *value)                           { _jvmti_thread_state = value; }
1757   // A JvmtiThreadState is lazily allocated. This jvmti_thread_state()
1758   // getter is used to get this JavaThread's JvmtiThreadState if it has
1759   // one which means NULL can be returned. JvmtiThreadState::state_for()
1760   // is used to get the specified JavaThread's JvmtiThreadState if it has
1761   // one or it allocates a new JvmtiThreadState for the JavaThread and
1762   // returns it. JvmtiThreadState::state_for() will return NULL only if
1763   // the specified JavaThread is exiting.
1764   JvmtiThreadState *jvmti_thread_state() const                                   { return _jvmti_thread_state; }
1765   static ByteSize jvmti_thread_state_offset()                                    { return byte_offset_of(JavaThread, _jvmti_thread_state); }
1766   void set_jvmti_get_loaded_classes_closure(JvmtiGetLoadedClassesClosure* value) { _jvmti_get_loaded_classes_closure = value; }
1767   JvmtiGetLoadedClassesClosure* get_jvmti_get_loaded_classes_closure() const     { return _jvmti_get_loaded_classes_closure; }
1768 
1769   // JVMTI PopFrame support
1770   // Setting and clearing popframe_condition
1771   // All of these enumerated values are bits. popframe_pending
1772   // indicates that a PopFrame() has been requested and not yet been
1773   // completed. popframe_processing indicates that that PopFrame() is in
1774   // the process of being completed. popframe_force_deopt_reexecution_bit
1775   // indicates that special handling is required when returning to a
1776   // deoptimized caller.
1777   enum PopCondition {
1778     popframe_inactive                      = 0x00,
1779     popframe_pending_bit                   = 0x01,
1780     popframe_processing_bit                = 0x02,
1781     popframe_force_deopt_reexecution_bit   = 0x04
1782   };
1783   PopCondition popframe_condition()                   { return (PopCondition) _popframe_condition; }
1784   void set_popframe_condition(PopCondition c)         { _popframe_condition = c; }
1785   void set_popframe_condition_bit(PopCondition c)     { _popframe_condition |= c; }
1786   void clear_popframe_condition()                     { _popframe_condition = popframe_inactive; }
1787   static ByteSize popframe_condition_offset()         { return byte_offset_of(JavaThread, _popframe_condition); }
1788   bool has_pending_popframe()                         { return (popframe_condition() &amp; popframe_pending_bit) != 0; }
1789   bool popframe_forcing_deopt_reexecution()           { return (popframe_condition() &amp; popframe_force_deopt_reexecution_bit) != 0; }
1790   void clear_popframe_forcing_deopt_reexecution()     { _popframe_condition &amp;= ~popframe_force_deopt_reexecution_bit; }
1791 #ifdef CC_INTERP
1792   bool pop_frame_pending(void)                        { return ((_popframe_condition &amp; popframe_pending_bit) != 0); }
1793   void clr_pop_frame_pending(void)                    { _popframe_condition = popframe_inactive; }
1794   bool pop_frame_in_process(void)                     { return ((_popframe_condition &amp; popframe_processing_bit) != 0); }
1795   void set_pop_frame_in_process(void)                 { _popframe_condition |= popframe_processing_bit; }
1796   void clr_pop_frame_in_process(void)                 { _popframe_condition &amp;= ~popframe_processing_bit; }
1797 #endif
1798 
1799   int frames_to_pop_failed_realloc() const            { return _frames_to_pop_failed_realloc; }
1800   void set_frames_to_pop_failed_realloc(int nb)       { _frames_to_pop_failed_realloc = nb; }
1801   void dec_frames_to_pop_failed_realloc()             { _frames_to_pop_failed_realloc--; }
1802 
1803  private:
1804   // Saved incoming arguments to popped frame.
1805   // Used only when popped interpreted frame returns to deoptimized frame.
1806   void*    _popframe_preserved_args;
1807   int      _popframe_preserved_args_size;
1808 
1809  public:
1810   void  popframe_preserve_args(ByteSize size_in_bytes, void* start);
1811   void* popframe_preserved_args();
1812   ByteSize popframe_preserved_args_size();
1813   WordSize popframe_preserved_args_size_in_words();
1814   void  popframe_free_preserved_args();
1815 
1816 
1817  private:
1818   JvmtiThreadState *_jvmti_thread_state;
1819   JvmtiGetLoadedClassesClosure* _jvmti_get_loaded_classes_closure;
1820 
1821   // Used by the interpreter in fullspeed mode for frame pop, method
1822   // entry, method exit and single stepping support. This field is
1823   // only set to non-zero by the VM_EnterInterpOnlyMode VM operation.
1824   // It can be set to zero asynchronously (i.e., without a VM operation
1825   // or a lock) so we have to be very careful.
1826   int               _interp_only_mode;
1827 
1828  public:
1829   // used by the interpreter for fullspeed debugging support (see above)
1830   static ByteSize interp_only_mode_offset() { return byte_offset_of(JavaThread, _interp_only_mode); }
1831   bool is_interp_only_mode()                { return (_interp_only_mode != 0); }
1832   int get_interp_only_mode()                { return _interp_only_mode; }
1833   void increment_interp_only_mode()         { ++_interp_only_mode; }
1834   void decrement_interp_only_mode()         { --_interp_only_mode; }
1835 
1836   // support for cached flag that indicates whether exceptions need to be posted for this thread
1837   // if this is false, we can avoid deoptimizing when events are thrown
1838   // this gets set to reflect whether jvmtiExport::post_exception_throw would actually do anything
1839  private:
1840   int    _should_post_on_exceptions_flag;
1841 
1842  public:
1843   int   should_post_on_exceptions_flag()  { return _should_post_on_exceptions_flag; }
1844   void  set_should_post_on_exceptions_flag(int val)  { _should_post_on_exceptions_flag = val; }
1845 
1846  private:
1847   ThreadStatistics *_thread_stat;
1848 
1849  public:
1850   ThreadStatistics* get_thread_stat() const    { return _thread_stat; }
1851 
1852   // Return a blocker object for which this thread is blocked parking.
1853   oop current_park_blocker();
1854 
1855  private:
1856   static size_t _stack_size_at_create;
1857 
1858  public:
1859   static inline size_t stack_size_at_create(void) {
1860     return _stack_size_at_create;
1861   }
1862   static inline void set_stack_size_at_create(size_t value) {
1863     _stack_size_at_create = value;
1864   }
1865 
1866 #if INCLUDE_ALL_GCS
1867   // SATB marking queue support
1868   SATBMarkQueue&amp; satb_mark_queue() { return _satb_mark_queue; }
1869   static SATBMarkQueueSet&amp; satb_mark_queue_set() {
1870     return _satb_mark_queue_set;
1871   }
1872 
1873   // Dirty card queue support
1874   DirtyCardQueue&amp; dirty_card_queue() { return _dirty_card_queue; }
1875   static DirtyCardQueueSet&amp; dirty_card_queue_set() {
1876     return _dirty_card_queue_set;
1877   }
1878 #endif // INCLUDE_ALL_GCS
1879 
1880   // This method initializes the SATB and dirty card queues before a
1881   // JavaThread is added to the Java thread list. Right now, we don't
1882   // have to do anything to the dirty card queue (it should have been
1883   // activated when the thread was created), but we have to activate
1884   // the SATB queue if the thread is created while a marking cycle is
1885   // in progress. The activation / de-activation of the SATB queues at
1886   // the beginning / end of a marking cycle is done during safepoints
1887   // so we have to make sure this method is called outside one to be
1888   // able to safely read the active field of the SATB queue set. Right
1889   // now, it is called just before the thread is added to the Java
1890   // thread list in the Threads::add() method. That method is holding
1891   // the Threads_lock which ensures we are outside a safepoint. We
1892   // cannot do the obvious and set the active field of the SATB queue
1893   // when the thread is created given that, in some cases, safepoints
1894   // might happen between the JavaThread constructor being called and the
1895   // thread being added to the Java thread list (an example of this is
1896   // when the structure for the DestroyJavaVM thread is created).
1897 #if INCLUDE_ALL_GCS
1898   void initialize_queues();
1899 #else  // INCLUDE_ALL_GCS
1900   void initialize_queues() { }
1901 #endif // INCLUDE_ALL_GCS
1902 
1903   // Machine dependent stuff
1904 #ifdef TARGET_OS_ARCH_linux_x86
1905 # include "thread_linux_x86.hpp"
1906 #endif
1907 #ifdef TARGET_OS_ARCH_linux_sparc
1908 # include "thread_linux_sparc.hpp"
1909 #endif
1910 #ifdef TARGET_OS_ARCH_linux_zero
1911 # include "thread_linux_zero.hpp"
1912 #endif
1913 #ifdef TARGET_OS_ARCH_solaris_x86
1914 # include "thread_solaris_x86.hpp"
1915 #endif
1916 #ifdef TARGET_OS_ARCH_solaris_sparc
1917 # include "thread_solaris_sparc.hpp"
1918 #endif
1919 #ifdef TARGET_OS_ARCH_windows_x86
1920 # include "thread_windows_x86.hpp"
1921 #endif
1922 #ifdef TARGET_OS_ARCH_linux_arm
1923 # include "thread_linux_arm.hpp"
1924 #endif
1925 #ifdef TARGET_OS_ARCH_linux_ppc
1926 # include "thread_linux_ppc.hpp"
1927 #endif
1928 #ifdef TARGET_OS_ARCH_linux_aarch64
1929 # include "thread_linux_aarch64.hpp"
1930 #endif
1931 #ifdef TARGET_OS_ARCH_aix_ppc
1932 # include "thread_aix_ppc.hpp"
1933 #endif
1934 #ifdef TARGET_OS_ARCH_bsd_x86
1935 # include "thread_bsd_x86.hpp"
1936 #endif
1937 #ifdef TARGET_OS_ARCH_bsd_zero
1938 # include "thread_bsd_zero.hpp"
1939 #endif
1940 
1941 
1942  public:
1943   void set_blocked_on_compilation(bool value) {
1944     _blocked_on_compilation = value;
1945   }
1946 
1947   bool blocked_on_compilation() {
1948     return _blocked_on_compilation;
1949   }
1950  protected:
1951   bool         _blocked_on_compilation;
1952 
1953 
1954   // JSR166 per-thread parker
1955  private:
1956   Parker*    _parker;
1957  public:
1958   Parker*     parker() { return _parker; }
1959 
1960   // Biased locking support
1961  private:
1962   GrowableArray&lt;MonitorInfo*&gt;* _cached_monitor_info;
1963  public:
1964   GrowableArray&lt;MonitorInfo*&gt;* cached_monitor_info() { return _cached_monitor_info; }
1965   void set_cached_monitor_info(GrowableArray&lt;MonitorInfo*&gt;* info) { _cached_monitor_info = info; }
1966 
1967   // clearing/querying jni attach status
1968   bool is_attaching_via_jni() const { return _jni_attach_state == _attaching_via_jni; }
1969   bool has_attached_via_jni() const { return is_attaching_via_jni() || _jni_attach_state == _attached_via_jni; }
1970   inline void set_done_attaching_via_jni();
1971 };
1972 
1973 // Inline implementation of JavaThread::current
1974 inline JavaThread* JavaThread::current() {
1975   Thread* thread = Thread::current();
1976   assert(thread-&gt;is_Java_thread(), "just checking");
1977   return (JavaThread*)thread;
1978 }
1979 
1980 inline CompilerThread* JavaThread::as_CompilerThread() {
1981   assert(is_Compiler_thread(), "just checking");
1982   return (CompilerThread*)this;
1983 }
1984 
1985 // Dedicated thread to sweep the code cache
1986 class CodeCacheSweeperThread : public JavaThread {
1987   CompiledMethod*       _scanned_compiled_method; // nmethod being scanned by the sweeper
1988  public:
1989   CodeCacheSweeperThread();
1990   // Track the nmethod currently being scanned by the sweeper
1991   void set_scanned_compiled_method(CompiledMethod* cm) {
1992     assert(_scanned_compiled_method == NULL || cm == NULL, "should reset to NULL before writing a new value");
1993     _scanned_compiled_method = cm;
1994   }
1995 
1996   // Hide sweeper thread from external view.
1997   bool is_hidden_from_external_view() const { return true; }
1998 
1999   bool is_Code_cache_sweeper_thread() const { return true; }
2000 
2001   // Prevent GC from unloading _scanned_compiled_method
2002   void oops_do(OopClosure* f, CodeBlobClosure* cf);
2003   void nmethods_do(CodeBlobClosure* cf);
2004 };
2005 
2006 // A thread used for Compilation.
2007 class CompilerThread : public JavaThread {
2008   friend class VMStructs;
2009  private:
2010   CompilerCounters* _counters;
2011 
2012   ciEnv*            _env;
2013   CompileLog*       _log;
2014   CompileTask*      _task;
2015   CompileQueue*     _queue;
2016   BufferBlob*       _buffer_blob;
2017 
2018   AbstractCompiler* _compiler;
2019 
2020  public:
2021 
2022   static CompilerThread* current();
2023 
2024   CompilerThread(CompileQueue* queue, CompilerCounters* counters);
2025 
2026   bool is_Compiler_thread() const                { return true; }
2027 
2028   virtual bool can_call_java() const;
2029 
2030   // Hide native compiler threads from external view.
2031   bool is_hidden_from_external_view() const      { return !can_call_java(); }
2032 
2033   void set_compiler(AbstractCompiler* c)         { _compiler = c; }
2034   AbstractCompiler* compiler() const             { return _compiler; }
2035 
2036   CompileQueue* queue()        const             { return _queue; }
2037   CompilerCounters* counters() const             { return _counters; }
2038 
2039   // Get/set the thread's compilation environment.
2040   ciEnv*        env()                            { return _env; }
2041   void          set_env(ciEnv* env)              { _env = env; }
2042 
2043   BufferBlob*   get_buffer_blob() const          { return _buffer_blob; }
2044   void          set_buffer_blob(BufferBlob* b)   { _buffer_blob = b; }
2045 
2046   // Get/set the thread's logging information
2047   CompileLog*   log()                            { return _log; }
2048   void          init_log(CompileLog* log) {
2049     // Set once, for good.
2050     assert(_log == NULL, "set only once");
2051     _log = log;
2052   }
2053 
2054 #ifndef PRODUCT
2055  private:
2056   IdealGraphPrinter *_ideal_graph_printer;
2057  public:
2058   IdealGraphPrinter *ideal_graph_printer()           { return _ideal_graph_printer; }
2059   void set_ideal_graph_printer(IdealGraphPrinter *n) { _ideal_graph_printer = n; }
2060 #endif
2061 
2062   // Get/set the thread's current task
2063   CompileTask* task()                      { return _task; }
2064   void         set_task(CompileTask* task) { _task = task; }
2065 };
2066 
2067 inline CompilerThread* CompilerThread::current() {
2068   return JavaThread::current()-&gt;as_CompilerThread();
2069 }
2070 
2071 // The active thread queue. It also keeps track of the current used
2072 // thread priorities.
2073 class Threads: AllStatic {
2074   friend class VMStructs;
2075  private:
2076   static JavaThread* _thread_list;
2077   static int         _number_of_threads;
2078   static int         _number_of_non_daemon_threads;
2079   static int         _return_code;
2080   static int         _thread_claim_parity;
2081 #ifdef ASSERT
2082   static bool        _vm_complete;
2083 #endif
2084 
2085   static void initialize_java_lang_classes(JavaThread* main_thread, TRAPS);
2086   static void initialize_jsr292_core_classes(TRAPS);
2087  public:
2088   // Thread management
2089   // force_daemon is a concession to JNI, where we may need to add a
2090   // thread to the thread list before allocating its thread object
2091   static void add(JavaThread* p, bool force_daemon = false);
2092   static void remove(JavaThread* p);
2093   static bool includes(JavaThread* p);
2094   static JavaThread* first()                     { return _thread_list; }
2095   static void threads_do(ThreadClosure* tc);
2096 
2097   // Initializes the vm and creates the vm thread
2098   static jint create_vm(JavaVMInitArgs* args, bool* canTryAgain);
2099   static void convert_vm_init_libraries_to_agents();
2100   static void create_vm_init_libraries();
2101   static void create_vm_init_agents();
2102   static void shutdown_vm_agents();
2103   static bool destroy_vm();
2104   // Supported VM versions via JNI
2105   // Includes JNI_VERSION_1_1
2106   static jboolean is_supported_jni_version_including_1_1(jint version);
2107   // Does not include JNI_VERSION_1_1
2108   static jboolean is_supported_jni_version(jint version);
2109 
2110   // The "thread claim parity" provides a way for threads to be claimed
2111   // by parallel worker tasks.
2112   //
2113   // Each thread contains a a "parity" field. A task will claim the
2114   // thread only if its parity field is the same as the global parity,
2115   // which is updated by calling change_thread_claim_parity().
2116   //
2117   // For this to work change_thread_claim_parity() needs to be called
2118   // exactly once in sequential code before starting parallel tasks
2119   // that should claim threads.
2120   //
2121   // New threads get their parity set to 0 and change_thread_claim_parity()
2122   // never set the global parity to 0.
2123   static int thread_claim_parity() { return _thread_claim_parity; }
2124   static void change_thread_claim_parity();
2125   static void assert_all_threads_claimed() NOT_DEBUG_RETURN;
2126 
2127   // Apply "f-&gt;do_oop" to all root oops in all threads.
2128   // This version may only be called by sequential code.
2129   static void oops_do(OopClosure* f, CodeBlobClosure* cf);
2130   // This version may be called by sequential or parallel code.
2131   static void possibly_parallel_oops_do(bool is_par, OopClosure* f, CodeBlobClosure* cf);
2132   // This creates a list of GCTasks, one per thread.
2133   static void create_thread_roots_tasks(GCTaskQueue* q);
2134   // This creates a list of GCTasks, one per thread, for marking objects.
2135   static void create_thread_roots_marking_tasks(GCTaskQueue* q);
2136 
2137   // Apply "f-&gt;do_oop" to roots in all threads that
2138   // are part of compiled frames
2139   static void compiled_frame_oops_do(OopClosure* f, CodeBlobClosure* cf);
2140 
2141   static void convert_hcode_pointers();
2142   static void restore_hcode_pointers();
2143 
2144   // Sweeper
2145   static void nmethods_do(CodeBlobClosure* cf);
2146 
2147   // RedefineClasses support
2148   static void metadata_do(void f(Metadata*));
2149   static void metadata_handles_do(void f(Metadata*));
2150 
2151 #ifdef ASSERT
2152   static bool is_vm_complete() { return _vm_complete; }
2153 #endif
2154 
2155   // Verification
2156   static void verify();
2157   static void print_on(outputStream* st, bool print_stacks, bool internal_format, bool print_concurrent_locks);
2158   static void print(bool print_stacks, bool internal_format) {
2159     // this function is only used by debug.cpp
2160     print_on(tty, print_stacks, internal_format, false /* no concurrent lock printed */);
2161   }
2162   static void print_on_error(outputStream* st, Thread* current, char* buf, int buflen);
2163   static void print_on_error(Thread* this_thread, outputStream* st, Thread* current, char* buf,
2164                              int buflen, bool* found_current);
2165   static void print_threads_compiling(outputStream* st, char* buf, int buflen);
2166 
2167   // Get Java threads that are waiting to enter a monitor. If doLock
2168   // is true, then Threads_lock is grabbed as needed. Otherwise, the
2169   // VM needs to be at a safepoint.
2170   static GrowableArray&lt;JavaThread*&gt;* get_pending_threads(int count,
2171                                                          address monitor, bool doLock);
2172 
2173   // Get owning Java thread from the monitor's owner field. If doLock
2174   // is true, then Threads_lock is grabbed as needed. Otherwise, the
2175   // VM needs to be at a safepoint.
2176   static JavaThread *owning_thread_from_monitor_owner(address owner,
2177                                                       bool doLock);
2178 
2179   // Number of threads on the active threads list
2180   static int number_of_threads()                 { return _number_of_threads; }
2181   // Number of non-daemon threads on the active threads list
2182   static int number_of_non_daemon_threads()      { return _number_of_non_daemon_threads; }
2183 
2184   // Deoptimizes all frames tied to marked nmethods
2185   static void deoptimized_wrt_marked_nmethods();
2186 
2187   static JavaThread* find_java_thread_from_java_tid(jlong java_tid);
2188 
2189 };
2190 
2191 
2192 // Thread iterator
2193 class ThreadClosure: public StackObj {
2194  public:
2195   virtual void do_thread(Thread* thread) = 0;
2196 };
2197 
2198 class SignalHandlerMark: public StackObj {
2199  private:
2200   Thread* _thread;
2201  public:
2202   SignalHandlerMark(Thread* t) {
2203     _thread = t;
2204     if (_thread) _thread-&gt;enter_signal_handler();
2205   }
2206   ~SignalHandlerMark() {
2207     if (_thread) _thread-&gt;leave_signal_handler();
2208     _thread = NULL;
2209   }
2210 };
2211 
2212 
2213 #endif // SHARE_VM_RUNTIME_THREAD_HPP
<a name="3" id="anc3"></a><b style="font-size: large; color: red">--- EOF ---</b>















































































</pre><form name="eof"><input name="value" value="3" type="hidden" /></form></body></html>
