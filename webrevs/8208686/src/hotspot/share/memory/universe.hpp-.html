<?xml version="1.0"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta charset="utf-8">
<meta http-equiv="cache-control" content="no-cache" />
<meta http-equiv="Pragma" content="no-cache" />
<meta http-equiv="Expires" content="-1" />
<!--
   Note to customizers: the body of the webrev is IDed as SUNWwebrev
   to allow easy overriding by users of webrev via the userContent.css
   mechanism available in some browsers.

   For example, to have all "removed" information be red instead of
   brown, set a rule in your userContent.css file like:

       body#SUNWwebrev span.removed { color: red ! important; }
-->
<style type="text/css" media="screen">
body {
    background-color: #eeeeee;
}
hr {
    border: none 0;
    border-top: 1px solid #aaa;
    height: 1px;
}
div.summary {
    font-size: .8em;
    border-bottom: 1px solid #aaa;
    padding-left: 1em;
    padding-right: 1em;
}
div.summary h2 {
    margin-bottom: 0.3em;
}
div.summary table th {
    text-align: right;
    vertical-align: top;
    white-space: nowrap;
}
span.lineschanged {
    font-size: 0.7em;
}
span.oldmarker {
    color: red;
    font-size: large;
    font-weight: bold;
}
span.newmarker {
    color: green;
    font-size: large;
    font-weight: bold;
}
span.removed {
    color: brown;
}
span.changed {
    color: blue;
}
span.new {
    color: blue;
    font-weight: bold;
}
a.print { font-size: x-small; }

</style>

<style type="text/css" media="print">
pre { font-size: 0.8em; font-family: courier, monospace; }
span.removed { color: #444; font-style: italic }
span.changed { font-weight: bold; }
span.new { font-weight: bold; }
span.newmarker { font-size: 1.2em; font-weight: bold; }
span.oldmarker { font-size: 1.2em; font-weight: bold; }
a.print {display: none}
hr { border: none 0; border-top: 1px solid #aaa; height: 1px; }
</style>

<title>Old src/hotspot/share/memory/universe.hpp</title>
<body id="SUNWwebrev">
<pre>
   1 /*
   2  * Copyright (c) 1997, 2018, Oracle and/or its affiliates. All rights reserved.
   3  * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
   4  *
   5  * This code is free software; you can redistribute it and/or modify it
   6  * under the terms of the GNU General Public License version 2 only, as
   7  * published by the Free Software Foundation.
   8  *
   9  * This code is distributed in the hope that it will be useful, but WITHOUT
  10  * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
  11  * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
  12  * version 2 for more details (a copy is included in the LICENSE file that
  13  * accompanied this code).
  14  *
  15  * You should have received a copy of the GNU General Public License version
  16  * 2 along with this work; if not, write to the Free Software Foundation,
  17  * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
  18  *
  19  * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
  20  * or visit www.oracle.com if you need additional information or have any
  21  * questions.
  22  *
  23  */
  24 
  25 #ifndef SHARE_VM_MEMORY_UNIVERSE_HPP
  26 #define SHARE_VM_MEMORY_UNIVERSE_HPP
  27 
  28 #include "oops/array.hpp"
  29 #include "runtime/handles.hpp"
  30 #include "utilities/growableArray.hpp"
  31 
  32 // Universe is a name space holding known system classes and objects in the VM.
  33 //
  34 // Loaded classes are accessible through the SystemDictionary.
  35 //
  36 // The object heap is allocated and accessed through Universe, and various allocation
  37 // support is provided. Allocation by the interpreter and compiled code is done inline
  38 // and bails out to Scavenge::invoke_and_allocate.
  39 
  40 class CollectedHeap;
  41 class DeferredObjAllocEvent;
  42 
  43 
  44 // A helper class for caching a Method* when the user of the cache
  45 // only cares about the latest version of the Method*.  This cache safely
  46 // interacts with the RedefineClasses API.
  47 
  48 class LatestMethodCache : public CHeapObj&lt;mtClass&gt; {
  49   // We save the Klass* and the idnum of Method* in order to get
  50   // the current cached Method*.
  51  private:
  52   Klass*                _klass;
  53   int                   _method_idnum;
  54 
  55  public:
  56   LatestMethodCache()   { _klass = NULL; _method_idnum = -1; }
  57   ~LatestMethodCache()  { _klass = NULL; _method_idnum = -1; }
  58 
  59   void   init(Klass* k, Method* m);
  60   Klass* klass() const           { return _klass; }
  61   int    method_idnum() const    { return _method_idnum; }
  62 
  63   Method* get_method();
  64 
  65   // CDS support.  Replace the klass in this with the archive version
  66   // could use this for Enhanced Class Redefinition also.
  67   void serialize(SerializeClosure* f) {
  68     f-&gt;do_ptr((void**)&amp;_klass);
  69   }
  70   void metaspace_pointers_do(MetaspaceClosure* it);
  71 };
  72 
  73 
  74 // For UseCompressedOops.
  75 struct NarrowPtrStruct {
  76   // Base address for oop-within-java-object materialization.
  77   // NULL if using wide oops or zero based narrow oops.
  78   address _base;
  79   // Number of shift bits for encoding/decoding narrow ptrs.
  80   // 0 if using wide ptrs or zero based unscaled narrow ptrs,
  81   // LogMinObjAlignmentInBytes/LogKlassAlignmentInBytes otherwise.
  82   int     _shift;
  83   // Generate code with implicit null checks for narrow ptrs.
  84   bool    _use_implicit_null_checks;
  85 };
  86 
  87 enum VerifyOption {
  88       VerifyOption_Default = 0,
  89 
  90       // G1
  91       VerifyOption_G1UsePrevMarking = VerifyOption_Default,
  92       VerifyOption_G1UseNextMarking = VerifyOption_G1UsePrevMarking + 1,
  93       VerifyOption_G1UseFullMarking = VerifyOption_G1UseNextMarking + 1
  94 };
  95 
  96 class Universe: AllStatic {
  97   // Ugh.  Universe is much too friendly.
  98   friend class MarkSweep;
  99   friend class oopDesc;
 100   friend class ClassLoader;
 101   friend class SystemDictionary;
 102   friend class ReservedHeapSpace;
 103   friend class VMStructs;
 104   friend class VM_PopulateDumpSharedSpace;
 105   friend class Metaspace;
 106   friend class MetaspaceShared;
 107 
 108   friend jint  universe_init();
 109   friend void  universe2_init();
 110   friend bool  universe_post_init();
 111   friend void  universe_post_module_init();
 112 
 113  private:
 114   // Known classes in the VM
 115   static Klass* _typeArrayKlassObjs[T_LONG+1];
 116   static Klass* _objectArrayKlassObj;
 117 
 118   // Known objects in the VM
 119 
 120   // Primitive objects
 121   static oop _int_mirror;
 122   static oop _float_mirror;
 123   static oop _double_mirror;
 124   static oop _byte_mirror;
 125   static oop _bool_mirror;
 126   static oop _char_mirror;
 127   static oop _long_mirror;
 128   static oop _short_mirror;
 129   static oop _void_mirror;
 130 
 131   static oop          _main_thread_group;             // Reference to the main thread group object
 132   static oop          _system_thread_group;           // Reference to the system thread group object
 133 
 134   static objArrayOop  _the_empty_class_klass_array;   // Canonicalized obj array of type java.lang.Class
 135   static oop          _the_null_sentinel;             // A unique object pointer unused except as a sentinel for null.
 136   static oop          _the_null_string;               // A cache of "null" as a Java string
 137   static oop          _the_min_jint_string;          // A cache of "-2147483648" as a Java string
 138   static LatestMethodCache* _finalizer_register_cache; // static method for registering finalizable objects
 139   static LatestMethodCache* _loader_addClass_cache;    // method for registering loaded classes in class loader vector
 140   static LatestMethodCache* _pd_implies_cache;         // method for checking protection domain attributes
 141   static LatestMethodCache* _throw_illegal_access_error_cache; // Unsafe.throwIllegalAccessError() method
 142   static LatestMethodCache* _do_stack_walk_cache;      // method for stack walker callback
 143 
 144   // preallocated error objects (no backtrace)
 145   static oop          _out_of_memory_error_java_heap;
 146   static oop          _out_of_memory_error_metaspace;
 147   static oop          _out_of_memory_error_class_metaspace;
 148   static oop          _out_of_memory_error_array_size;
 149   static oop          _out_of_memory_error_gc_overhead_limit;
 150   static oop          _out_of_memory_error_realloc_objects;
 151 
 152   // preallocated cause message for delayed StackOverflowError
 153   static oop          _delayed_stack_overflow_error_message;
 154 
 155   static Array&lt;int&gt;*            _the_empty_int_array;            // Canonicalized int array
 156   static Array&lt;u2&gt;*             _the_empty_short_array;          // Canonicalized short array
 157   static Array&lt;Klass*&gt;*         _the_empty_klass_array;          // Canonicalized klass array
 158   static Array&lt;InstanceKlass*&gt;* _the_empty_instance_klass_array; // Canonicalized instance klass array
 159   static Array&lt;Method*&gt;*        _the_empty_method_array;         // Canonicalized method array
 160 
 161   static Array&lt;Klass*&gt;*  _the_array_interfaces_array;
 162 
 163   // array of preallocated error objects with backtrace
 164   static objArrayOop   _preallocated_out_of_memory_error_array;
 165 
 166   // number of preallocated error objects available for use
 167   static volatile jint _preallocated_out_of_memory_error_avail_count;
 168 
 169   static oop          _null_ptr_exception_instance;   // preallocated exception object
 170   static oop          _arithmetic_exception_instance; // preallocated exception object
 171   static oop          _virtual_machine_error_instance; // preallocated exception object
 172   // The object used as an exception dummy when exceptions are thrown for
 173   // the vm thread.
 174   static oop          _vm_exception;
 175 
 176   // References waiting to be transferred to the ReferenceHandler
 177   static oop          _reference_pending_list;
 178 
 179   // The particular choice of collected heap.
 180   static CollectedHeap* _collectedHeap;
 181 
 182   static intptr_t _non_oop_bits;
 183 
 184   // For UseCompressedOops.
 185   static struct NarrowPtrStruct _narrow_oop;
 186   // For UseCompressedClassPointers.
 187   static struct NarrowPtrStruct _narrow_klass;
 188   static address _narrow_ptrs_base;
 189   // CompressedClassSpaceSize set to 1GB, but appear 3GB away from _narrow_ptrs_base during CDS dump.
 190   static uint64_t _narrow_klass_range;
 191   // array of dummy objects used with +FullGCAlot
 192   debug_only(static objArrayOop _fullgc_alot_dummy_array;)
 193   // index of next entry to clear
 194   debug_only(static int         _fullgc_alot_dummy_next;)
 195 
 196   // Compiler/dispatch support
 197   static int  _base_vtable_size;                      // Java vtbl size of klass Object (in words)
 198 
 199   // Initialization
 200   static bool _bootstrapping;                         // true during genesis
 201   static bool _module_initialized;                    // true after call_initPhase2 called
 202   static bool _fully_initialized;                     // true after universe_init and initialize_vtables called
 203 
 204   // the array of preallocated errors with backtraces
 205   static objArrayOop  preallocated_out_of_memory_errors()     { return _preallocated_out_of_memory_error_array; }
 206 
 207   // generate an out of memory error; if possible using an error with preallocated backtrace;
 208   // otherwise return the given default error.
 209   static oop        gen_out_of_memory_error(oop default_err);
 210 
 211   // Historic gc information
 212   static size_t _heap_capacity_at_last_gc;
 213   static size_t _heap_used_at_last_gc;
 214 
 215   static CollectedHeap* create_heap();
 216   static jint initialize_heap();
 217   static void initialize_basic_type_mirrors(TRAPS);
 218   static void fixup_mirrors(TRAPS);
 219 
 220   static void reinitialize_vtable_of(Klass* k, TRAPS);
 221   static void reinitialize_itables(TRAPS);
 222   static void compute_base_vtable_size();             // compute vtable size of class Object
 223 
 224   static void genesis(TRAPS);                         // Create the initial world
 225 
 226   // Mirrors for primitive classes (created eagerly)
 227   static oop check_mirror(oop m) {
 228     assert(m != NULL, "mirror not initialized");
 229     return m;
 230   }
 231 
 232   static void     set_narrow_oop_base(address base) {
 233     assert(UseCompressedOops, "no compressed oops?");
 234     _narrow_oop._base    = base;
 235   }
 236   static void     set_narrow_klass_base(address base) {
 237     assert(UseCompressedClassPointers, "no compressed klass ptrs?");
 238     _narrow_klass._base   = base;
 239   }
 240   static void     set_narrow_klass_range(uint64_t range) {
 241      assert(UseCompressedClassPointers, "no compressed klass ptrs?");
 242      _narrow_klass_range = range;
 243   }
 244   static void     set_narrow_oop_use_implicit_null_checks(bool use) {
 245     assert(UseCompressedOops, "no compressed ptrs?");
 246     _narrow_oop._use_implicit_null_checks   = use;
 247   }
 248 
 249   // Debugging
 250   static int _verify_count;                           // number of verifies done
 251 
 252   // True during call to verify().  Should only be set/cleared in verify().
 253   static bool _verify_in_progress;
 254   static long verify_flags;
 255 
 256   static uintptr_t _verify_oop_mask;
 257   static uintptr_t _verify_oop_bits;
 258 
 259   static void calculate_verify_data(HeapWord* low_boundary, HeapWord* high_boundary) PRODUCT_RETURN;
 260   static void compute_verify_oop_data();
 261 
 262  public:
 263   // Known classes in the VM
 264   static Klass* boolArrayKlassObj()                 { return typeArrayKlassObj(T_BOOLEAN); }
 265   static Klass* byteArrayKlassObj()                 { return typeArrayKlassObj(T_BYTE); }
 266   static Klass* charArrayKlassObj()                 { return typeArrayKlassObj(T_CHAR); }
 267   static Klass* intArrayKlassObj()                  { return typeArrayKlassObj(T_INT); }
 268   static Klass* shortArrayKlassObj()                { return typeArrayKlassObj(T_SHORT); }
 269   static Klass* longArrayKlassObj()                 { return typeArrayKlassObj(T_LONG); }
 270   static Klass* floatArrayKlassObj()                { return typeArrayKlassObj(T_FLOAT); }
 271   static Klass* doubleArrayKlassObj()               { return typeArrayKlassObj(T_DOUBLE); }
 272 
 273   static Klass* objectArrayKlassObj()               { return _objectArrayKlassObj; }
 274 
 275   static Klass* typeArrayKlassObj(BasicType t) {
 276     assert((uint)t &gt;= T_BOOLEAN, "range check for type: %s", type2name(t));
 277     assert((uint)t &lt; T_LONG+1,   "range check for type: %s", type2name(t));
 278     assert(_typeArrayKlassObjs[t] != NULL, "domain check");
 279     return _typeArrayKlassObjs[t];
 280   }
 281 
 282   // Known objects in the VM
 283   static oop int_mirror()                   { return check_mirror(_int_mirror); }
 284   static oop float_mirror()                 { return check_mirror(_float_mirror); }
 285   static oop double_mirror()                { return check_mirror(_double_mirror); }
 286   static oop byte_mirror()                  { return check_mirror(_byte_mirror); }
 287   static oop bool_mirror()                  { return check_mirror(_bool_mirror); }
 288   static oop char_mirror()                  { return check_mirror(_char_mirror); }
 289   static oop long_mirror()                  { return check_mirror(_long_mirror); }
 290   static oop short_mirror()                 { return check_mirror(_short_mirror); }
 291   static oop void_mirror()                  { return check_mirror(_void_mirror); }
 292 
 293   static void set_int_mirror(oop m)         { _int_mirror = m;    }
 294   static void set_float_mirror(oop m)       { _float_mirror = m;  }
 295   static void set_double_mirror(oop m)      { _double_mirror = m; }
 296   static void set_byte_mirror(oop m)        { _byte_mirror = m;   }
 297   static void set_bool_mirror(oop m)        { _bool_mirror = m;   }
 298   static void set_char_mirror(oop m)        { _char_mirror = m;   }
 299   static void set_long_mirror(oop m)        { _long_mirror = m;   }
 300   static void set_short_mirror(oop m)       { _short_mirror = m;  }
 301   static void set_void_mirror(oop m)        { _void_mirror = m;   }
 302 
 303   // table of same
 304   static oop _mirrors[T_VOID+1];
 305 
 306   static oop java_mirror(BasicType t) {
 307     assert((uint)t &lt; T_VOID+1, "range check");
 308     return check_mirror(_mirrors[t]);
 309   }
 310   static oop      main_thread_group()                 { return _main_thread_group; }
 311   static void set_main_thread_group(oop group)        { _main_thread_group = group;}
 312 
 313   static oop      system_thread_group()               { return _system_thread_group; }
 314   static void set_system_thread_group(oop group)      { _system_thread_group = group;}
 315 
 316   static objArrayOop  the_empty_class_klass_array ()  { return _the_empty_class_klass_array;   }
 317   static Array&lt;Klass*&gt;* the_array_interfaces_array() { return _the_array_interfaces_array;   }
 318   static oop          the_null_string()               { return _the_null_string;               }
 319   static oop          the_min_jint_string()          { return _the_min_jint_string;          }
 320 
 321   static Method*      finalizer_register_method()     { return _finalizer_register_cache-&gt;get_method(); }
 322   static Method*      loader_addClass_method()        { return _loader_addClass_cache-&gt;get_method(); }
 323 
 324   static Method*      protection_domain_implies_method() { return _pd_implies_cache-&gt;get_method(); }
 325   static Method*      throw_illegal_access_error()    { return _throw_illegal_access_error_cache-&gt;get_method(); }
 326 
 327   static Method*      do_stack_walk_method()          { return _do_stack_walk_cache-&gt;get_method(); }
 328 
 329   static oop          the_null_sentinel()             { return _the_null_sentinel;             }
 330   static address      the_null_sentinel_addr()        { return (address) &amp;_the_null_sentinel;  }
 331 
 332   // Function to initialize these
 333   static void initialize_known_methods(TRAPS);
 334 
 335   static oop          null_ptr_exception_instance()   { return _null_ptr_exception_instance;   }
 336   static oop          arithmetic_exception_instance() { return _arithmetic_exception_instance; }
 337   static oop          virtual_machine_error_instance() { return _virtual_machine_error_instance; }
 338   static oop          vm_exception()                  { return _vm_exception; }
 339 
 340   // Reference pending list manipulation.  Access is protected by
 341   // Heap_lock.  The getter, setter and predicate require the caller
 342   // owns the lock.  Swap is used by parallel non-concurrent reference
 343   // processing threads, where some higher level controller owns
 344   // Heap_lock, so requires the lock is locked, but not necessarily by
 345   // the current thread.
 346   static oop          reference_pending_list();
 347   static void         set_reference_pending_list(oop list);
 348   static bool         has_reference_pending_list();
 349   static oop          swap_reference_pending_list(oop list);
 350 
 351   static Array&lt;int&gt;*             the_empty_int_array()    { return _the_empty_int_array; }
 352   static Array&lt;u2&gt;*              the_empty_short_array()  { return _the_empty_short_array; }
 353   static Array&lt;Method*&gt;*         the_empty_method_array() { return _the_empty_method_array; }
 354   static Array&lt;Klass*&gt;*          the_empty_klass_array()  { return _the_empty_klass_array; }
 355   static Array&lt;InstanceKlass*&gt;*  the_empty_instance_klass_array() { return _the_empty_instance_klass_array; }
 356 
 357   // OutOfMemoryError support. Returns an error with the required message. The returned error
 358   // may or may not have a backtrace. If error has a backtrace then the stack trace is already
 359   // filled in.
 360   static oop out_of_memory_error_java_heap()          { return gen_out_of_memory_error(_out_of_memory_error_java_heap);  }
 361   static oop out_of_memory_error_metaspace()          { return gen_out_of_memory_error(_out_of_memory_error_metaspace);   }
 362   static oop out_of_memory_error_class_metaspace()    { return gen_out_of_memory_error(_out_of_memory_error_class_metaspace);   }
 363   static oop out_of_memory_error_array_size()         { return gen_out_of_memory_error(_out_of_memory_error_array_size); }
 364   static oop out_of_memory_error_gc_overhead_limit()  { return gen_out_of_memory_error(_out_of_memory_error_gc_overhead_limit);  }
 365   static oop out_of_memory_error_realloc_objects()    { return gen_out_of_memory_error(_out_of_memory_error_realloc_objects);  }
 366   static oop delayed_stack_overflow_error_message()   { return _delayed_stack_overflow_error_message; }
 367 
 368   // The particular choice of collected heap.
 369   static CollectedHeap* heap() { return _collectedHeap; }
 370 
 371   // For UseCompressedOops
 372   // Narrow Oop encoding mode:
 373   // 0 - Use 32-bits oops without encoding when
 374   //     NarrowOopHeapBaseMin + heap_size &lt; 4Gb
 375   // 1 - Use zero based compressed oops with encoding when
 376   //     NarrowOopHeapBaseMin + heap_size &lt; 32Gb
 377   // 2 - Use compressed oops with disjoint heap base if
 378   //     base is 32G-aligned and base &gt; 0. This allows certain
 379   //     optimizations in encoding/decoding.
 380   //     Disjoint: Bits used in base are disjoint from bits used
 381   //     for oops ==&gt; oop = (cOop &lt;&lt; 3) | base.  One can disjoint
 382   //     the bits of an oop into base and compressed oop.
 383   // 3 - Use compressed oops with heap base + encoding.
 384   enum NARROW_OOP_MODE {
 385     UnscaledNarrowOop  = 0,
 386     ZeroBasedNarrowOop = 1,
 387     DisjointBaseNarrowOop = 2,
 388     HeapBasedNarrowOop = 3,
 389     AnyNarrowOopMode = 4
 390   };
 391   static NARROW_OOP_MODE narrow_oop_mode();
 392   static const char* narrow_oop_mode_to_string(NARROW_OOP_MODE mode);
 393   static char*    preferred_heap_base(size_t heap_size, size_t alignment, NARROW_OOP_MODE mode);
 394   static char*    preferred_metaspace_base(size_t heap_size, NARROW_OOP_MODE mode);
 395   static address  narrow_oop_base()                  { return  _narrow_oop._base; }
 396   // Test whether bits of addr and possible offsets into the heap overlap.
 397   static bool     is_disjoint_heap_base_address(address addr) {
 398     return (((uint64_t)(intptr_t)addr) &amp;
 399             (((uint64_t)UCONST64(0xFFFFffffFFFFffff)) &gt;&gt; (32-LogMinObjAlignmentInBytes))) == 0;
 400   }
 401   // Check for disjoint base compressed oops.
 402   static bool     narrow_oop_base_disjoint()        {
 403     return _narrow_oop._base != NULL &amp;&amp; is_disjoint_heap_base_address(_narrow_oop._base);
 404   }
 405   // Check for real heapbased compressed oops.
 406   // We must subtract the base as the bits overlap.
 407   // If we negate above function, we also get unscaled and zerobased.
 408   static bool     narrow_oop_base_overlaps()          {
 409     return _narrow_oop._base != NULL &amp;&amp; !is_disjoint_heap_base_address(_narrow_oop._base);
 410   }
 411   static bool  is_narrow_oop_base(void* addr)             { return (narrow_oop_base() == (address)addr); }
 412   static int      narrow_oop_shift()                      { return  _narrow_oop._shift; }
 413   static bool     narrow_oop_use_implicit_null_checks()   { return  _narrow_oop._use_implicit_null_checks; }
 414 
 415   // For UseCompressedClassPointers
 416   static address  narrow_klass_base()                     { return  _narrow_klass._base; }
 417   static bool  is_narrow_klass_base(void* addr)           { return (narrow_klass_base() == (address)addr); }
 418   static uint64_t narrow_klass_range()                    { return  _narrow_klass_range; }
 419   static int      narrow_klass_shift()                    { return  _narrow_klass._shift; }
 420   static bool     narrow_klass_use_implicit_null_checks() { return  _narrow_klass._use_implicit_null_checks; }
 421 
 422   static address* narrow_ptrs_base_addr()                 { return &amp;_narrow_ptrs_base; }
 423   static void     set_narrow_ptrs_base(address a)         { _narrow_ptrs_base = a; }
 424   static address  narrow_ptrs_base()                      { return _narrow_ptrs_base; }
 425 
 426   static void     print_compressed_oops_mode(outputStream* st);
 427 
 428   // this is set in vm_version on sparc (and then reset in universe afaict)
 429   static void     set_narrow_oop_shift(int shift)         {
 430     _narrow_oop._shift   = shift;
 431   }
 432 
 433   static void     set_narrow_klass_shift(int shift)       {
 434     assert(shift == 0 || shift == LogKlassAlignmentInBytes, "invalid shift for klass ptrs");
 435     _narrow_klass._shift   = shift;
 436   }
 437 
 438   // Reserve Java heap and determine CompressedOops mode
 439   static ReservedSpace reserve_heap(size_t heap_size, size_t alignment);
 440 
 441   // Historic gc information
 442   static size_t get_heap_capacity_at_last_gc()         { return _heap_capacity_at_last_gc; }
 443   static size_t get_heap_free_at_last_gc()             { return _heap_capacity_at_last_gc - _heap_used_at_last_gc; }
 444   static size_t get_heap_used_at_last_gc()             { return _heap_used_at_last_gc; }
 445   static void update_heap_info_at_gc();
 446 
 447   // Testers
 448   static bool is_bootstrapping()                      { return _bootstrapping; }
 449   static bool is_module_initialized()                 { return _module_initialized; }
 450   static bool is_fully_initialized()                  { return _fully_initialized; }
 451 
 452   static bool        on_page_boundary(void* addr);
 453   static bool        should_fill_in_stack_trace(Handle throwable);
 454   static void check_alignment(uintx size, uintx alignment, const char* name);
 455 
 456   // Iteration
 457 
 458   // Apply "f" to the addresses of all the direct heap pointers maintained
 459   // as static fields of "Universe".
 460   static void oops_do(OopClosure* f);
 461 
 462   // CDS support
 463   static void serialize(SerializeClosure* f);
 464 
 465   // Apply "f" to all klasses for basic types (classes not present in
 466   // SystemDictionary).
 467   static void basic_type_classes_do(void f(Klass*));
 468   static void basic_type_classes_do(KlassClosure* closure);
 469   static void metaspace_pointers_do(MetaspaceClosure* it);
 470 
 471   // Debugging
 472   enum VERIFY_FLAGS {
 473     Verify_Threads = 1,
 474     Verify_Heap = 2,
 475     Verify_SymbolTable = 4,
 476     Verify_StringTable = 8,
 477     Verify_CodeCache = 16,
 478     Verify_SystemDictionary = 32,
 479     Verify_ClassLoaderDataGraph = 64,
 480     Verify_MetaspaceUtils = 128,
 481     Verify_JNIHandles = 256,
 482     Verify_CodeCacheOops = 512,
 483     Verify_All = -1
 484   };
 485   static void initialize_verify_flags();
 486   static bool should_verify_subset(uint subset);
 487   static bool verify_in_progress() { return _verify_in_progress; }
 488   static void verify(VerifyOption option, const char* prefix);
 489   static void verify(const char* prefix) {
 490     verify(VerifyOption_Default, prefix);
 491   }
 492   static void verify() {
 493     verify("");
 494   }
 495 
 496   static int  verify_count()       { return _verify_count; }
 497   static void print_on(outputStream* st);
 498   static void print_heap_at_SIGBREAK();
 499   static void print_heap_before_gc();
 500   static void print_heap_after_gc();
 501 
 502   // Change the number of dummy objects kept reachable by the full gc dummy
 503   // array; this should trigger relocation in a sliding compaction collector.
 504   debug_only(static bool release_fullgc_alot_dummy();)
 505   // The non-oop pattern (see compiledIC.hpp, etc)
 506   static void*   non_oop_word();
 507 
 508   // Oop verification (see MacroAssembler::verify_oop)
 509   static uintptr_t verify_oop_mask()          PRODUCT_RETURN0;
 510   static uintptr_t verify_oop_bits()          PRODUCT_RETURN0;
 511   static uintptr_t verify_mark_bits()         PRODUCT_RETURN0;
 512   static uintptr_t verify_mark_mask()         PRODUCT_RETURN0;
 513 
 514   // Compiler support
 515   static int base_vtable_size()               { return _base_vtable_size; }
 516 };
 517 
 518 class DeferredObjAllocEvent : public CHeapObj&lt;mtInternal&gt; {
 519   private:
 520     oop    _oop;
 521     size_t _bytesize;
 522     jint   _arena_id;
 523 
 524   public:
 525     DeferredObjAllocEvent(const oop o, const size_t s, const jint id) {
 526       _oop      = o;
 527       _bytesize = s;
 528       _arena_id = id;
 529     }
 530 
 531     ~DeferredObjAllocEvent() {
 532     }
 533 
 534     jint   arena_id() { return _arena_id; }
 535     size_t bytesize() { return _bytesize; }
 536     oop    get_oop()  { return _oop; }
 537 };
 538 
 539 #endif // SHARE_VM_MEMORY_UNIVERSE_HPP
</pre></body></html>
